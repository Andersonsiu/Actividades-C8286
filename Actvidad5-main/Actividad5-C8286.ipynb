{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01e99f81-f039-43cb-ad39-b7684d96f2d8",
   "metadata": {},
   "source": [
    "### Actividad: patrones de diseño para microservicios\n",
    "\n",
    "\n",
    "Los patrones de diseño para microservicios que son especialmente útiles en entornos de computación concurrente, paralela y distribuida abordan principalmente cómo descomponer las aplicaciones en servicios más pequeños, independientes y escalables. Estos patrones también se centran en cómo estos servicios pueden comunicarse de manera eficiente, manejar fallos y procesar datos de manera concurrente y paralela. \n",
    "\n",
    "- Service Discovery: En un sistema distribuido con muchos microservicios, es crucial que los servicios puedan encontrarse y comunicarse entre sí. El patrón de Service Discovery permite a los microservicios registrarse en un servicio central y descubrir dinámicamente la ubicación de otros servicios necesarios para completar una solicitud.\n",
    "\n",
    "- Circuit Breaker: Este patrón previene fallos en un microservicio que puede causar fallas en cascada a otros servicios dependientes. Al detectar fallas repetidas en un servicio, el Circuit Breaker corta temporalmente la llamada al servicio fallido, permitiendo que se recupere y evitando que el sistema completo se vea afectado.\n",
    "\n",
    "- Bulkhead: Inspirado en los compartimientos estancos de un barco, este patrón limita las fallas a partes aisladas del sistema para evitar que se propaguen. En el contexto de la computación paralela y distribuida, este patrón puede ser implementado para limitar la cantidad de recursos que un solo cliente o servicio puede consumir, permitiendo así que el sistema mantenga la estabilidad bajo carga.\n",
    "\n",
    "- Sidecar: Este patrón se utiliza para desacoplar aspectos de la infraestructura de los microservicios principales, permitiendo que cada servicio se enfoque en su lógica de negocio. Un proceso sidecar puede manejar funcionalidades como monitoreo, registro, configuración de red, que son esenciales para la computación distribuida y la comunicación entre servicios.\n",
    "\n",
    "- Event Sourcing: En este patrón, los cambios en el estado de la aplicación son registrados como una secuencia de eventos. Esto permite que el sistema sea más resiliente y escalable, facilitando el procesamiento paralelo de eventos y la reconstrucción del estado del sistema a partir de estos eventos si es necesario.\n",
    "  \n",
    "- Sagas: Para manejar transacciones que involucran múltiples microservicios en un entorno distribuido, el patrón de Sagas descompone las transacciones en una serie de operaciones locales en cada servicio. Si una operación falla, se ejecutan compensaciones en los servicios afectados para revertir la transacción.\n",
    "\n",
    "- Edge Server:  actúa como un intermediario entre los clientes externos y tu red de microservicios. Este patrón es particularmente útil para manejar preocupaciones comunes como seguridad, balanceo de carga, autenticación y enrutamiento. El Edge Server puede simplificar la interacción del cliente con el conjunto de microservicios y puede actuar como un punto de control para optimizar las solicitudes antes de que lleguen a los servicios internos.\n",
    "\n",
    "- Reactive Microservices: son diseñados siguiendo los principios de la programación reactiva, lo que significa que son construidos para ser no bloqueantes, orientados a eventos y capaces de manejar un alto grado de procesamiento concurrente y flujos de datos en tiempo real. Esto les permite responder de manera más eficiente a las interacciones con los usuarios o con otros servicios, mejorando el rendimiento y la escalabilidad.\n",
    "\n",
    "- Distributed Tracing:  crucial en arquitecturas de microservicios donde las solicitudes pueden cruzar múltiples servicios antes de completarse. Este patrón ayuda a monitorear y diagnosticar problemas en aplicaciones distribuidas al proporcionar visibilidad en cómo las solicitudes viajan a través de los servicios. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ad901c-f3bd-4ac5-bd7b-a74f41c1334f",
   "metadata": {},
   "source": [
    "#### Ejemplo de implementación de Service Discovery\n",
    "\n",
    "Para este ejemplo, necesitarás tener instalado Flask y requests. Puedes instalarlos mediante pip si no los tienes:\n",
    "\n",
    "pip install Flask requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc7952a-5a62-46c6-844e-708f9ce03198",
   "metadata": {},
   "source": [
    "**Servicio de descubrimiento de servicios**\n",
    "\n",
    "El servicio de descubrimiento mantendrá un registro de las instancias de microservicios y proporcionará un endpoint para que los clientes descubran y se comuniquen con las instancias disponibles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02fd1cee-adf0-4982-9a80-b31b7bf29d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/andersonrojas/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/andersonrojas/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1074, in launch_instance\n",
      "    app.initialize(argv)\n",
      "  File \"/home/andersonrojas/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 118, in inner\n",
      "    return method(app, *args, **kwargs)\n",
      "  File \"/home/andersonrojas/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 692, in initialize\n",
      "    self.init_sockets()\n",
      "  File \"/home/andersonrojas/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 331, in init_sockets\n",
      "    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
      "  File \"/home/andersonrojas/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 253, in _bind_socket\n",
      "    return self._try_bind_socket(s, port)\n",
      "  File \"/home/andersonrojas/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 229, in _try_bind_socket\n",
      "    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
      "  File \"/home/andersonrojas/.local/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 311, in bind\n",
      "    super().bind(addr)\n",
      "  File \"_zmq.py\", line 898, in zmq.backend.cython._zmq.Socket.bind\n",
      "  File \"_zmq.py\", line 160, in zmq.backend.cython._zmq._check_rc\n",
      "zmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:9034')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andersonrojas/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, jsonify, request\n",
    "import requests\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Registro de microservicios disponibles\n",
    "services = {\n",
    "    'microservice_a': ['http://127.0.0.1:5001', 'http://127.0.0.1:5002', 'http://127.0.0.1:5003']\n",
    "}\n",
    "\n",
    "# Endpoint para registrar/desregistrar servicios\n",
    "@app.route('/register', methods=['POST'])\n",
    "def register_service():\n",
    "    data = request.json\n",
    "    if data['action'] == 'register':\n",
    "        if data['service_name'] not in services:\n",
    "            services[data['service_name']] = []\n",
    "        if data['url'] not in services[data['service_name']]:\n",
    "            services[data['service_name']].append(data['url'])\n",
    "    elif data['action'] == 'unregister':\n",
    "        if data['service_name'] in services and data['url'] in services[data['service_name']]:\n",
    "            services[data['service_name']].remove(data['url'])\n",
    "    return jsonify(services)\n",
    "\n",
    "# Endpoint para obtener una instancia disponible\n",
    "@app.route('/discover/<service_name>')\n",
    "def discover_service(service_name):\n",
    "    if service_name in services and services[service_name]:\n",
    "        # Simple round-robin load balancing\n",
    "        url = services[service_name].pop(0)\n",
    "        services[service_name].append(url)\n",
    "        return jsonify({'url': url})\n",
    "    return jsonify({'error': 'No service available'}), 404\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5000, debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6092fa24-aa41-433c-94b2-944e61e62019",
   "metadata": {},
   "source": [
    "**Microservicios**\n",
    "\n",
    "Aquí tienes un ejemplo simple de microservicios que se registran automáticamente en el servicio de descubrimiento cuando se inician."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b4f7ea-8c94-4432-b64c-e4685fb99af8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='127.0.0.1', port=5000): Max retries exceeded with url: /register (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ae1abf616c0>: Failed to establish a new connection: [Errno 111] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py:169\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/util/connection.py:96\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/util/connection.py:86\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     85\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 86\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:700\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 700\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:395\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 395\u001b[0m         \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhttplib_request_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py:234\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    233\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_default_user_agent()\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mHTTPConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1283\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1283\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1329\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1328\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1329\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1278\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1278\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1038\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1038\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1041\u001b[0m \n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:976\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 976\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py:200\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 200\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_conn(conn)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py:181\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7ae1abf616c0>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/adapters.py:439\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 439\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:756\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    754\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 756\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/util/retry.py:574\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    576\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=5000): Max retries exceeded with url: /register (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ae1abf616c0>: Failed to establish a new connection: [Errno 111] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHola desde Microservicio A en \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m service_url\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Registrar en el servicio de descubrimiento\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp://127.0.0.1:5000/register\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mregister\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mservice_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_url\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     app\u001b[38;5;241m.\u001b[39mrun(port\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(service_url\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/api.py:119\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    108\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py:544\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    539\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m'\u001b[39m: allow_redirects,\n\u001b[1;32m    542\u001b[0m }\n\u001b[1;32m    543\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 544\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py:657\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    656\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 657\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    660\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/adapters.py:516\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 516\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=5000): Max retries exceeded with url: /register (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ae1abf616c0>: Failed to establish a new connection: [Errno 111] Connection refused'))"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "import requests\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "service_url = 'http://127.0.0.1:5001'  # Cambia el puerto para cada instancia\n",
    "service_name = 'microservice_a'\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return \"Hola desde Microservicio A en \" + service_url\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Registrar en el servicio de descubrimiento\n",
    "    requests.post('http://127.0.0.1:5000/register', json={'action': 'register', 'service_name': service_name, 'url': service_url})\n",
    "    app.run(port=int(service_url.split(':')[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faee39f6-08fe-4a61-8e9b-2b93c05e3da4",
   "metadata": {},
   "source": [
    "En este ejemplo, el service discovery está implementado de forma muy básica con balanceo de carga round-robin. Cada instancia de microservicio se registra automáticamente al iniciarse.\n",
    "\n",
    "Cuando un cliente quiere interactuar con un microservicio, primero contacta al servicio de descubrimiento para obtener la URL de una instancia activa. Una vez que tiene la URL, el cliente puede enviar directamente sus solicitudes a esa instancia de microservicio.\n",
    "\n",
    "Este flujo asegura que:\n",
    "\n",
    "- Los microservicios pueden registrarse y desregistrarse de manera dinámica.\n",
    "- Los clientes siempre tienen acceso a instancias activas de microservicios.\n",
    "- Las cargas se distribuyen equitativamente entre todas las instancias disponibles.\n",
    "\n",
    "Este enfoque también ayuda a manejar la escalabilidad, ya que nuevas instancias pueden ser añadidas o retiradas sin afectar a los clientes, siempre y cuando utilicen el servicio de descubrimiento para obtener las URLs activas. Además, se puede mejorar la robustez del sistema implementando chequeos de salud regular en cada microservicio, permitiendo que el servicio de descubrimiento retire automáticamente cualquier instancia que no responda adecuadamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc91a6a-d88e-47bf-b563-4d0129bf4966",
   "metadata": {},
   "source": [
    "**Ejecución del código** \n",
    "\n",
    "Servicio de descubrimiento de Servicios:\n",
    "- Guarda el código del servicio de descubrimiento en un archivo, por ejemplo, service_discovery.py.\n",
    "- Ejecuta este archivo en una terminal. Este servicio correrá en el puerto 5000\n",
    "\n",
    "python service_discovery.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443b6a71-0694-40d7-8dfe-676515e71e99",
   "metadata": {},
   "source": [
    "Microservicios:\n",
    "Guarda el código del microservicio en otro archivo, por ejemplo, microservice_a.py.\n",
    "\n",
    "- Modifica la variable service_url para cada instancia que quieras correr. Por ejemplo, puedes usar 5001, 5002, etc., para diferentes instancias.\n",
    "- Ejecuta cada instancia en su propia terminal. Asegúrate de cambiar el puerto cada vez que ejecutes una nueva instancia:\n",
    "\n",
    "python microservice_a.py\n",
    "\n",
    "Repite este paso para cada instancia que desees ejecutar, asegurándote de cambiar service_url para que cada una escuche en un puerto diferente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51507739-a6ba-4ce0-aefa-3210fb9431fe",
   "metadata": {},
   "source": [
    "#### Testeo de funcionamiento\n",
    "\n",
    "Verifica el registro de servicios:\n",
    "\n",
    "- Puedes verificar qué servicios están registrados enviando una solicitud GET a http://127.0.0.1:5000/register. Puedes usar un navegador o herramientas como Postman o curl para esto.\n",
    "\n",
    "Descubrimiento de servicios:\n",
    "\n",
    "- Para obtener la URL de una instancia activa de microservice_a, puedes enviar una solicitud GET a http://127.0.0.1:5000/discover/microservice_a. De nuevo, puedes usar un navegador o herramientas de API para verificar esto.\n",
    "\n",
    "Envía solicitudes a las instancias del microservicio:\n",
    "\n",
    "- Usando la URL proporcionada por el servicio de descubrimiento, puedes enviar solicitudes directamente a las instancias activas del microservicio. Por ejemplo, si obtienes http://127.0.0.1:5001 como respuesta, puedes acceder a esta dirección en tu navegador para ver la respuesta del microservicio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53987aa7-cbb2-4abf-8a16-7f3aa149ec8e",
   "metadata": {},
   "source": [
    "#### Tu participación\n",
    "\n",
    "- ¿Qué es un servicio de descubrimiento en el contexto de microservicios y por qué es crucial para la operación eficiente de una arquitectura basada en microservicios?\n",
    "\n",
    "- Implementa una tercera instancia de microservice_a que escuche en el puerto 5003. Regístrala en el servicio de descubrimiento y verifica que el balanceo de carga funcione correctamente enviando múltiples solicitudes a /discover/microservice_a.\n",
    "  * Modifica microservice_a.py para cambiar el puerto a 5003.\n",
    "  * Ejecuta el servicio y observa cómo se comporta el balanceo de carga.\n",
    "\n",
    "- Simula una falla en una de las instancias del microservicio (por ejemplo, deteniendo el proceso que corre en el puerto 5001) y observa cómo el servicio de descubrimiento maneja la ausencia de la instancia fallida. ¿Continúa dirigiendo solicitudes a la instancia detenida?\n",
    "  * Detén la instancia del microservicio en el puerto 5001.\n",
    "  * Envía solicitudes a /discover/microservice_a y verifica si la instancia detenida sigue siendo ofrecida por el servicio de descubrimiento.\n",
    "\n",
    "- Escribe un script que automáticamente desregistre una instancia del microservicio del servicio de descubrimiento cuando detecte un error o una interrupción en la instancia.\n",
    "    * Implementa una verificación de salud en microservice_a.py.\n",
    "    * Usa una ruta como /health para reportar el estado de salud del servicio.\n",
    "    * Modifica el servicio de descubrimiento para eliminar automáticamente servicios que no pasen la verificación de salud.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2b6a2-416a-4413-814e-d47bf2d47b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify, request\n",
    "import requests\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "services = {\n",
    "    'microservice_a': ['http://127.0.0.1:5001', 'http://127.0.0.1:5002', 'http://127.0.0.1:5003']\n",
    "}\n",
    "\n",
    "@app.route('/register', methods=['POST'])\n",
    "def register_service():\n",
    "    data = request.json\n",
    "    if data['action'] == 'register':\n",
    "        if data['service_name'] not in services:\n",
    "            services[data['service_name']] = []\n",
    "        if data['url'] not in services[data['service_name']]:\n",
    "            services[data['service_name']].append(data['url'])\n",
    "    elif data['action'] == 'unregister':\n",
    "        if data['service_name'] in services and data['url'] in services[data['service_name']]:\n",
    "            services[data['service_name']].remove(data['url'])\n",
    "    return jsonify(services)\n",
    "\n",
    "@app.route('/discover/<service_name>')\n",
    "def discover_service(service_name):\n",
    "    available_services = []\n",
    "    if service_name in services:\n",
    "        for url in services[service_name]:\n",
    "            if requests.get(url + '/health').status_code == 200:\n",
    "                available_services.append(url)\n",
    "        if available_services:\n",
    "            url = available_services.pop(0)\n",
    "            available_services.append(url)\n",
    "            return jsonify({'url': url})\n",
    "    return jsonify({'error': 'No service available'}), 404\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5000, debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf1c836-4507-48ef-ba5c-fb2356026449",
   "metadata": {},
   "source": [
    "### Ejemplo de implementación del Circuit Breaker\n",
    "Primero, crearemos una clase CircuitBreaker para manejar el estado del circuito y la lógica de transición entre estados (cerrado, abierto y semiabierto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564a85d3-9a34-404c-9fbf-e8adad108c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from flask import Flask, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "class CircuitBreaker:\n",
    "    def __init__(self, fail_threshold=3, reset_timeout=10):\n",
    "        self.fail_threshold = fail_threshold\n",
    "        self.reset_timeout = reset_timeout\n",
    "        self.failures = 0\n",
    "        self.last_failure_time = None\n",
    "        self.state = \"closed\"\n",
    "\n",
    "    def call(self, func, *args, **kwargs):\n",
    "        if self.state == \"open\":\n",
    "            if time.time() - self.last_failure_time > self.reset_timeout:\n",
    "                self.state = \"half-open\"\n",
    "            else:\n",
    "                raise Exception(\"Circuit is open. Calls are not allowed.\")\n",
    "        \n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            self.reset()\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self.record_failure()\n",
    "            raise e\n",
    "\n",
    "    def record_failure(self):\n",
    "        self.failures += 1\n",
    "        self.last_failure_time = time.time()\n",
    "        if self.failures >= self.fail_threshold:\n",
    "            self.state = \"open\"\n",
    "\n",
    "    def reset(self):\n",
    "        self.failures = 0\n",
    "        self.state = \"closed\"\n",
    "\n",
    "def unreliable_service():\n",
    "    \"\"\"Simulate a call to an unreliable service.\"\"\"\n",
    "    import random\n",
    "    if random.random() < 0.5:  # 50% chance of failure\n",
    "        raise Exception(\"Service failure.\")\n",
    "    return \"Service response\"\n",
    "\n",
    "breaker = CircuitBreaker()\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    try:\n",
    "        # Make a call through the circuit breaker\n",
    "        response = breaker.call(unreliable_service)\n",
    "        return jsonify({'response': response, 'status': 'success'})\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e), 'status': 'service unavailable'})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5005)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e199a736-c76b-43b6-8c62-b1805507d0de",
   "metadata": {},
   "source": [
    "- CircuitBreaker Class: La clase CircuitBreaker gestiona los estados del circuito. Mantiene un conteo de fallos y cambia el estado del circuito a \"abierto\" si el número de fallos consecutivos excede un umbral definido (fail_threshold). Si el circuito está en estado \"abierto\" y ha pasado suficiente tiempo (reset_timeout), el circuito se moverá al estado \"semiabierto\" en el siguiente intento de llamada.\n",
    "\n",
    "- Función de servicio poco confiable: unreliable_service simula un servicio externo que podría fallar aleatoriamente, lo que es ideal para demostrar el comportamiento del circuit breaker.\n",
    "\n",
    "- Flask App: La aplicación Flask expone una ruta que hace una llamada a través del circuit breaker. Si el circuit breaker está \"abierto\" y no se ha movido a \"semiabierto\" o \"cerrado\", se lanzará una excepción y se devolverá un error al cliente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd557347-fc99-4a9f-aaa2-6ebb0734c1d7",
   "metadata": {},
   "source": [
    "**Ejecución y prueba**\n",
    "\n",
    "- Ejecutar el microservicio: Inicia la aplicación Flask ejecutando el script en tu entorno local. Esto iniciará el servidor en el puerto 5005.\n",
    "- Probar el comportamiento: Usa un navegador o herramientas como curl o Postman para hacer solicitudes a http://localhost:5005/. Podrás observar cómo, después de varios fallos simulados, el circuit breaker se activa, rechazando las llamadas hasta que el tiempo de reinicio haya pasado, y luego intenta una llamada para ver si el servicio se ha recuperado.\n",
    "\n",
    "python circuit_breaker_example.py\n",
    "\n",
    "Abre un navegador web y visita http://localhost:5005/ o utiliza una herramienta como Postman o curl para hacer solicitudes al servidor:\n",
    "\n",
    "curl http://localhost:5005/\n",
    "\n",
    "Observa cómo el circuit breaker responde a fallos simulados y cómo maneja el estado abierto y semiabierto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88c4197-d5b2-4662-8de5-ec9a3e7abbd2",
   "metadata": {},
   "source": [
    "#### Tu participación\n",
    "\n",
    "\n",
    "- ¿Qué representa el estado \"abierto\" en un circuit breaker y cómo afecta a las solicitudes subsecuentes en nuestro ejemplo?\n",
    "- Explica el propósito del estado \"semiabierto\" en un circuit breaker. ¿Cómo decide el circuit breaker pasar del estado \"semiabierto\" a \"cerrado\"?\n",
    "- Cambia el valor de fail_threshold a un número mayor o menor y observa cómo esto afecta la frecuencia con la que el circuito se abre. Documenta tus observaciones.\n",
    "- Agrega una funcionalidad que registre cada cambio de estado en el circuit breaker a un archivo de log. Esto es útil para auditar y depurar el comportamiento del sistema.\n",
    "- Modifica la función unreliable_service para que después de un número específico de fallos, garantice un éxito. Esto simulará un servicio que se recupera después de ciertas fallas. Observa cómo el circuit breaker maneja esta recuperación.\n",
    "- Experimenta con diferentes valores para reset_timeout y evalúa cómo el tiempo de inactividad afecta la disponibilidad percibida del servicio. Considera escenarios de alta y baja carga en tus pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19faa852-b920-4d52-b474-d58029d6940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from flask import Flask, jsonify\n",
    "import logging\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "logging.basicConfig(filename='circuit_breaker.log', level=logging.INFO)\n",
    "\n",
    "def record_failure(self):\n",
    "    self.failures += 1\n",
    "    self.last_failure_time = time.time()\n",
    "    if self.failures >= self.fail_threshold:\n",
    "        self.state = \"open\"\n",
    "        logging.info(f'Circuit opened at {self.last_failure_time}')\n",
    "\n",
    "class CircuitBreaker:\n",
    "    def __init__(self, fail_threshold=3, reset_timeout=10):\n",
    "        self.fail_threshold = fail_threshold\n",
    "        self.reset_timeout = reset_timeout\n",
    "        self.failures = 0\n",
    "        self.last_failure_time = None\n",
    "        self.state = \"closed\"\n",
    "    \n",
    "    def call(self, func, *args, **kwargs):\n",
    "        if self.state == \"open\":\n",
    "            if time.time() - self.last_failure_time > self.reset_timeout:\n",
    "                self.state = \"half-open\"\n",
    "            else:\n",
    "                raise Exception(\"Circuit is open. Calls are not allowed.\")\n",
    "        \n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            self.reset()\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self.record_failure()\n",
    "            raise e\n",
    "\n",
    "    def record_failure(self):\n",
    "        self.failures += 1\n",
    "        self.last_failure_time = time.time()\n",
    "        if self.failures >= self.fail_threshold:\n",
    "            self.state = \"open\"\n",
    "\n",
    "    def reset(self):\n",
    "        self.failures = 0\n",
    "        self.state = \"closed\"\n",
    "\n",
    "failure_count = 0\n",
    "\n",
    "def unreliable_service():\n",
    "    global failure_count\n",
    "    failure_count += 1\n",
    "    if failure_count > 5:  # Garantiza un éxito después de 5 fallos\n",
    "        failure_count = 0\n",
    "        return \"Service response\"\n",
    "    raise Exception(\"Service failure.\")\n",
    "\n",
    "\n",
    "breaker = CircuitBreaker(fail_threshold=3, reset_timeout=30)  # Incrementa o disminuye el timeout\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    try:\n",
    "        # Make a call through the circuit breaker\n",
    "        response = breaker.call(unreliable_service)\n",
    "        return jsonify({'response': response, 'status': 'success'})\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e), 'status': 'service unavailable'})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5005)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b6feaa-76bf-49f9-a3f5-612face4296a",
   "metadata": {},
   "source": [
    "### Ejemplo de implementación del Bulkhead\n",
    "\n",
    "El patrón Bulkhead es utilizado en el diseño de sistemas para aislar fallos y limitar su propagación dentro de un sistema más grande. En el contexto de la programación paralela o distribuida, el patrón Bulkhead puede ser usado para limitar el número de recursos (como hilos o conexiones de red) que una parte del sistema puede consumir, previniendo así que un problema en una parte del sistema afecte al resto.\n",
    "\n",
    "Para ilustrar el patrón Bulkhead en Python, podemos simular un escenario donde diferentes tareas o servicios compiten por recursos limitados. Utilizaremos el módulo concurrent.futures para manejar tareas asincrónicas con un número limitado de trabajadores y  limitar la cantidad de recursos utilizados por cada tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21279a5a-9d6b-433e-90dc-73fd4b589d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "# Función que simula una tarea que puede fallar o tardar mucho\n",
    "def task(id, duration):\n",
    "    try:\n",
    "        print(f\"Iniciando tarea {id} que tardará {duration} segundos.\")\n",
    "        time.sleep(duration)  # Simula tiempo de procesamiento\n",
    "        print(f\"Tarea {id} completada.\")\n",
    "        return f\"Resultado de la tarea {id}\"\n",
    "    except Exception as e:\n",
    "        return f\"Tarea {id} falló: {str(e)}\"\n",
    "\n",
    "# Función principal que ejecuta tareas utilizando un Bulkhead\n",
    "def main():\n",
    "    # Usar ThreadPoolExecutor como un Bulkhead\n",
    "    # Limitamos el número de tareas simultáneas a 3\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        # Simulamos la recepción de tareas con diferentes duraciones\n",
    "        tasks = {executor.submit(task, i, duration): i for i, duration in enumerate([2, 3, 5, 1, 4])}\n",
    "        for future in concurrent.futures.as_completed(tasks):\n",
    "            task_id = tasks[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                print(f\"Tarea {task_id} completada con resultado: {result}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Tarea {task_id} generó una excepción: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796990b6-041c-465c-b871-83d7ac2e2424",
   "metadata": {},
   "source": [
    "Explicación del código:\n",
    "\n",
    "- Función de tarea (task): Esta función representa una tarea individual que podría tardar un tiempo variable en completarse, simbolizado por la llamada a time.sleep(). La función imprime mensajes al comenzar y completar la tarea.\n",
    "- Ejecución de Tareas (main): En la función principal, utilizamos ThreadPoolExecutor de concurrent.futures para simular el patrón Bulkhead. Se establece un máximo de tres trabajadores (hilos) para manejar las tareas, limitando así el número de tareas que se ejecutan en paralelo.\n",
    "- Gestión de tareas: Las tareas se agregan al ejecutor y se monitorean hasta su completación. El executor.submit inicia la tarea, y as_completed maneja las tareas conforme van terminando. Cada tarea se identifica y se manejan excepciones potenciales que podrían surgir durante su ejecución."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd978217-f764-419c-9a8d-d943ed7c092b",
   "metadata": {},
   "source": [
    "Ejecución del código:\n",
    "\n",
    "python bulkhead_example.py\n",
    "\n",
    "* Asegúrate de usar python3 en lugar de python si tienes múltiples versiones de Python instaladas y python no se refiere a Python 3.x.\n",
    "* Después de ejecutar el script, verás en la terminal la salida del programa, mostrando cuándo cada tarea comienza y termina, y cómo el sistema maneja múltiples tareas simultáneamente limitadas a un máximo de tres en ejecución paralela.\n",
    "* La salida te dará una idea clara de cómo el patrón Bulkhead está limitando el número de tareas concurrentes para prevenir la sobrecarga del sistema y mejorar el manejo de recurso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb834bf-b01e-4779-8d75-39d1775e25b5",
   "metadata": {},
   "source": [
    "#### Tu participación\n",
    "\n",
    "- Explica cómo el patrón Bulkhead contribuye a la resiliencia de un sistema de microservicios. ¿Cómo previene que fallos en una parte del sistema afecten al resto del sistema?\n",
    "- Compara el patrón Bulkhead con el patrón Circuit Breaker. ¿En qué situaciones es preferible uno sobre el otro?\n",
    "- Discute los posibles riesgos de no implementar el patrón Bulkhead en un sistema que maneja múltiples tareas o solicitudes concurrentes.\n",
    "- ¿Cómo influiría la implementación del patrón Bulkhead en el diseño de una nueva aplicación de software? Considera aspectos como la escalabilidad, mantenibilidad y la gestión de fallos.\n",
    "- Modifica el número de trabajadores (max_workers) en el ThreadPoolExecutor y observa cómo afecta el rendimiento y la capacidad de respuesta del sistema. Documenta los resultados con diferentes configuraciones.\n",
    "- Mejora el manejo de excepciones en el código para asegurarte de que ninguna tarea pueda causar un fallo en el sistema completo. Implementa registros detallados de los errores para facilitar la depuración.\n",
    "- Escribe un script que genere un número muy alto de tareas simultáneas y utiliza el patrón Bulkhead para manejar adecuadamente esta carga. Observa y documenta cómo el sistema maneja la sobrecarga.\n",
    "- Integra funcionalidades de monitorización para rastrear el tiempo de ejecución de cada tarea y el uso de recursos del sistema. Utiliza esta información para ajustar dinámicamente el número de hilos en el ThreadPoolExecutor.\n",
    "- Combina el patrón Bulkhead con el patrón Circuit Breaker para manejar mejor las tareas que fallan repetidamente. Implementa lógica para que, después de cierto número de fallos consecutivos, el sistema deje de intentar ejecutar una tarea fallida durante un período de tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f63985d7-e6ff-495a-94bd-1f5b29e46c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 22:45:26,018 - INFO - Iniciando tarea 0 que tardará 1 segundos.\n",
      "2024-05-09 22:45:26,022 - INFO - Iniciando tarea 1 que tardará 2 segundos.\n",
      "2024-05-09 22:45:26,023 - INFO - Iniciando tarea 2 que tardará 3 segundos.\n",
      "2024-05-09 22:45:26,027 - INFO - Iniciando tarea 3 que tardará 4 segundos.\n",
      "2024-05-09 22:45:26,028 - INFO - Iniciando tarea 4 que tardará 5 segundos.\n",
      "2024-05-09 22:45:27,021 - INFO - Iniciando tarea 5 que tardará 6 segundos.\n",
      "2024-05-09 22:45:27,022 - ERROR - Tarea 0 falló.\n",
      "2024-05-09 22:45:28,025 - INFO - Tarea 1 completada.\n",
      "2024-05-09 22:45:28,025 - INFO - Resultado de la tarea 1\n",
      "2024-05-09 22:45:29,026 - ERROR - Tarea 2 falló.\n",
      "2024-05-09 22:45:30,041 - INFO - Tarea 3 completada.\n",
      "2024-05-09 22:45:30,044 - INFO - Resultado de la tarea 3\n",
      "2024-05-09 22:45:31,053 - ERROR - Tarea 4 falló.\n",
      "2024-05-09 22:45:33,026 - INFO - Tarea 5 completada.\n",
      "2024-05-09 22:45:33,027 - INFO - Resultado de la tarea 5\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "import concurrent.futures\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def task(id, duration):\n",
    "    logging.info(f\"Iniciando tarea {id} que tardará {duration} segundos.\")\n",
    "    time.sleep(duration)\n",
    "    if id % 2 == 0:\n",
    "        raise Exception(f\"Tarea {id} falló.\")\n",
    "    logging.info(f\"Tarea {id} completada.\")\n",
    "    return f\"Resultado de la tarea {id}\"\n",
    "\n",
    "def main():\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        futures = []\n",
    "        for i in range(6):\n",
    "            future = executor.submit(task, i, i+1)\n",
    "            futures.append(future)\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                logging.info(result)\n",
    "            except Exception as e:\n",
    "                logging.error(str(e))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf0ae03-d73b-4f79-9825-e5c05ba78de6",
   "metadata": {},
   "source": [
    "### Ejemplo de implementación del Sidecar \n",
    "En este ejemplo, tendrás un servicio principal que realiza alguna funcionalidad básica y un sidecar que se encargará de hacer el logging de las actividades del servicio principal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ecb89-dc60-4844-a8ab-8e1732ed703f",
   "metadata": {},
   "source": [
    "El servicio principal será una simple aplicación Flask que expone un endpoint API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3c4d0df-6cdb-4a9f-9f88-5a28bf48014c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 22:45:39,630 - INFO - \u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "2024-05-09 22:45:39,631 - INFO - \u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "2024-05-09 22:45:42,255 - INFO - 127.0.0.1 - - [09/May/2024 22:45:42] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return jsonify({\"message\": \"Hello from the main service!\"})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e90dadc-db30-4e11-85a8-d0f03e02237e",
   "metadata": {},
   "source": [
    "El sidecar será responsable de revisar y registrar las solicitudes realizadas al servicio principal. Utilizaremos aiohttp para crear un pequeño servidor web que actúe como un proxy, registrando cada solicitud que pase hacia el servicio principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c1722bd-4fce-4095-8748-a7dc287dc9d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot run the event loop while another loop is running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/aiohttp/web.py:544\u001b[0m, in \u001b[0;36mrun_app\u001b[0;34m(app, host, port, path, sock, shutdown_timeout, keepalive_timeout, ssl_context, print, backlog, access_log_class, access_log_format, access_log, handle_signals, reuse_address, reuse_port, handler_cancellation, loop)\u001b[0m\n\u001b[1;32m    543\u001b[0m     asyncio\u001b[38;5;241m.\u001b[39mset_event_loop(loop)\n\u001b[0;32m--> 544\u001b[0m     \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain_task\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (GracefulExit, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/base_events.py:625\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m--> 625\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m new_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m futures\u001b[38;5;241m.\u001b[39misfuture(future)\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/base_events.py:586\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 586\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    587\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot run the event loop while another loop is running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot run the event loop while another loop is running",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m app\u001b[38;5;241m.\u001b[39mrouter\u001b[38;5;241m.\u001b[39madd_route(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, handler)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mweb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_app\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/aiohttp/web.py:548\u001b[0m, in \u001b[0;36mrun_app\u001b[0;34m(app, host, port, path, sock, shutdown_timeout, keepalive_timeout, ssl_context, print, backlog, access_log_class, access_log_format, access_log, handle_signals, reuse_address, reuse_port, handler_cancellation, loop)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m--> 548\u001b[0m     \u001b[43m_cancel_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mmain_task\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m     _cancel_tasks(asyncio\u001b[38;5;241m.\u001b[39mall_tasks(loop), loop)\n\u001b[1;32m    550\u001b[0m     loop\u001b[38;5;241m.\u001b[39mrun_until_complete(loop\u001b[38;5;241m.\u001b[39mshutdown_asyncgens())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/aiohttp/web.py:473\u001b[0m, in \u001b[0;36m_cancel_tasks\u001b[0;34m(to_cancel, loop)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m to_cancel:\n\u001b[1;32m    471\u001b[0m     task\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[0;32m--> 473\u001b[0m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mto_cancel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m to_cancel:\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m task\u001b[38;5;241m.\u001b[39mcancelled():\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/base_events.py:625\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run until the Future is done.\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \n\u001b[1;32m    616\u001b[0m \u001b[38;5;124;03mIf the argument is a coroutine, it is wrapped in a Task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03mReturn the Future's result, or raise its exception.\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m--> 625\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m new_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m futures\u001b[38;5;241m.\u001b[39misfuture(future)\n\u001b[1;32m    628\u001b[0m future \u001b[38;5;241m=\u001b[39m tasks\u001b[38;5;241m.\u001b[39mensure_future(future, loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/base_events.py:586\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 586\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    587\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot run the event loop while another loop is running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot run the event loop while another loop is running"
     ]
    }
   ],
   "source": [
    "from flask import Flask, jsonify\n",
    "import aiohttp\n",
    "from aiohttp import web\n",
    "import asyncio\n",
    "\n",
    "async def handler(request):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        # Proxear la solicitud al servicio principal\n",
    "        async with session.get('http://localhost:5000') as response:\n",
    "            data = await response.json()\n",
    "            print(f\"Logging request: {data}\")  # Simula el registro de la solicitud\n",
    "            return web.json_response(data)\n",
    "\n",
    "app = web.Application()\n",
    "app.router.add_route('GET', '/', handler)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    web.run_app(app, port=5001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c84a3-629e-4293-944f-926e1698409d",
   "metadata": {},
   "source": [
    "Explicación del código:\n",
    "\n",
    "- Servicio principal: Se ejecuta en el puerto 5000 y simplemente devuelve un mensaje de bienvenida. Este servicio representa cualquier microservicio en una arquitectura más grande que realiza operaciones específicas del negocio.\n",
    "\n",
    "- Sidecar: Se ejecuta en el puerto 5001 y actúa como un proxy hacia el servicio principal. Captura cada solicitud y realiza el registro (logging) antes de pasar la solicitud al servicio principal. Este ejemplo ilustra cómo un sidecar puede ser usado para offload tareas como logging y monitorización, liberando al servicio principal para que se enfoque en sus funcionalidades principales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e724de6-cf42-4805-92c1-4d24d3048e70",
   "metadata": {},
   "source": [
    "Ejecución y prueba del sistema\n",
    "\n",
    "- Ejecutar el servicio principal: Guarda el código en un archivo, por ejemplo main_service.py, y ejecútalo usando Python.\n",
    "- Ejecutar el Sidecar: Guarda el código del sidecar en otro archivo, por ejemplo sidecar.py, y ejecútalo en un terminal diferente.\n",
    "\n",
    "Para probar que todo está funcionando, puedes hacer una solicitud HTTP al sidecar:\n",
    " curl http://localhost:5001/\n",
    "\n",
    "Deberías ver que el sidecar registra la solicitud y luego pasa la respuesta del servicio principal.\n",
    "\n",
    "**Observación:** Este es un ejemplo muy simplificado del patrón Sidecar. En un entorno real, especialmente en entornos basados en contenedores como Kubernetes, los sidecars pueden ser más complejos y manejar tareas más críticas, aprovechando la proximidad al servicio principal para mejorar la eficiencia y la seguridad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d31986d-37a3-481c-8c77-5e9854dc0e94",
   "metadata": {},
   "source": [
    "#### Tu participación\n",
    "\n",
    "- ¿Qué es el patrón Sidecar y cómo se diferencia de otros patrones arquitectónicos en microservicios?\n",
    "- ¿Cuáles son las ventajas de usar un Sidecar en comparación con incorporar funcionalidades directamente en el servicio principal?\n",
    "- Identifica y describe tres escenarios de uso real donde el patrón Sidecar podría ser especialmente beneficioso en una arquitectura de microservicios.\n",
    "- Discute cómo el patrón Sidecar puede mejorar la resiliencia y la escalabilidad de una aplicación distribuida.\n",
    "- ¿Cómo se implementa típicamente el patrón Sidecar en entornos basados en contenedores como Kubernetes? Describe el proceso y los beneficios.\n",
    "- Basándote en el ejemplo proporcionado, expande el sidecar para que no solo registre las solicitudes, sino también las respuestas del servicio principal. Asegúrate de capturar detalles como el tiempo de respuesta y el código de estado.\n",
    "- Desarrolla un Sidecar que periódicamente verifique la salud del servicio principal y registre el estado. Implementa notificaciones (por ejemplo, a través de un simple print o guardando en un archivo) si el servicio principal no responde adecuadamente.\n",
    "- Modifica el Sidecar para que simule la introducción de fallas en el servicio principal bajo ciertas condiciones (por ejemplo, cada diez solicitudes) y prueba cómo el sistema maneja y se recupera de tales fallas.\n",
    "- Crea un Sidecar que funcione como un proxy avanzado, implementando características como la autenticación y el balanceo de carga entre múltiples instancias del servicio principal.\n",
    "- Implementa un Sidecar que cache las respuestas del servicio principal para mejorar la eficiencia y reducir la carga. El Sidecar debería verificar si una solicitud tiene una respuesta válida en caché y servirla inmediatamente sin redirigir la solicitud al servicio principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d438ad9-abe7-4f78-b114-f8c19b1b1d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#salud\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def check_health(service_url):\n",
    "    try:\n",
    "        response = requests.get(service_url)\n",
    "        if response.status_code == 200:\n",
    "            print(\"Servicio principal en buen estado.\")\n",
    "        else:\n",
    "            print(\"Servicio principal con problemas.\")\n",
    "    except requests.exceptions.RequestException:\n",
    "        print(\"Servicio principal no accesible.\")\n",
    "\n",
    "def main():\n",
    "    service_url = 'http://localhost:5000/health'\n",
    "    while True:\n",
    "        check_health(service_url)\n",
    "        time.sleep(10)  # Verifica cada 10 segundos\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "#fallas\n",
    "import requests\n",
    "import random\n",
    "\n",
    "def possibly_fail_request(service_url):\n",
    "    if random.randint(1, 10) == 1:  # 10% de probabilidad de falla\n",
    "        print(\"Introduciendo una falla en el sistema.\")\n",
    "        requests.get(service_url + \"/fail\")  # Endpoint que causa una falla\n",
    "    else:\n",
    "        response = requests.get(service_url)\n",
    "        print(\"Respuesta normal del servicio principal.\")\n",
    "\n",
    "def main():\n",
    "    service_url = 'http://localhost:5000'\n",
    "    while True:\n",
    "        possibly_fail_request(service_url)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "#3. Sidecar como Proxy Avanzado\n",
    "from flask import Flask, request, jsonify\n",
    "import requests\n",
    "import itertools\n",
    "\n",
    "app = Flask(__name__)\n",
    "services = ['http://localhost:5001', 'http://localhost:5002']\n",
    "service_cycle = itertools.cycle(services)\n",
    "\n",
    "@app.route('/<path:path>', methods=['GET', 'POST'])\n",
    "def proxy(path):\n",
    "    service_url = next(service_cycle)\n",
    "    if request.method == 'GET':\n",
    "        resp = requests.get(f'{service_url}/{path}')\n",
    "    elif request.method == 'POST':\n",
    "        resp = requests.post(f'{service_url}/{path}', json=request.get_json())\n",
    "    return jsonify(resp.json())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(port=5003)\n",
    "\n",
    "#4 catching\n",
    "from flask import Flask, request, jsonify\n",
    "import requests\n",
    "\n",
    "app = Flask(__name__)\n",
    "cache = {}\n",
    "\n",
    "@app.route('/<path:path>', methods=['GET'])\n",
    "def cached_proxy(path):\n",
    "    if path in cache:\n",
    "        print(\"Sirviendo desde caché.\")\n",
    "        return jsonify(cache[path])\n",
    "    else:\n",
    "        response = requests.get(f'http://localhost:5000/{path}')\n",
    "        cache[path] = response.json()\n",
    "        print(\"Caché actualizado y sirviendo respuesta fresca.\")\n",
    "        return jsonify(cache[path])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(port=5004)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a381919-42ef-43db-b3be-ddea5cb4fd47",
   "metadata": {},
   "source": [
    "### Ejemplo de implementación de Edge Server\n",
    "\n",
    "Para ilustrar el patrón de servidor perimetral (Edge Server) utilizando Python, podemos utilizar Flask para crear un simple servidor perimetral que actúa como un proxy inverso y también Flask para los microservicios internos. Vamos a simular un escenario donde el servidor perimetral controla el acceso a tres microservicios, protegiéndolos de solicitudes externas no autorizadas y realizando un balanceo de carga simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0bac65-a3b4-44ab-8dbf-2ed4454804a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, abort\n",
    "import requests\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Configuración de los microservicios internos\n",
    "services = {\n",
    "    'microservice_a': 'http://localhost:5001',\n",
    "    'microservice_b': 'http://localhost:5002',\n",
    "    'microservice_c': 'http://localhost:5003'\n",
    "}\n",
    "\n",
    "# Función de autenticación de ejemplo\n",
    "def authenticate_request(api_key):\n",
    "    # Simular la autenticación con una clave API\n",
    "    return api_key == \"secret\"\n",
    "\n",
    "@app.route('/<service>', methods=['GET', 'POST'])\n",
    "def proxy(service):\n",
    "    if service not in services:\n",
    "        return jsonify({\"error\": \"Service not found\"}), 404\n",
    "\n",
    "    if not authenticate_request(request.headers.get('X-API-Key')):\n",
    "        return jsonify({\"error\": \"Unauthorized\"}), 401\n",
    "\n",
    "    service_url = services[service]\n",
    "    response = requests.request(\n",
    "        method=request.method,\n",
    "        url=f\"{service_url}{request.full_path}\",\n",
    "        headers={key: value for key, value in request.headers if key != 'Host'},\n",
    "        data=request.get_data(),\n",
    "        allow_redirects=False)\n",
    "\n",
    "    return (response.content, response.status_code, response.headers.items())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa613f-834c-4853-86aa-17afd0ddba24",
   "metadata": {},
   "source": [
    "Aquí hay un ejemplo de cómo podría lucir un microservicio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e6e315-b5cb-47e6-9d52-fb99caa09b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return jsonify({\"message\": \"Hello from Microservice A\"})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5001)  # Cambia el puerto para B y C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fda2dc-dc15-47ca-a46b-2c977f2daa10",
   "metadata": {},
   "source": [
    "Repite el mismo código para Microservice B y C, cambiando el mensaje y el puerto (5002 para B, 5003 para C).\n",
    "\n",
    "Explicación del código\n",
    "\n",
    "- Servidor Perimetral: El servidor perimetral actúa como un proxy inverso, manejando todas las solicitudes entrantes. Solo redirige solicitudes a servicios específicos configurados y autentica las solicitudes utilizando una clave API simple.\n",
    "- Autenticación: Se realiza mediante la función authenticate_request, que comprueba si la clave API proporcionada en la cabecera X-API-Key es válida.\n",
    "- Proxying Requests: Las solicitudes se reenvían al microservicio correspondiente, incluyendo la manipulación de los métodos HTTP, parámetros y cabeceras.\n",
    "- Microservicios internos: Cada microservicio simplemente devuelve un mensaje. Estos servicios están configurados para ejecutarse en diferentes puertos y no son accesibles directamente desde el exterior sin pasar por el servidor perimetral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed21ae7-b210-4784-94b2-80a1ad94fb49",
   "metadata": {},
   "source": [
    "**Implementación del código**\n",
    "\n",
    "- Guarda el código del servidor perimetral en un archivo, por ejemplo, edge_server.py.\n",
    "- Guarda el código de cada microservicio en archivos separados, por ejemplo, microservice_a.py, microservice_b.py, y microservice_c.py.\n",
    "- Ejecuta el servidor perimetral:\n",
    "  python edge_server.py\n",
    "    Esto iniciará el servidor perimetral en localhost en el puerto 5000.\n",
    "- Abre terminales separadas para cada microservicio.\n",
    "- Navega al directorio donde están guardados los archivos de los microservicios.\n",
    "- Ejecuta cada microservicio en un puerto diferente:\n",
    "\n",
    "  ```\n",
    "  python microservice_a.py  # se ejecutará en el puerto 5001\n",
    "  python microservice_b.py  # se ejecutará en el puerto 5002\n",
    "  python microservice_c.py  # se ejecutará en el puerto 5003\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d904f52-187a-44c6-adcc-dfd3a8dc5ce8",
   "metadata": {},
   "source": [
    "**Probar el sistema** \n",
    "\n",
    "* Puedes usar un navegador web o una herramienta como cURL para hacer solicitudes al servidor perimetral. Asegúrate de incluir la clave API correcta en las cabeceras de la solicitud para autenticar:\n",
    "\n",
    " ```\n",
    "   curl -H \"X-API-Key: secret\" http://localhost:5000/microservice_a\n",
    "   curl -H \"X-API-Key: secret\" http://localhost:5000/microservice_b\n",
    "   curl -H \"X-API-Key: secret\" http://localhost:5000/microservice_c\n",
    " ```\n",
    "* Intenta enviar solicitudes sin la clave API o con una clave incorrecta para ver cómo el servidor perimetral maneja la autenticación:\n",
    "\n",
    "  ```\n",
    "    curl http://localhost:5000/microservice_a  # Debería fallar con 401 Unauthorized\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ceab23-ed94-443e-95d9-e8b1410f8681",
   "metadata": {},
   "source": [
    "#### Tu participación\n",
    "\n",
    "- ¿Qué funciones realiza un servidor perimetral (Edge Server) en una arquitectura de microservicios? ¿Por qué es crucial para la seguridad y la gestión del tráfico?\n",
    "- Compara el servidor perimetral con el API Gateway. ¿Cuáles son las similitudes y diferencias clave entre estos dos patrones?\n",
    "- ¿Cómo puede un servidor perimetral ayudar a prevenir ataques comunes como DDoS, SQL Injection, y Cross-Site Scripting (XSS)?\n",
    "- ¿Cómo contribuye un servidor perimetral al escalado de aplicaciones en un entorno de microservicios? Considera escenarios con alto . - --- ¿Cómo puede diseñarse un servidor perimetral para manejar fallas en los microservicios a los que redirige? Considera técnicas como el - \n",
    "- Modifica el servidor perimetral para utilizar JSON Web Tokens (JWT) en lugar de claves API simples para la autenticación. Implementa un endpoint que emita tokens JWT a los clientes después de una autenticación exitosa basada en nombre de usuario y contraseña.\n",
    "- Agrega capacidades de logging avanzadas al servidor perimetral. Asegúrate de registrar todas las solicitudes entrantes, incluyendo detalles como la dirección IP del solicitante, la hora de la solicitud, y la respuesta del microservicio. Configura el logging para que los datos se escriban en un archivo en un formato que facilite el análisis posterior.\n",
    "- Implementa una funcionalidad en el servidor perimetral que permita modificar dinámicamente las rutas o los microservicios a los que se redirigen las solicitudes sin necesidad de reiniciar el servidor. Esto podría involucrar la lectura de un archivo de configuración o consultar una base de datos de rutas en tiempo real.\n",
    "- [Opcional] Escribe un middleware para el servidor perimetral que analice la carga de tráfico y tome decisiones inteligentes sobre cuándo rechazar nuevas conexiones o redirigirlas a otros servidores para balancear la carga.\n",
    "- [Opcional] Desarrolla un script que simule un ataque DDoS al servidor perimetral y luego mejora el servidor perimetral para manejar eficazmente tales ataques, por ejemplo, implementando límites de tasa o desafíos CAPTCHA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239e47cd-cbb2-4144-b809-179e3936afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementación de JWT y Endpoint de Autenticación\n",
    "from flask import Flask, jsonify, request\n",
    "import jwt\n",
    "import datetime\n",
    "\n",
    "app = Flask(__name__)\n",
    "SECRET_KEY = \"your_secret_key\"\n",
    "\n",
    "@app.route('/token', methods=['POST'])\n",
    "def create_token():\n",
    "    username = request.json.get('username')\n",
    "    password = request.json.get('password')\n",
    "    if username == \"admin\" and password == \"password\":  # Esta es una simplificación\n",
    "        payload = {\n",
    "            'exp': datetime.datetime.utcnow() + datetime.timedelta(hours=24),\n",
    "            'iat': datetime.datetime.utcnow(),\n",
    "            'sub': username\n",
    "        }\n",
    "        token = jwt.encode(payload, SECRET_KEY, algorithm='HS256')\n",
    "        return jsonify({'token': token})\n",
    "    else:\n",
    "        return jsonify({'message': 'Invalid credentials'}), 401\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609d1d2a-8351-4ce6-afa1-5b6e4c71d61e",
   "metadata": {},
   "source": [
    "### Ejemplo de implementación de microservicios reactivos\n",
    "\n",
    "Primero, necesitas instalar las bibliotecas necesarias. Si no tienes instalado aiohttp, puedes hacerlo con pip:\n",
    "\n",
    "pip install aiohttp\n",
    "\n",
    "Presentamos un ejemplo de cómo podrías implementar un microservicio utilizando aiohttp para manejar las solicitudes de forma asincrónica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed627f6-d576-4158-8c97-9a70e674f31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiohttp import web, ClientSession\n",
    "import asyncio\n",
    "\n",
    "async def fetch_data(url):\n",
    "    \"\"\"Función asincrónica para obtener datos de otro servicio.\"\"\"\n",
    "    async with ClientSession() as session:\n",
    "        async with session.get(url) as response:\n",
    "            return await response.text()\n",
    "\n",
    "async def handle_request(request):\n",
    "    \"\"\"Manejador que simula la llamada a otro microservicio.\"\"\"\n",
    "    data_url = \"http://example.com/data\"  # URL del servicio de datos\n",
    "    data = await fetch_data(data_url)\n",
    "    return web.Response(text=f\"Data from other service: {data}\")\n",
    "\n",
    "async def service_health(request):\n",
    "    \"\"\"Endpoint para chequear la salud del servicio.\"\"\"\n",
    "    return web.Response(text=\"Service is up and running!\")\n",
    "\n",
    "app = web.Application()\n",
    "app.add_routes([web.get('/', handle_request),\n",
    "                web.get('/health', service_health)])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    web.run_app(app, port=8080)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c2dbed-bd54-46b0-b345-647189183968",
   "metadata": {},
   "source": [
    "Descripción del código\n",
    "\n",
    "- fetch_data: Esta función asincrónica realiza solicitudes HTTP a otro servicio. Utiliza aiohttp.ClientSession para manejar las conexiones de manera eficiente y asincrónica.\n",
    "- handle_request: Es un manejador para las solicitudes entrantes que, a su vez, hace una llamada a otro microservicio. La llamada es no bloqueante y espera asincrónicamente por la respuesta.\n",
    "- service_health: Un simple endpoint para verificar la salud del servicio, útil para implementaciones de microservicios que necesitan ser monitoreados y mantenidos.\n",
    "- Se configura una aplicación de aiohttp y se añaden rutas para manejar las solicitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f4f9fc-70b8-4173-833f-4b80fca4e74b",
   "metadata": {},
   "source": [
    "Ejecución del código\n",
    "\n",
    "- Abre una terminal en la carpeta donde guardaste el archivo reactive_microservice.py.\n",
    "- Ejecuta el archivo con Python mediante el siguiente comando:\n",
    "\n",
    "  python reactive_microservice.py\n",
    "\n",
    "Este comando iniciará el servidor web en el puerto 8080.\n",
    "\n",
    "Una vez que el servidor esté en ejecución, puedes probar el microservicio utilizando un navegador o una herramienta como curl. Aquí tienes cómo puedes hacerlo:\n",
    "\n",
    "- Probar el endpoint principal:Abre tu navegador y visita http://localhost:8080/ o usa curl en la terminal:\n",
    "  curl http://localhost:8080/\n",
    "\n",
    "Esto debería ejecutar la función handle_request que a su vez hará una llamada al URL especificado en data_url (asegúrate de que data_url apunte a un servicio válido o simula uno para pruebas).\n",
    "\n",
    "- Probar el endpoint de salud:Puedes verificar si el servicio está funcionando correctamente visitando http://localhost:8080/health o usando curl:\n",
    "\n",
    "    curl http://localhost:8080/health\n",
    "\n",
    "Esto debería devolver el mensaje \"Service is up and running!\"\n",
    "\n",
    "Consideraciones\n",
    "\n",
    "- Asegúrate de que el puerto 8080 esté libre o cambia el puerto en el código si es necesario.\n",
    "- El URL data_url en la función fetch_data debe apuntar a un destino válido que responda a solicitudes HTTP GET, o debes simular uno para pruebas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204da358-2488-4c03-843f-c7e6111c7acf",
   "metadata": {},
   "source": [
    "#### Tu participación\n",
    "\n",
    "- ¿Cómo contribuye el modelo asincrónico a la resiliencia y escalabilidad de los microservicios comparado con un modelo sincrónico tradicional?\n",
    "- Explica cómo los microservicios pueden ser diseñados para ser autorreparables y qué estrategias se podrían implementar para lograrlo.\n",
    "- Modifica el microservicio para que haga llamadas paralelas a múltiples servicios en handle_request, utilizando asyncio.gather para combinar los resultados y responder una vez que todas las respuestas estén disponibles.\n",
    "- Implementa un mecanismo de reintento en fetch_data para manejar fallos temporales, donde el servicio intenta nuevamente la solicitud después de un breve retraso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb19217-1a28-490b-9127-042e824b9288",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Llamadas Paralelas con asyncio.gather\n",
    "async def handle_request(request):\n",
    "    \"\"\"Manejador que realiza llamadas paralelas a múltiples servicios.\"\"\"\n",
    "    service_urls = [\"http://example.com/data1\", \"http://example.com/data2\"]\n",
    "    responses = await asyncio.gather(*(fetch_data(url) for url in service_urls))\n",
    "    combined_data = \" \".join(responses)\n",
    "    return web.Response(text=f\"Combined data from services: {combined_data}\")\n",
    "\n",
    "##Mecanismo de Reintento en fetch_data\n",
    "async def fetch_data(url, attempts=3, delay=2):\n",
    "    \"\"\"Función asincrónica que reintenta obtener datos de otro servicio en caso de fallo.\"\"\"\n",
    "    async with ClientSession() as session:\n",
    "        try:\n",
    "            async with session.get(url, timeout=10) as response:\n",
    "                response.raise_for_status()\n",
    "                return await response.text()\n",
    "        except Exception as e:\n",
    "            if attempts > 1:\n",
    "                await asyncio.sleep(delay)  # Esperar antes de reintentar\n",
    "                return await fetch_data(url, attempts - 1, delay * 2)  # Aumentar el retraso\n",
    "            else:\n",
    "                return f\"Failed after retries: {str(e)}\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef0c674-a583-49c2-a075-bf8c76ec58c6",
   "metadata": {},
   "source": [
    "### Ejemplo de implementación de distributed tracing \n",
    "\n",
    "Vamos a crear tres microservicios simples que se llamarán entre sí. Cada uno registrará sus acciones junto con un ID de correlación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f36d75-a8e3-4af4-a36d-d523e1d4c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import requests\n",
    "import uuid\n",
    "import logging\n",
    "\n",
    "# Configuración de logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def get_correlation_id():\n",
    "    # Obtener el correlation ID de la cabecera de la solicitud, o generar uno nuevo si no existe\n",
    "    return request.headers.get('X-Correlation-ID', uuid.uuid4().hex)\n",
    "\n",
    "@app.route('/serviceA')\n",
    "def service_a():\n",
    "    correlation_id = get_correlation_id()\n",
    "    logging.info(f\"Service A called with correlation ID: {correlation_id}\")\n",
    "\n",
    "    # Llamada a Service B\n",
    "    headers = {'X-Correlation-ID': correlation_id}\n",
    "    response_b = requests.get(\"http://localhost:5001/serviceB\", headers=headers)\n",
    "    \n",
    "    # Llamada a Service C\n",
    "    response_c = requests.get(\"http://localhost:5002/serviceC\", headers=headers)\n",
    "    \n",
    "    return jsonify({\n",
    "        'serviceB_response': response_b.text, \n",
    "        'serviceC_response': response_c.text\n",
    "    })\n",
    "\n",
    "@app.route('/serviceB')\n",
    "def service_b():\n",
    "    correlation_id = get_correlation_id()\n",
    "    logging.info(f\"Service B called with correlation ID: {correlation_id}\")\n",
    "    return f\"Service B processed with correlation ID: {correlation_id}\"\n",
    "\n",
    "@app.route('/serviceC')\n",
    "def service_c():\n",
    "    correlation_id = get_correlation_id()\n",
    "    logging.info(f\"Service C called with correlation ID: {correlation_id}\")\n",
    "    return f\"Service C processed with correlation ID: {correlation_id}\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Asumiendo diferentes puertos para simulación de diferentes servicios\n",
    "    import sys\n",
    "    port = 5000 if len(sys.argv) == 1 else int(sys.argv[1])\n",
    "    app.run(port=port)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af258e6c-707d-4915-8498-72377f68f008",
   "metadata": {},
   "source": [
    "Explicación del código\n",
    "\n",
    "- Utilizamos el módulo logging de Python para registrar los eventos. Cada evento registrará el ID de correlación para rastrear la solicitud a través de los servicios.\n",
    "- En cada servicio, intentamos recuperar el X-Correlation-ID de las cabeceras HTTP. Si no está presente, generamos uno nuevo utilizando uuid.uuid4().hex. Esto asegura que cada cadena de solicitudes tenga un ID único que las trace.\n",
    "- El ServiceA hace llamadas a ServiceB y ServiceC, pasando el X-Correlation-ID en las cabeceras HTTP para mantener la trazabilidad.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b37d59-5f37-40e1-99dc-5b218fc00555",
   "metadata": {},
   "source": [
    "Ejecución y Pruebas\n",
    "\n",
    "- Guarda el código en un archivo, por ejemplo, tracing_example.py.\n",
    "- Ejecuta tres instancias del servidor en diferentes terminales para simular los diferentes servicios:\n",
    "\n",
    "    python tracing_example.py 5000\n",
    "    python tracing_example.py 5001\n",
    "    python tracing_example.py 5002\n",
    "\n",
    "Usa un navegador o una herramienta como curl para llamar al ServiceA y observar las respuestas:\n",
    "\n",
    "    curl http://localhost:5000/serviceA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148d6338-282c-48eb-b820-3ef3504ed847",
   "metadata": {},
   "source": [
    "Verás en los logs que cada llamada a los servicios incluye el mismo ID de correlación, lo que te permite rastrear cómo se procesa una solicitud a través de diferentes servicios. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9afaafc-63a4-4ac5-babf-7cebb156d9d3",
   "metadata": {},
   "source": [
    "#### Tu participación\n",
    "\n",
    "- ¿Qué es un ID de correlación y cómo facilita el seguimiento distribuido en arquitecturas de microservicios?\n",
    "- Explica cómo la propagación del ID de correlación entre los servicios mejora la capacidad de depuración y monitorización en sistemas distribuidos.\n",
    "- ¿Cuáles son las ventajas de utilizar un sistema centralizado de logging en un entorno de microservicios?\n",
    "- Discute los desafíos de implementar el seguimiento distribuido en un sistema de microservicios que ya está en producción. ¿Qué estrategias podrían mitigar estos desafíos?\n",
    "- ¿Cómo puede impactar el seguimiento distribuido en el rendimiento de un sistema de microservicios y cómo se podría minimizar este impacto?\n",
    "- Modifica el código para incluir más información en los logs, como parámetros específicos de la solicitud o más detalles del estado interno en cada punto de logging. Ejemplo: Registrar los parámetros de entrada en ServiceB y ServiceC.\n",
    "- Agrega código que simule un fallo aleatorio en ServiceC.\n",
    "- Implementa una solución que reintente la solicitud a ServiceC si falla, utilizando el mismo ID de correlación y registra cada intento.\n",
    "- Escribe un script que extraiga logs de un archivo y filtre por ID de correlación. Este script debería ser capaz de mostrar la cadena completa de eventos para una solicitud específica. Ejemplo: Un script Python que lee un archivo de log y muestra todas las entradas relacionadas con un ID de correlación dado.\n",
    "- Agrega manejo de timeouts a las solicitudes HTTP en ServiceA que se hacen a ServiceB y ServiceC.\n",
    "- Modifica el código para registrar la latencia de las solicitudes entre servicios. Registra el tiempo que toma cada servicio para responder y analiza los datos para identificar posibles cuellos de botella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067238b-50e0-4cf6-9b4b-c7411c25dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mejora del Sistema de Logging\n",
    "\n",
    "@app.route('/serviceB')\n",
    "def service_b():\n",
    "    correlation_id = get_correlation_id()\n",
    "    param = request.args.get('param', 'default')\n",
    "    logging.info(f\"Service B called with correlation ID: {correlation_id}, Parameter: {param}\")\n",
    "    return f\"Service B processed with correlation ID: {correlation_id}, Parameter: {param}\"\n",
    "\n",
    "@app.route('/serviceC')\n",
    "def service_c():\n",
    "    correlation_id = get_correlation_id()\n",
    "    status = \"Starting process\"\n",
    "    logging.info(f\"Service C called with correlation ID: {correlation_id}, Status: {status}\")\n",
    "    try:\n",
    "        # Simular fallo aleatorio\n",
    "        if random.random() < 0.5:\n",
    "            raise ValueError(\"Simulated Failure\")\n",
    "        status = \"Completed successfully\"\n",
    "    except Exception as e:\n",
    "        status = f\"Failed with error: {str(e)}\"\n",
    "        logging.error(f\"Service C error with correlation ID: {correlation_id}: {str(e)}\")\n",
    "    finally:\n",
    "        logging.info(f\"Service C final status with correlation ID: {correlation_id}: {status}\")\n",
    "    return f\"Service C processed with correlation ID: {correlation_id}, Status: {status}\"\n",
    "\n",
    "## Implementación de Retries\n",
    "\n",
    "def retry_request(url, headers, max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                return response.text\n",
    "        except requests.RequestException as e:\n",
    "            logging.error(f\"Attempt {attempt + 1}: Failed to call {url} with error: {str(e)}\")\n",
    "            time.sleep(1)  # Espera antes de reintentar\n",
    "    return \"Failed after retries\"\n",
    "\n",
    "@app.route('/serviceA')\n",
    "def service_a():\n",
    "    correlation_id = get_correlation_id()\n",
    "    headers = {'X-Correlation-ID': correlation_id}\n",
    "    response_b = requests.get(\"http://localhost:5001/serviceB\", headers=headers)\n",
    "    response_c = retry_request(\"http://localhost:5002/serviceC\", headers)\n",
    "    return jsonify({\n",
    "        'serviceB_response': response_b.text, \n",
    "        'serviceC_response': response_c\n",
    "    })\n",
    "\n",
    "#Monitorización de Latencia\n",
    "\n",
    "@app.route('/serviceA')\n",
    "def service_a():\n",
    "    start_time = time.time()\n",
    "    correlation_id = get_correlation_id()\n",
    "    headers = {'X-Correlation-ID': correlation_id}\n",
    "    response_b = requests.get(\"http://localhost:5001/serviceB\", headers=headers)\n",
    "    response_c = retry_request(\"http://localhost:5002/serviceC\", headers)\n",
    "    total_time = time.time() - start_time\n",
    "    logging.info(f\"Total processing time for correlation ID {correlation_id}: {total_time} seconds\")\n",
    "    return jsonify({\n",
    "        'serviceB_response': response_b.text, \n",
    "        'serviceC_response': response_c,\n",
    "        'latency': total_time\n",
    "    })\n",
    "\n",
    "#Script de Extracción de Logs\n",
    "\n",
    "def filter_logs_by_correlation_id(file_path, correlation_id):\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if correlation_id in line:\n",
    "                print(line)\n",
    "\n",
    "# Uso del script\n",
    "filter_logs_by_correlation_id('path_to_log_file.log', 'desired_correlation_id')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
