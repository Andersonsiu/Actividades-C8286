{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14fd13fa-b393-479b-9926-ed9b0a805e6f",
   "metadata": {},
   "source": [
    "### Paralelismo de datos\n",
    "\n",
    "El paralelismo de datos es una técnica de computación paralela donde se divide un conjunto de datos en partes más pequeñas que pueden ser procesadas simultáneamente por múltiples procesadores o núcleos de procesamiento. A diferencia del paralelismo de tareas, donde diferentes tareas o funciones son ejecutadas en paralelo, el paralelismo de datos se centra en aplicar la misma operación a diferentes fragmentos de datos de manera concurrente. Esta técnica es particularmente efectiva en aplicaciones que involucran grandes volúmenes de datos y operaciones repetitivas.\n",
    "\n",
    "**Conceptos fundamentales**:\n",
    "\n",
    "División de datos:\n",
    "\n",
    "- Segmentación: Los datos se segmentan en bloques que pueden ser procesados independientemente. Por ejemplo, en el procesamiento de imágenes, una imagen puede dividirse en múltiples segmentos, y cada segmento puede ser procesado por un núcleo diferente.\n",
    "- Distribución: Los datos segmentados se distribuyen entre los procesadores disponibles. Esta distribución debe ser balanceada para asegurar que cada procesador tenga una cantidad similar de trabajo, minimizando así el tiempo total de ejecución.\n",
    "\n",
    "Operaciones similares:\n",
    "\n",
    "- Aplicación de la misma operación: Cada procesador aplica la misma operación a su segmento de datos. Esto es eficiente en algoritmos como el procesamiento de matrices, transformadas de Fourier, y en la mayoría de las operaciones aritméticas en vectores.\n",
    "- Independencia de los datos: Las operaciones deben ser independientes entre sí para evitar conflictos y asegurar que no se necesiten sincronizaciones complejas.\n",
    " \n",
    "\n",
    "**Implementaciones y arquitecturas**\n",
    "\n",
    "Vectorización:\n",
    "\n",
    "- Procesadores SIMD (Single Instruction, Multiple Data): En estos procesadores, una sola instrucción es aplicada a múltiples datos simultáneamente. SIMD es común en unidades de procesamiento gráfico (GPU) y en algunas extensiones de conjuntos de instrucciones de CPU como SSE (Streaming SIMD Extensions) y AVX (Advanced Vector Extensions).\n",
    "- Ejemplos: Operaciones como la suma de vectores, multiplicación de matrices, y filtrado de imágenes se benefician enormemente de la vectorización.\n",
    "\n",
    "Arquitectura de memoria compartida:\n",
    "\n",
    "- Multiprocesadores de memoria compartida: En estas arquitecturas, múltiples procesadores comparten una única memoria principal. La sincronización y la coherencia de caché son críticas en estos sistemas para asegurar que todos los procesadores trabajen con datos consistentes.\n",
    "- OpenMP: Es una API para programación paralela en sistemas de memoria compartida. Permite a los programadores especificar de manera sencilla las partes del código que deben ser paralelizadas.\n",
    "\n",
    "Arquitectura de memoria distribuida:\n",
    "\n",
    "- Clusters y grids: En sistemas de memoria distribuida, cada procesador tiene su propia memoria local. Los datos deben ser explícitamente enviados entre procesadores, generalmente mediante un mecanismo de paso de mensajes.\n",
    "- MPI (Message Passing Interface): Es un estándar para la programación paralela en sistemas de memoria distribuida. Permite la comunicación eficiente entre procesos que se ejecutan en diferentes nodos de un cluster.\n",
    "\n",
    "**Aplicaciones y ejemplos**\n",
    "\n",
    "Procesamiento de imágenes:\n",
    "\n",
    "- Filtrado y Transformaciones: Operaciones como la convolución y las transformadas de Fourier en imágenes se pueden paralelizar dividiendo la imagen en bloques y aplicando la operación a cada bloque simultáneamente.\n",
    "- Ejemplo práctico: En el procesamiento de video, cada cuadro puede ser segmentado y procesado en paralelo para efectos como el suavizado, la detección de bordes, y la compresión.\n",
    "\n",
    "Computación científica:\n",
    "\n",
    "- Simulaciones: Simulaciones de sistemas físicos, como dinámica molecular o simulaciones de clima, pueden paralelizarse dividiendo el espacio físico en subregiones, cada una procesada en paralelo.\n",
    "- Ejemplo práctico: En una simulación de dinámica de fluidos, el dominio de simulación puede dividirse en celdas, y el cálculo del flujo en cada celda se realiza en paralelo.\n",
    "\n",
    "Big Data y análisis de datos:\n",
    "\n",
    "- MapReduce: Es un modelo de programación que permite el procesamiento de grandes conjuntos de datos en paralelo. Los datos se dividen en fragmentos y se procesan en paralelo mediante funciones de mapeo y reducción.\n",
    "- Ejemplo práctico: Procesos de ETL (Extract, Transform, Load) en bases de datos grandes se benefician del paralelismo de datos para extraer, transformar y cargar datos de manera eficiente.\n",
    "\n",
    "**Desafíos y consideraciones**\n",
    "\n",
    "Equilibrio de carga:\n",
    "\n",
    "- Desbalanceo de carga: Un desafío importante en el paralelismo de datos es asegurar que todos los procesadores tengan una cantidad equitativa de trabajo. Si algunos procesadores terminan antes que otros, los recursos no se utilizan de manera eficiente.\n",
    "- Técnicas de equilibrio: Estrategias como el balanceo dinámico de carga y la redistribución de datos en tiempo de ejecución pueden ayudar a mitigar este problema.\n",
    "\n",
    "Comunicación y sincronización:\n",
    "\n",
    "- Latencia y ancho de banda: En arquitecturas de memoria distribuida, la latencia de comunicación y el ancho de banda son factores críticos. Una comunicación excesiva puede reducir significativamente los beneficios del paralelismo.\n",
    "- Barreras y sincronización: La necesidad de sincronización entre procesadores puede introducir esperas y reducir la eficiencia. El diseño de algoritmos debe minimizar estas sincronizaciones.\n",
    "\n",
    "Coherencia de memoria:\n",
    "\n",
    "- Incoherencia de caché: En sistemas de memoria compartida, mantener la coherencia de caché es esencial para asegurar que todos los procesadores trabajen con datos actualizados.\n",
    "- Protocolos de coherencia: Protocolos como MESI (Modified, Exclusive, Shared, Invalid) y MOESI (Modified, Owner, Exclusive, Shared, Invalid) se utilizan para gestionar la coherencia de caché."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff6a5aa-b0e8-4f5d-93bf-ae8712316e05",
   "metadata": {},
   "source": [
    "#### Ejercicios de paralelismo de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea7cf13-0141-4bca-9453-df1405428db0",
   "metadata": {},
   "source": [
    "\n",
    "Ejercicio 1: Procesamiento paralelo de imágenes con OpenCV y Multiprocessing\n",
    "Descripción: Divide una imagen en varios segmentos y aplica un filtro (por ejemplo, filtro de desenfoque) a cada segmento en paralelo usando el módulo multiprocessing.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Cargar una imagen utilizando OpenCV.\n",
    "- Dividir la imagen en segmentos.\n",
    "- Aplicar un filtro de desenfoque a cada segmento en paralelo.\n",
    "- Unir los segmentos procesados y guardar la imagen resultante.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa cv2.imread para cargar la imagen.\n",
    "- Usa multiprocessing.Pool para el procesamiento paralelo.\n",
    "- Usa numpy.hstack o numpy.vstack para unir los segmentos procesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c3d0c7-9f9e-4272-90e4-f4452382bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2 #procesamiento de imagenes\n",
    "import numpy as np  #manejo de arreglos\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def apply_blur(segment):\n",
    "    return cv2.GaussianBlur(segment, (15, 15), 0)\n",
    "\n",
    "def parallel_image_processing(image_path):    \n",
    "    image = cv2.imread(image_path)  #carga la imagen desde la ruta \n",
    "    height, width, _ = image.shape  #obtiene dimensiones de la imagen\n",
    "    segments = np.array_split(image, 4, axis=1)  #divide la imagen en 4 segmenos verticales\n",
    "\n",
    "    with Pool(processes=4) as pool:\n",
    "        blurred_segments = pool.map(apply_blur, segments)  #aplica la funcion en paralelo \n",
    "\n",
    "    blurred_image = np.hstack(blurred_segments)  #une segmentos desenfocados en una sola imagen\n",
    "    cv2.imwrite('blurred_image.jpg', blurred_image)\n",
    "\n",
    "parallel_image_processing('input_image.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def5fc8c-6fbc-4df7-b011-549899abf39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e51faf-02fe-45c1-a14c-ee8bf3d719f8",
   "metadata": {},
   "source": [
    "Ejercicio 2: Paralelización de operaciones matriciales con NumPy y Joblib\n",
    "\n",
    "Descripción: Paraleliza una serie de operaciones matriciales (multiplicación de matrices) utilizando Joblib.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Crear dos matrices grandes con numpy.\n",
    "- Dividir las matrices en sub-matrices.\n",
    "- Multiplicar las sub-matrices en paralelo utilizando Joblib.\n",
    "- Reunir los resultados y formar la matriz resultante.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa numpy.split para dividir las matrices.\n",
    "- Usa joblib.Parallel y joblib.delayed para el procesamiento paralelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a008cca-9d53-421d-a55f-d4a48fdc7d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np #operaciones matriciales y generacion de datos\n",
    "from joblib import Parallel, delayed  #ejecutar tareas en paralelo\n",
    "\n",
    "def multiply_sub_matrices(A, B): #toma dos submatrices \n",
    "    return np.dot(A, B)  #calcula su multiplicacion\n",
    "\n",
    "def parallel_matrix_multiplication():   #realiza multiplicacion de matrices en paralelo\n",
    "    A = np.random.rand(1000, 1000)      #matriz A 1000x1000\n",
    "    B = np.random.rand(1000, 1000)\n",
    "    A_subs = np.array_split(A, 4, axis=0)  #divide la matriz en 4 submatrices a largo la fila\n",
    "    B_subs = np.array_split(B, 4, axis=1)  #columna\n",
    "    C = np.zeros((1000, 1000))  #crear matriz c para almacenar resultados\n",
    "\n",
    "    def calculate_and_store(i,j): #calcula producto de las submatrices  asubs bsubs\n",
    "        return np.dot(A_subs[i],B_subs[j])\n",
    "    \n",
    "    results = Parallel(n_jobs=4)(delayed(calculate_and_store)(i,j) for i in range(4) for j in range(4)) #itera las combinaciones i y j para multiplicar submatrices\n",
    "\n",
    "    for i in range(4): #colocar los resultados de la matrtiz c en posiciones correctas\n",
    "        for j in range(4):\n",
    "            C[i*250:(i+1)*250,j*250:(j+1)*250] = results[i*4+j] #coloca cada resultado en la posicion correspondiente de\n",
    "\n",
    "    return C\n",
    "\n",
    "C = parallel_matrix_multiplication()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbc8d0-ffa3-4f05-94e8-3d72d8c7dc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79b9d81-0ba4-40e2-bee0-99df775df29a",
   "metadata": {},
   "source": [
    "Ejercicio 3: Procesamiento paralelo de archivos con Dask\n",
    "\n",
    "Descripción: Utiliza Dask para procesar un conjunto de archivos CSV en paralelo, realizando una agregación (por ejemplo, promedio de una columna específica).\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Leer varios archivos CSV con Dask.\n",
    "- Procesar los archivos en paralelo para calcular el promedio de una columna específica.\n",
    "- Combinar los resultados y obtener el promedio total.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa dask.dataframe.read_csv para leer los archivos.\n",
    "- Usa dask.dataframe para realizar las operaciones en paralelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9282f85-4257-4274-9590-ccaba542225b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average value: 61.25\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd  #procesamiento paralelo de grandes conjuntos de datos \n",
    "\n",
    "def parallel_csv_processing(file_paths):   #procesa archivos csv en paralelo y calcula el promedio de una columna\n",
    "    df = dd.read_csv(file_paths)  #leer varios archivos csv en paralelo y lo combina en un solo dataframe\n",
    "    average_value = df['target_column'].mean().compute()  #promedio de la columna \n",
    "    return average_value\n",
    "\n",
    "file_paths = ['file1.csv', 'file2.csv', 'file3.csv', 'file4.csv']  #lista archivos \n",
    "average = parallel_csv_processing(file_paths)  #llama a la funcion \n",
    "print(f\"Average value: {average}\") #imprime valor del promedio \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c32cd1-27da-40aa-8847-7ee1efa54624",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7e484-f1b5-4a5a-bb9a-2e0cb7f85f0f",
   "metadata": {},
   "source": [
    "Ejercicio 4: Multiplicación de matrices paralela con OpenMP\n",
    "Descripción: Implementa la multiplicación de matrices utilizando OpenMP para paralelizar el cálculo.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Crear dos matrices grandes.\n",
    "- Paralelizar la multiplicación de matrices utilizando directivas de OpenMP.\n",
    "- Compilar y ejecutar el programa en un sistema con múltiples núcleos.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa #pragma omp parallel for para paralelizar los bucles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ec33bce-8868-4b83-b080-5bc60e97fd9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1481753451.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    void parallel_matrix_multiplication(int N) {\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "\n",
    "void parallel_matrix_multiplication(int N) {\n",
    "    int i, j, k;\n",
    "    double **A = (double **)malloc(N * sizeof(double *));\n",
    "    double **B = (double **)malloc(N * sizeof(double *));\n",
    "    double **C = (double **)malloc(N * sizeof(double *));\n",
    "    for (i = 0; i < N; i++) {\n",
    "        A[i] = (double *)malloc(N * sizeof(double));\n",
    "        B[i] = (double *)malloc(N * sizeof(double));\n",
    "        C[i] = (double *)malloc(N * sizeof(double));\n",
    "        for (j = 0; j < N; j++) {\n",
    "            A[i][j] = rand() % 100;\n",
    "            B[i][j] = rand() % 100;\n",
    "            C[i][j] = 0.0;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    #pragma omp parallel for private(i, j, k) shared(A, B, C)\n",
    "    for (i = 0; i < N; i++) {\n",
    "        for (j = 0; j < N; j++) {\n",
    "            for (k = 0; k < N; k++) {\n",
    "                C[i][j] += A[i][k] * B[k][j];\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Imprimir una pequeña parte de la matriz resultado\n",
    "    for (i = 0; i < 5; i++) {\n",
    "        for (j = 0; j < 5; j++) {\n",
    "            printf(\"%f \", C[i][j]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "\n",
    "    for (i = 0; i < N; i++) {\n",
    "        free(A[i]);\n",
    "        free(B[i]);\n",
    "        free(C[i]);\n",
    "    }\n",
    "    free(A);\n",
    "    free(B);\n",
    "    free(C);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int N = 1000;\n",
    "    parallel_matrix_multiplication(N);\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5e9b4d-cc13-4c3a-a7c1-b910aa1f1c3a",
   "metadata": {},
   "source": [
    "Ejercicio 5: Suma paralela de un vector con Pthreads\n",
    "\n",
    "Descripción: Implementa la suma de los elementos de un vector utilizando pthread para paralelizar el cálculo.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Crear un vector grande.\n",
    "- Dividir el vector en segmentos y asignar cada segmento a un hilo diferente.\n",
    "- Utilizar pthread para realizar la suma en paralelo y combinar los resultados.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa pthread_create y pthread_join para gestionar los hilos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fee9a13-94b9-46c1-aaed-3dc2447488fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <pthread.h>\n",
    "\n",
    "#define NUM_THREADS 4\n",
    "#define VECTOR_SIZE 1000000\n",
    "\n",
    "typedef struct {\n",
    "    int start;\n",
    "    int end;\n",
    "    double *vector;\n",
    "    double sum;\n",
    "} ThreadData;\n",
    "\n",
    "void *partial_sum(void *arg) {\n",
    "    ThreadData *data = (ThreadData *)arg;\n",
    "    data->sum = 0.0;\n",
    "    for (int i = data->start; i < data->end; i++) {\n",
    "        data->sum += data->vector[i];\n",
    "    }\n",
    "    pthread_exit(NULL);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    double *vector = (double *)malloc(VECTOR_SIZE * sizeof(double));\n",
    "    for (int i = 0; i < VECTOR_SIZE; i++) {\n",
    "        vector[i] = rand() % 100;\n",
    "    }\n",
    "\n",
    "    pthread_t threads[NUM_THREADS];\n",
    "    ThreadData thread_data[NUM_THREADS];\n",
    "    int segment_size = VECTOR_SIZE / NUM_THREADS;\n",
    "\n",
    "    for (int i = 0; i < NUM_THREADS; i++) {\n",
    "        thread_data[i].start = i * segment_size;\n",
    "        thread_data[i].end = (i == NUM_THREADS - 1) ? VECTOR_SIZE : (i + 1) * segment_size;\n",
    "        thread_data[i].vector = vector;\n",
    "        pthread_create(&threads[i], NULL, partial_sum, (void *)&thread_data[i]);\n",
    "    }\n",
    "\n",
    "    double total_sum = 0.0;\n",
    "    for (int i = 0; i < NUM_THREADS; i++) {\n",
    "        pthread_join(threads[i], NULL);\n",
    "        total_sum += thread_data[i].sum;\n",
    "    }\n",
    "\n",
    "    printf(\"Total sum: %f\\n\", total_sum);\n",
    "    free(vector);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d389f253-7612-42a1-936c-731f14e4d3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391839db-f31c-4b98-81d7-70291f518f68",
   "metadata": {},
   "source": [
    "### Paralelismo de tareas\n",
    "\n",
    "El paralelismo de tareas es una técnica de computación paralela que se enfoca en dividir un problema en múltiples tareas independientes que pueden ejecutarse simultáneamente. A diferencia del paralelismo de datos, donde la misma operación se aplica a diferentes fragmentos de datos, el paralelismo de tareas permite que distintas operaciones o funciones se ejecuten en paralelo. Esta técnica es particularmente útil en aplicaciones donde las tareas son naturalmente independientes o pueden descomponerse en sub-tareas que no dependen entre sí.\n",
    "\n",
    "\n",
    "**Conceptos fundamentales**\n",
    "\n",
    "Descomposición de tareas:\n",
    "\n",
    "- División del problema: El primer paso en el paralelismo de tareas es dividir el problema en tareas más pequeñas que pueden ejecutarse de manera independiente. Esta división debe hacerse de tal manera que minimice la dependencia y maximice la paralelización.\n",
    "- Granularidad: La granularidad se refiere al tamaño de las tareas. Las tareas gruesas son grandes y pueden ser pocas, mientras que las tareas finas son pequeñas y numerosas. Un equilibrio adecuado es esencial para maximizar la eficiencia y minimizar el overhead de gestión.\n",
    "\n",
    "**Asignación de tareas:**\n",
    "\n",
    "- Distribución dinámica vs. estática: En una asignación estática, las tareas se distribuyen a los procesadores de manera fija antes de la ejecución. En una asignación dinámica, las tareas se asignan a medida que los procesadores se desocupen, lo cual puede ayudar a equilibrar la carga.\n",
    "- Balanceo de carga: El balanceo de carga asegura que todas las unidades de procesamiento tengan una cantidad equitativa de trabajo, evitando que algunos procesadores estén inactivos mientras otros están sobrecargados.\n",
    "\n",
    "**Sincronización y comunicación:**\n",
    "\n",
    "- Sincronización de tareas: Aunque las tareas son independientes, puede ser necesario sincronizarlas en ciertos puntos para asegurar que las dependencias se manejan correctamente.\n",
    "- Comunicación entre tareas: En sistemas donde las tareas deben intercambiar datos, la comunicación debe ser eficiente para minimizar el overhead y evitar cuellos de botella.\n",
    "\n",
    "**Implementaciones y arquitecturas**\n",
    "\n",
    "Procesadores Multinúcleo:\n",
    "\n",
    "- Multiprocesadores de memoria compartida: En sistemas con múltiples núcleos en un solo chip, las tareas se pueden distribuir entre los núcleos. Estos sistemas se benefician de un acceso rápido a una memoria compartida.\n",
    "- Herramientas de programación: OpenMP es una de las herramientas más utilizadas para paralelizar tareas en sistemas de memoria compartida. Permite la paralelización de bucles y la creación de secciones paralelas de código.\n",
    "\n",
    "Clusters y grids:\n",
    "\n",
    "- Sistemas de memoria distribuida: En un cluster, cada nodo tiene su propia memoria, y las tareas se distribuyen entre los nodos. La comunicación entre nodos se realiza mediante mensajes.\n",
    "\n",
    "- Message passing interface (MPI): Es el estándar para la programación en memoria distribuida. Facilita la creación de programas que pueden ejecutar tareas en paralelo en diferentes nodos de un cluster.\n",
    "\n",
    "**Sistemas híbridos**\n",
    "\n",
    "- Combinación de memoria compartida y distribuida: Algunos sistemas combinan ambos enfoques, utilizando memoria compartida dentro de un nodo y comunicación mediante mensajes entre nodos.\n",
    "- Modelos de programación híbridos: Herramientas como MPI+OpenMP permiten aprovechar las ventajas de ambos modelos, distribuyendo tareas a nivel de nodo y paralelizándolas dentro de cada nodo.\n",
    "\n",
    "**Aplicaciones y ejemplos**\n",
    "\n",
    "Servidores web:\n",
    "\n",
    "- Manejo de solicitudes concurrentes: En un servidor web, cada solicitud de cliente puede ser manejada como una tarea independiente. Esto permite al servidor procesar múltiples solicitudes al mismo tiempo, mejorando la capacidad de respuesta.\n",
    "- Ejemplo práctico: Un servidor Apache puede utilizar hilos para manejar cada solicitud de manera concurrente, permitiendo servir páginas web a múltiples usuarios simultáneamente.\n",
    "\n",
    "Sistemas de bases de datos:\n",
    "\n",
    "- Consultas concurrentes: Las bases de datos pueden ejecutar múltiples consultas en paralelo. Cada consulta puede ser tratada como una tarea independiente, permitiendo a la base de datos manejar un gran volumen de solicitudes.\n",
    "- Ejemplo práctico: Un sistema de gestión de bases de datos como MySQL puede ejecutar varias consultas de usuarios diferentes en paralelo, mejorando la eficiencia y el rendimiento.\n",
    "\n",
    "Procesamiento de señales:\n",
    "\n",
    "- Análisis y filtrado en tiempo real: En el procesamiento de señales, diferentes etapas del análisis y filtrado pueden ser ejecutadas en paralelo. Cada etapa puede ser tratada como una tarea separada.\n",
    "- Ejemplo práctico: En un sistema de reconocimiento de voz, la pre-procesamiento de señales, la extracción de características y el reconocimiento de patrones pueden ejecutarse en paralelo para acelerar el procesamiento.\n",
    "\n",
    "**Desafíos y consideraciones**\n",
    "\n",
    "Dependencias entre tareas:\n",
    "\n",
    "- Dependencias de datos: Las dependencias entre tareas pueden complicar la paralelización. Es esencial identificar y gestionar estas dependencias para evitar bloqueos y garantizar la coherencia de los datos.\n",
    "- Técnicas de resolución: Técnicas como la descomposición en fases y el uso de barreras de sincronización pueden ayudar a manejar dependencias.\n",
    "\n",
    "Overhead de sincronización:\n",
    "\n",
    "- Costos de sincronización: La sincronización entre tareas introduce overhead. Minimizar este overhead es crucial para mantener la eficiencia.\n",
    "- Estrategias de mitigación: El uso de algoritmos de sincronización eficientes y la reducción de la frecuencia de sincronización pueden ayudar a minimizar los costos.\n",
    "\n",
    "Equilibrio de carga:\n",
    "\n",
    "- Desbalance de carga: Un desbalance en la carga de trabajo puede reducir la eficiencia del sistema. Es importante distribuir las tareas de manera que cada procesador tenga una carga similar.\n",
    "- Técnicas de balanceo: Métodos como el balanceo dinámico de carga, donde las tareas se reasignan en tiempo de ejecución, pueden ayudar a mantener el equilibrio.\n",
    "\n",
    "Comunicación y ancho de banda:\n",
    "\n",
    "- Latencia de comunicación: En sistemas de memoria distribuida, la latencia de comunicación puede ser un cuello de botella. Es esencial diseñar las tareas y el sistema de comunicación para minimizar la latencia.\n",
    "- Optimización del ancho de banda: El uso eficiente del ancho de banda de comunicación es crucial para el rendimiento. Técnicas como la agregación de mensajes y la compresión de datos pueden ayudar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b0cb9c-502f-4280-8493-6e91d81dfbfe",
   "metadata": {},
   "source": [
    "Ejercicio 6: Procesamiento paralelo de archivos con concurrent.futures\n",
    "\n",
    "Descripción: Implementa un sistema para procesar múltiples archivos de texto en paralelo, donde cada archivo se lee y se realiza una operación de conteo de palabras.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Crear una lista de archivos de texto.\n",
    "- Usar concurrent.futures.ThreadPoolExecutor para procesar los archivos en paralelo.\n",
    "- Contar las palabras en cada archivo y almacenar los resultados en un diccionario.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa ThreadPoolExecutor para paralelizar la lectura y el conteo de palabras.\n",
    "- Usa un diccionario compartido para almacenar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c066cabb-1688-4c56-9561-15985c804ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file1.txt': 3, 'file2.txt': 8, 'file3.txt': 6}\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import os\n",
    "\n",
    "def count_words_in_file(file_path):\n",
    "    with open(file_path, 'r') as file: #abre el archivo\n",
    "        text = file.read()   #lee el contenido\n",
    "    word_count = len(text.split())  #divide el txto en palabras con split\n",
    "    return (file_path, word_count)  \n",
    "\n",
    "def parallel_word_count(file_paths):\n",
    "    results = {} #almacernar los resultados\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:  \n",
    "        future_to_file = {executor.submit(count_words_in_file, file_path): file_path for file_path in file_paths} #enviar las tareas el executor\n",
    "        for future in concurrent.futures.as_completed(future_to_file): #itera sobre las tareas completadas\n",
    "            file_path = future_to_file[future]   # ruta del archivo\n",
    "            try: \n",
    "                file_path, count = future.result()   #resultado de la tarea\n",
    "                results[file_path] = count          \n",
    "            except Exception as exc:\n",
    "                print(f\"{file_path} generated an exception: {exc}\")\n",
    "    return results\n",
    "\n",
    "file_paths = [\"file1.txt\", \"file2.txt\", \"file3.txt\"]  \n",
    "word_counts = parallel_word_count(file_paths)  #almacena los resultados en wordcounts\n",
    "print(word_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a341c525-5974-4a78-8f60-3120ad9ed1ac",
   "metadata": {},
   "source": [
    "Ejercicio 7: Descarga paralela de páginas Web con aiohttp y asyncio\n",
    "\n",
    "Descripción: Implementa un sistema para descargar varias páginas web en paralelo utilizando aiohttp y asyncio.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Crear una lista de URLs.\n",
    "- Usar aiohttp y asyncio para descargar las páginas web en paralelo.\n",
    "- Almacenar el contenido de cada página en un archivo separado.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa aiohttp para realizar solicitudes HTTP de manera asíncrona.\n",
    "- Usa asyncio para gestionar la concurrencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b7ddefc-b912-485f-973e-937686824e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio \n",
    "\n",
    "async def fetch_page(session, url): #solicitudes http\n",
    "    async with session.get(url) as response:  #hacemos un get a la url\n",
    "        content = await response.text()  #esperamos la respuesta y lee el contenido\n",
    "        filename = url.replace(\"https://\", \"\").replace(\"/\", \"_\") + \".html\"  #crea un nombre de archivo y remplaza\n",
    "        with open(filename, 'w') as file: #abre el archivo en modo escritura\n",
    "            file.write(content) #escribe el contenido de la pagina en el archivo\n",
    "        return filename\n",
    "\n",
    "async def parallel_download(urls): \n",
    "    async with aiohttp.ClientSession() as session: #crea una sesionaiohttp \n",
    "        tasks = [fetch_page(session, url) for url in urls]  #crea una lista de tareas donde cada tarea es una llamada\n",
    "        return await asyncio.gather(*tasks)  #ejecuta las tareas de forma concurrente\n",
    "\n",
    "urls = [\"https://es.wikipedia.org/wiki/Cristiano_Ronaldo\", \"https://es.wikipedia.org/wiki/Lionel_Messi\", \"https://es.wikipedia.org/wiki/Neymar\"]\n",
    "#results = asyncio.run(parallel_download(urls))\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606ddf28-730c-4d66-a083-a6db72d020ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe04de8-e811-4a08-9513-1f78c7434d0f",
   "metadata": {},
   "source": [
    "Ejercicio 8: Evaluación de modelos en paralelo con joblib\n",
    "\n",
    "Descripción: Implementa un sistema para evaluar varios modelos de machine learning en paralelo utilizando joblib.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Entrenar varios modelos de machine learning con diferentes parámetros.\n",
    "- Usar joblib.Parallel para evaluar los modelos en paralelo.\n",
    "- Comparar los resultados y seleccionar el mejor modelo.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa joblib.Parallel y joblib.delayed para paralelizar la evaluación de los modelos.\n",
    "Usa una métrica de evaluación adecuada, como la precisión o el F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7597b754-fc9d-44a1-87c6-794e43959831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anderson/.local/lib/python3.10/site-packages/scipy/linalg/_misc.py:3: RuntimeWarning: coroutine 'parallel_download' was never awaited\n",
      "  from .blas import get_blas_funcs\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/anderson/.local/lib/python3.10/site-packages/scipy/linalg/lapack.py:827: RuntimeWarning: coroutine 'parallel_download' was never awaited\n",
      "  from scipy.linalg import _flapack\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10, 1.0), (50, 1.0), (100, 1.0), (200, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris  #carga datasets iris\n",
    "from sklearn.model_selection import train_test_split  #divide el dataset en conjuntos de entrenami\n",
    "from sklearn.ensemble import RandomForestClassifier  #bosques aleaotrios\n",
    "from sklearn.metrics import accuracy_score  #calcula precision de modelo\n",
    "from joblib import Parallel, delayed   \n",
    "\n",
    "def evaluate_model(n_estimators, X_train, X_test, y_train, y_test): #xtrain,xtest,etc es datos de entrenamiento\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators) #crea un modelo randomforest / #n_estimator es numero de arboles en el bosque\n",
    "    model.fit(X_train, y_train)  #entrena el modelo\n",
    "    y_pred = model.predict(X_test) #predice las etiquetas\n",
    "    return (n_estimators, accuracy_score(y_test, y_pred)) #retorna la precision del modelo\n",
    "\n",
    "def parallel_model_evaluation():\n",
    "    iris = load_iris()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42) #divide el dataset en 30% de prueba\n",
    "    n_estimators_list = [10, 50, 100, 200]\n",
    "    results = Parallel(n_jobs=4)(delayed(evaluate_model)(n, X_train, X_test, y_train, y_test) for n in n_estimators_list) #se usa parallel para ejecutar los modelos en paralelo\n",
    "    return results\n",
    "\n",
    "results = parallel_model_evaluation()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef036aca-b015-4585-93e6-c9d4f10e6458",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615d9a96-146b-4b4b-876d-af2871c1d51f",
   "metadata": {},
   "source": [
    "Ejercicio 9: Compresión de archivos en paralelo con Pthreads\n",
    "\n",
    "Descripción: Implementa un sistema para comprimir múltiples archivos de texto en paralelo utilizando pthread.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Crear una lista de archivos de texto.\n",
    "- Usar pthread para paralelizar la compresión de los archivos.\n",
    "- Almacenar los archivos comprimidos.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa pthread_create y pthread_join para gestionar los hilos.\n",
    "- Usa una biblioteca de compresión como zlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc4fc01-5839-4a01-b6b0-fa0ca2e604f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <pthread.h>\n",
    "#include <zlib.h>\n",
    "\n",
    "typedef struct {\n",
    "    char *input_file;\n",
    "    char *output_file;\n",
    "} ThreadData;\n",
    "\n",
    "void *compress_file(void *arg) {\n",
    "    ThreadData *data = (ThreadData *)arg;\n",
    "    FILE *source = fopen(data->input_file, \"rb\");\n",
    "    FILE *dest = fopen(data->output_file, \"wb\");\n",
    "    if (!source || !dest) {\n",
    "        perror(\"File open error\");\n",
    "        pthread_exit(NULL);\n",
    "    }\n",
    "\n",
    "    char in_buffer[1024];\n",
    "    char out_buffer[1024];\n",
    "    z_stream stream = {0};\n",
    "    deflateInit(&stream, Z_DEFAULT_COMPRESSION);\n",
    "\n",
    "    int read;\n",
    "    while ((read = fread(in_buffer, 1, sizeof(in_buffer), source)) > 0) {\n",
    "        stream.avail_in = read;\n",
    "        stream.next_in = (Bytef *)in_buffer;\n",
    "        do {\n",
    "            stream.avail_out = sizeof(out_buffer);\n",
    "            stream.next_out = (Bytef *)out_buffer;\n",
    "            deflate(&stream, Z_NO_FLUSH);\n",
    "            fwrite(out_buffer, 1, sizeof(out_buffer) - stream.avail_out, dest);\n",
    "        } while (stream.avail_out == 0);\n",
    "    }\n",
    "\n",
    "    do {\n",
    "        stream.avail_out = sizeof(out_buffer);\n",
    "        stream.next_out = (Bytef *)out_buffer;\n",
    "        deflate(&stream, Z_FINISH);\n",
    "        fwrite(out_buffer, 1, sizeof(out_buffer) - stream.avail_out, dest);\n",
    "    } while (stream.avail_out == 0);\n",
    "\n",
    "    deflateEnd(&stream);\n",
    "    fclose(source);\n",
    "    fclose(dest);\n",
    "    pthread_exit(NULL);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    char *input_files[] = {\"file1.txt\", \"file2.txt\", \"file3.txt\"};\n",
    "    char *output_files[] = {\"file1.txt.gz\", \"file2.txt.gz\", \"file3.txt.gz\"};\n",
    "    int num_files = 3;\n",
    "\n",
    "    pthread_t threads[num_files];\n",
    "    ThreadData thread_data[num_files];\n",
    "\n",
    "    for (int i = 0; i < num_files; i++) {\n",
    "        thread_data[i].input_file = input_files[i];\n",
    "        thread_data[i].output_file = output_files[i];\n",
    "        pthread_create(&threads[i], NULL, compress_file, &thread_data[i]);\n",
    "    }\n",
    "\n",
    "    for (int i = 0; i < num_files; i++) {\n",
    "        pthread_join(threads[i], NULL);\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb75238-ebd3-41a7-bdd4-39e788b42f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea35c329-9541-4f1e-bd9b-60221fd95a07",
   "metadata": {},
   "source": [
    "### Taxonomía de Flynn: SIMD y MIMD\n",
    "\n",
    "La taxonomía de Flynn es una clasificación de arquitecturas de computadoras desarrollada por Michael J. Flynn en 1966. Esta taxonomía se basa en la cantidad de flujos de instrucciones y de datos que una computadora puede manejar simultáneamente, dividiéndose en cuatro categorías principales: SISD (Single Instruction, Single Data), SIMD (Single Instruction, Multiple Data), MISD (Multiple Instruction, Single Data) y MIMD (Multiple Instruction, Multiple Data). Entre estas, SIMD y MIMD son las más relevantes y ampliamente utilizadas en sistemas paralelos y distribuidos.\n",
    "\n",
    "**SIMD (Single Instruction, Multiple Data)**\n",
    "SIMD, o Single Instruction, Multiple Data, es una arquitectura que permite a una única instrucción operar sobre múltiples elementos de datos simultáneamente. Este enfoque es particularmente útil en aplicaciones que involucran grandes volúmenes de datos y operaciones repetitivas, como procesamiento de imágenes, gráficos por computadora, simulaciones científicas, y machine learning.\n",
    "\n",
    "En una arquitectura SIMD, una única unidad de control emite una instrucción que se aplica simultáneamente a múltiples unidades de procesamiento. Cada unidad de procesamiento realiza la misma operación en diferentes conjuntos de datos de manera sincronizada. Por ejemplo, en un procesador SIMD, una instrucción de suma podría sumar simultáneamente pares de números almacenados en diferentes registros o posiciones de memoria.\n",
    "\n",
    "**Ventajas**\n",
    "\n",
    "- Eficiencia en el procesamiento de datos: SIMD es extremadamente eficiente para operaciones vectoriales y matriciales, donde la misma operación se aplica a grandes conjuntos de datos.\n",
    "- Mejor utilización del hardware: Aprovecha mejor los recursos del hardware al permitir que múltiples datos sean procesados en paralelo.\n",
    "Aceleración del Rendimiento: Puede mejorar significativamente el rendimiento de aplicaciones que son inherentemente paralelas, reduciendo el tiempo de ejecución total.\n",
    "\n",
    "**Desventajas**\n",
    "\n",
    "- Flexibilidad limitada: SIMD es menos flexible para aplicaciones que no pueden ser fácilmente paralelizadas a nivel de datos.\n",
    "- Sobrecarga de Control: El manejo de múltiples datos con una sola instrucción puede requerir una mayor complejidad en la gestión de control y sincronización.\n",
    "- Limitaciones en Diversidad de Tareas: No es adecuado para tareas que requieren diferentes operaciones simultáneamente.\n",
    "\n",
    "**Ejemplos de implementaciones**\n",
    "\n",
    "- Vectores y matrices en procesadores de gráficos (GPUs): Los GPUs son el ejemplo más común de arquitecturas SIMD, donde miles de núcleos ejecutan las mismas operaciones en diferentes píxeles de una imagen.\n",
    "- Extensiones SIMD en CPUs: Extensiones como SSE (Streaming SIMD Extensions) y AVX (Advanced Vector Extensions) en procesadores x86 permiten operaciones SIMD en CPUs.\n",
    "\n",
    "**MIMD (Multiple Instruction, Multiple Data)**\n",
    "\n",
    "MIMD, o Multiple Instruction, Multiple Data, es una arquitectura que permite a múltiples unidades de procesamiento ejecutar diferentes instrucciones sobre diferentes conjuntos de datos simultáneamente. Este enfoque es más flexible y adecuado para una amplia gama de aplicaciones, incluyendo sistemas multiprocesador, supercomputadoras y clusters de computadoras.\n",
    "\n",
    "En una arquitectura MIMD, cada procesador tiene su propia unidad de control y puede ejecutar instrucciones independientemente de los otros procesadores. Esto permite que diferentes procesadores ejecuten distintos programas o partes de un programa en diferentes datos al mismo tiempo. Los procesadores en un sistema MIMD pueden trabajar en tareas completamente independientes o colaborar en una tarea distribuida.\n",
    "\n",
    "**Ventajas**\n",
    "\n",
    "- Flexibilidad y versatilidad: MIMD es extremadamente flexible y puede manejar una amplia variedad de tareas y aplicaciones, desde simulaciones científicas hasta servidores web.\n",
    "- Escalabilidad: Permite una fácil escalabilidad agregando más procesadores para aumentar la capacidad de procesamiento.\n",
    "- Eficiencia en multiprogramación: Puede ejecutar múltiples programas o hilos de un programa simultáneamente, aprovechando al máximo los recursos del sistema.\n",
    "\n",
    "**Desventajas**\n",
    "\n",
    "- Complejidad en sincronización: La coordinación y sincronización entre múltiples procesadores pueden ser complejas y costosas en términos de tiempo y recursos.\n",
    "- Consumo de energía: Los sistemas MIMD pueden consumir más energía debido al uso de múltiples unidades de control y procesamiento.\n",
    "- Desafíos en diseño y programación: La programación para sistemas MIMD puede ser más complicada, requiriendo técnicas avanzadas de paralelismo y gestión de recursos.\n",
    "\n",
    "**Ejemplos de implementaciones**\n",
    "\n",
    "- Multiprocesadores simétricos (SMP): Sistemas donde múltiples procesadores comparten la misma memoria y pueden trabajar de manera cooperativa en diferentes partes de una aplicación.\n",
    "- Clusters de computadoras: Conjuntos de computadoras conectadas que trabajan juntas en una tarea común, utilizando paradigmas de programación distribuidos como MPI (Message Passing Interface).\n",
    "- Supercomputadoras: Utilizan miles de procesadores MIMD para realizar cálculos intensivos y simulaciones científicas complejas.\n",
    "\n",
    "#### Comparación entre SIMD y MIMD\n",
    "\n",
    "**Aplicabilidad**\n",
    "- SIMD: Ideal para aplicaciones con alta coherencia de datos y operaciones repetitivas como procesamiento multimedia, gráficos, y análisis de datos.\n",
    "- MIMD: Adecuado para aplicaciones más complejas y diversas, como servidores web, bases de datos, y simulaciones científicas.\n",
    "\n",
    "Eficiencia y flexibilidad\n",
    "- SIMD: Ofrece alta eficiencia en tareas específicas, pero es menos flexible para aplicaciones variadas.\n",
    "- MIMD: Proporciona gran flexibilidad y capacidad de manejar tareas diversas, aunque puede ser menos eficiente en algunas aplicaciones específicas debido a la sobrecarga de control.\n",
    "\n",
    "Diseño y programación\n",
    "- SIMD: Menos complejo en términos de diseño y programación para aplicaciones adecuadas, pero con limitaciones en la adaptabilidad a diferentes tipos de tareas.\n",
    "- MIMD: Más complejo en diseño y programación, pero ofrece un entorno más robusto para una amplia gama de aplicaciones y técnicas de paralelismo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c985a55c-c48e-45a7-9793-a36886eb6468",
   "metadata": {},
   "source": [
    "### Ejemplos teóricos\n",
    "\n",
    "**SIMD (Single Instruction, Multiple Data)**:\n",
    "\n",
    "Teórico:\n",
    "\n",
    "- Procesamiento de imágenes: Imagina que tienes una imagen en escala de grises representada como una matriz de píxeles y quieres aumentar el brillo de cada píxel en un 10%. En una arquitectura SIMD, una única instrucción de suma puede aplicarse simultáneamente a todos los píxeles de la imagen. Esto significa que, en lugar de procesar cada píxel individualmente, el sistema procesa múltiples píxeles al mismo tiempo.\n",
    "\n",
    "- Simulación de dinámica de fluidos: En simulaciones de dinámica de fluidos, se puede dividir el espacio de simulación en celdas y aplicar las mismas ecuaciones a cada celda para calcular las interacciones de fluidos. En una arquitectura SIMD, una única instrucción puede actualizar simultáneamente el estado de múltiples celdas, acelerando considerablemente la simulación.\n",
    "- Multiplicación de matrices: En cálculos científicos, la multiplicación de matrices es una operación común. En SIMD, cada elemento de la matriz resultante puede calcularse simultáneamente aplicando la misma instrucción a diferentes elementos de las matrices de entrada, acelerando significativamente el cálculo.\n",
    "- Procesamiento de señales: Imagina que tienes una señal de audio representada como un array de muestras y quieres aplicar un filtro paso bajo a esta señal. En una arquitectura SIMD, una única instrucción de multiplicación puede aplicarse simultáneamente a múltiples muestras de la señal, filtrando varias partes de la señal al mismo tiempo.\n",
    "\n",
    "**MIMD (Multiple Instruction, Multiple Data)**:\n",
    "\n",
    "Teórico:\n",
    "\n",
    "- Servidores web: Imagina un servidor web que maneja múltiples solicitudes de clientes simultáneamente. Cada solicitud puede requerir diferentes operaciones, como recuperar datos de una base de datos, procesar los datos y generar una página web. En una arquitectura MIMD, diferentes procesadores pueden manejar diferentes solicitudes de clientes de manera concurrente, cada uno ejecutando diferentes instrucciones en diferentes datos.\n",
    "\n",
    "- Simulaciones científicas Complejas: En simulaciones científicas que requieren cálculos complejos y variados, como la predicción del clima, diferentes procesadores pueden trabajar en diferentes partes de la simulación. Por ejemplo, un procesador podría calcular la temperatura en una región específica, mientras que otro calcula la presión atmosférica en una región diferente, y ambos cálculos se ejecutan en paralelo.\n",
    "- Bases de datos distribuidas: En una base de datos distribuida, diferentes nodos pueden ejecutar diferentes consultas SQL en paralelo. Mientras un nodo puede estar ejecutando una consulta de selección, otro nodo puede estar ejecutando una consulta de inserción, y ambos operan sobre diferentes subconjuntos de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736f3dc8-986d-4994-936c-c6adb1cec52f",
   "metadata": {},
   "source": [
    "### Ejemplos prácticos\n",
    "\n",
    "SIMD (Single Instruction, Multiple Data):\n",
    "\n",
    "\n",
    "Procesamiento de Imágenes con OpenCV y NumPy (Python): En este ejemplo, usaremos NumPy y OpenCV para aplicar un filtro de desenfoque a una imagen utilizando operaciones vectorizadas que son una forma de SIMD en Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c5c0802-3279-4ecf-91c3-744994d7d212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def apply_blur(image):\n",
    "    return cv2.GaussianBlur(image, (15, 15), 0)\n",
    "\n",
    "image = cv2.imread('input_image.jpg')\n",
    "blurred_image = apply_blur(image)\n",
    "cv2.imwrite('blurred_image.jpg', blurred_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c766fd-4ed6-4964-8965-d8e1dc729229",
   "metadata": {},
   "source": [
    "Extensiones SIMD en C con SSE: Usando instrucciones SSE en C para sumar elementos de dos vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe27f877-deb4-46c0-91d6-b3458a65fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <xmmintrin.h>\n",
    "\n",
    "void add_float_arrays(float *a, float *b, float *result, int n) {\n",
    "    for (int i = 0; i < n; i += 4) {\n",
    "        __m128 va = _mm_load_ps(&a[i]);\n",
    "        __m128 vb = _mm_load_ps(&b[i]);\n",
    "        __m128 vr = _mm_add_ps(va, vb);\n",
    "        _mm_store_ps(&result[i], vr);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float a[4] = {1.0, 2.0, 3.0, 4.0};\n",
    "    float b[4] = {5.0, 6.0, 7.0, 8.0};\n",
    "    float result[4];\n",
    "    add_float_arrays(a, b, result, 4);\n",
    "    for (int i = 0; i < 4; i++) {\n",
    "        printf(\"%f\\n\", result[i]);\n",
    "    }\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb7e37c-f57e-4fe3-a4bc-1f14942c53cc",
   "metadata": {},
   "source": [
    "Operaciones vectoriales en Numpy (Python): Usar Numpy para realizar operaciones vectoriales en paralelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "897cf2c1-f96c-4722-8c62-261bb14fd369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  8 10 12]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vector_addition(a, b):\n",
    "    return np.add(a, b)\n",
    "\n",
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([5, 6, 7, 8])\n",
    "result = vector_addition(a, b)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a937f8fc-67f4-47fa-b03d-c0e52324930b",
   "metadata": {},
   "source": [
    "Procesamiento SIMD con AVX en C: Usar instrucciones AVX para realizar la suma de elementos de dos vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc6725-d03b-46bf-850e-de1f0b5bab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <immintrin.h>\n",
    "\n",
    "void add_float_arrays_avx(float *a, float *b, float *result, int n) {\n",
    "    for (int i = 0; i < n; i += 8) {\n",
    "        __m256 va = _mm256_load_ps(&a[i]);\n",
    "        __m256 vb = _mm256_load_ps(&b[i]);\n",
    "        __m256 vr = _mm256_add_ps(va, vb);\n",
    "        _mm256_store_ps(&result[i], vr);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float a[8] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0};\n",
    "    float b[8] = {9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0};\n",
    "    float result[8];\n",
    "    add_float_arrays_avx(a, b, result, 8);\n",
    "    for (int i = 0; i < 8; i++) {\n",
    "        printf(\"%f\\n\", result[i]);\n",
    "    }\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470db6ce-12c6-413a-8eab-7738fdb874a1",
   "metadata": {},
   "source": [
    "MIMD (Multiple Instruction, Multiple Data):\n",
    "\n",
    "Servidor Web Concurrente en Python con asyncio: Implementación de un servidor web simple que maneja múltiples solicitudes de clientes en paralelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea3c9b8a-1378-4bb7-a940-37baeea7095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def handle_request(reader, writer):\n",
    "    data = await reader.read(100)\n",
    "    message = data.decode()\n",
    "    print(f\"Received {message}\")\n",
    "    writer.write(data)\n",
    "    await writer.drain()\n",
    "    writer.close()\n",
    "\n",
    "async def main():\n",
    "    server = await asyncio.start_server(handle_request, '127.0.0.1', 8888)\n",
    "    async with server:\n",
    "        await server.serve_forever()\n",
    "\n",
    "#asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189bcc79-4a95-469f-abc3-cbcef60f4acf",
   "metadata": {},
   "source": [
    "Multiprocesamiento en C con Pthreads: Implementación de la suma paralela de elementos en un array usando pthread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2afd7e-4527-4599-b5cf-eb5c880829bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <pthread.h>\n",
    "\n",
    "#define NUM_THREADS 4\n",
    "#define ARRAY_SIZE 1000\n",
    "\n",
    "typedef struct {\n",
    "    int *array;\n",
    "    int start;\n",
    "    int end;\n",
    "    int sum;\n",
    "} ThreadData;\n",
    "\n",
    "void *partial_sum(void *arg) {\n",
    "    ThreadData *data = (ThreadData *)arg;\n",
    "    data->sum = 0;\n",
    "    for (int i = data->start; i < data->end; i++) {\n",
    "        data->sum += data->array[i];\n",
    "    }\n",
    "    pthread_exit(NULL);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int array[ARRAY_SIZE];\n",
    "    for (int i = 0; i < ARRAY_SIZE; i++) {\n",
    "        array[i] = rand() % 10;\n",
    "    }\n",
    "\n",
    "    pthread_t threads[NUM_THREADS];\n",
    "    ThreadData thread_data[NUM_THREADS];\n",
    "    int segment_size = ARRAY_SIZE / NUM_THREADS;\n",
    "\n",
    "    for (int i = 0; i < NUM_THREADS; i++) {\n",
    "        thread_data[i].array = array;\n",
    "        thread_data[i].start = i * segment_size;\n",
    "        thread_data[i].end = (i + 1) * segment_size;\n",
    "        pthread_create(&threads[i], NULL, partial_sum, &thread_data[i]);\n",
    "    }\n",
    "\n",
    "    int total_sum = 0;\n",
    "    for (int i = 0; i < NUM_THREADS; i++) {\n",
    "        pthread_join(threads[i], NULL);\n",
    "        total_sum += thread_data[i].sum;\n",
    "    }\n",
    "\n",
    "    printf(\"Total sum: %d\\n\", total_sum);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc7ef9-3400-4b50-8276-0cacf19fee53",
   "metadata": {},
   "source": [
    "Ejecutar diferentes tareas concurrentes en Python con concurrent.futures: Ejecutar tareas que calculan el cuadrado y el cubo de diferentes números en paralelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10aa9907-5fbf-4ebf-acf9-174f3833595b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "343\n",
      "729\n",
      "216\n",
      "1\n",
      "0\n",
      "16\n",
      "512\n",
      "125\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def calculate_square(n):\n",
    "    return n * n\n",
    "\n",
    "def calculate_cube(n):\n",
    "    return n * n * n\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor: #se crea el threadpool... pque administra grupo de hilos\n",
    "    #envia la funcion con el argumetno i al ejecutor\n",
    "    futures = [executor.submit(calculate_square, i) for i in range(5)] + \\\n",
    "              [executor.submit(calculate_cube, i) for i in range(5, 10)] #lista de tareas para calcular los cubos del 5 al 9\n",
    "    for future in concurrent.futures.as_completed(futures): #itera las tareas en orden que se completen\n",
    "        print(future.result()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c6dbfc-976b-4ca2-9d41-a5424dd37e35",
   "metadata": {},
   "source": [
    "Simulación de Monte Carlo en C con Pthreads: Usar pthread para realizar simulaciones de Monte Carlo en paralelo para estimar el valor de Pi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e782fb6-7b88-443e-8e5a-2bd38cb785d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <pthread.h>\n",
    "#include <math.h>\n",
    "\n",
    "#define NUM_THREADS 4\n",
    "#define NUM_POINTS 1000000\n",
    "\n",
    "typedef struct {\n",
    "    int points_inside_circle;\n",
    "    int num_points;\n",
    "} ThreadData;\n",
    "\n",
    "void *monte_carlo_pi(void *arg) {\n",
    "    ThreadData *data = (ThreadData *)arg;\n",
    "    int points_inside_circle = 0;\n",
    "    unsigned int seed = rand();\n",
    "    for (int i = 0; i < data->num_points; i++) {\n",
    "        double x = (double)rand_r(&seed) / RAND_MAX;\n",
    "        double y = (double)rand_r(&seed) / RAND_MAX;\n",
    "        if (x * x + y * y <= 1.0) {\n",
    "            points_inside_circle++;\n",
    "        }\n",
    "    }\n",
    "    data->points_inside_circle = points_inside_circle;\n",
    "    pthread_exit(NULL);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    pthread_t threads[NUM_THREADS];\n",
    "    ThreadData thread_data[NUM_THREADS];\n",
    "    int points_per_thread = NUM_POINTS / NUM_THREADS;\n",
    "\n",
    "    for (int i = 0; i < NUM_THREADS; i++) {\n",
    "        thread_data[i].num_points = points_per_thread;\n",
    "        pthread_create(&threads[i], NULL, monte_carlo_pi, &thread_data[i]);\n",
    "    }\n",
    "\n",
    "    int total_points_inside_circle = 0;\n",
    "    for (int i = 0; i < NUM_THREADS; i++) {\n",
    "        pthread_join(threads[i], NULL);\n",
    "        total_points_inside_circle += thread_data[i].points_inside_circle;\n",
    "    }\n",
    "\n",
    "    double pi_estimate = (4.0 * total_points_inside_circle) / NUM_POINTS;\n",
    "    printf(\"Estimated value of Pi: %f\\n\", pi_estimate);\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae065998-9c61-4f23-a9ae-51c8cacc1cda",
   "metadata": {},
   "source": [
    "### Paralelismo a nivel de instrucción (ILP - Instruction-Level Parallelism)\n",
    "\n",
    "El paralelismo a nivel de instrucción (ILP, por sus siglas en inglés) es una técnica de arquitectura de computadoras que busca mejorar el rendimiento de los procesadores al ejecutar múltiples instrucciones en paralelo dentro de un solo núcleo de procesamiento. A diferencia del paralelismo de tareas o datos, que distribuye las cargas de trabajo entre múltiples núcleos o procesadores, ILP se centra en la ejecución simultánea de múltiples instrucciones individuales desde un flujo de instrucciones secuencial.\n",
    "\n",
    "**Conceptos fundamentales**\n",
    "\n",
    "- Pipeline de instrucciones: El pipeline de instrucciones es una técnica básica que permite la superposición de diferentes etapas de procesamiento de instrucciones, tales como la búsqueda, decodificación, ejecución, y escritura de resultados. Cada etapa del pipeline puede operar en una instrucción diferente al mismo tiempo, lo que permite que múltiples instrucciones sean procesadas simultáneamente en distintas fases del pipeline.\n",
    "\n",
    "- Superescalaridad: Un procesador superescalar puede emitir y ejecutar más de una instrucción por ciclo de reloj. Esto se logra mediante la duplicación de ciertas unidades funcionales dentro del procesador, como las unidades de punto flotante o las unidades de enteros, permitiendo que múltiples instrucciones sean ejecutadas en paralelo.\n",
    "\n",
    "- Reordenamiento de instrucciones: Para maximizar la utilización del pipeline, los procesadores modernos implementan técnicas de reordenamiento de instrucciones. Esto permite que las instrucciones que no tienen dependencias de datos puedan ser ejecutadas antes que otras que sí las tienen, reduciendo así los ciclos de espera y aumentando el paralelismo.\n",
    "\n",
    "Predicción de bifurcaciones: Las bifurcaciones en el flujo de control de un programa pueden causar retrasos en el pipeline, ya que el procesador debe decidir cuál camino de ejecución seguir. La predicción de bifurcaciones intenta anticipar la dirección que tomará una bifurcación y carga las instrucciones correspondientes en el pipeline. Si la predicción es correcta, el procesamiento continúa sin interrupciones; si es incorrecta, las instrucciones incorrectas deben ser descartadas, lo que introduce un retraso.\n",
    "\n",
    "Ejecución especulativa: La ejecución especulativa es una técnica que trabaja en conjunto con la predicción de bifurcaciones. El procesador ejecuta instrucciones basadas en predicciones antes de confirmar que son necesarias. Si la predicción es correcta, se ha ganado tiempo al haber adelantado trabajo; si no, los resultados se descartan y el procesador reanudará la ejecución desde el punto correcto.\n",
    "\n",
    "**Ejemplos y técnicas de implementación**\n",
    "\n",
    "- Pipeline clásico:\n",
    "    * Etapas del pipeline: En un pipeline típico, hay varias etapas que una instrucción debe atravesar. Un ejemplo básico incluye las etapas de fetch (búsqueda), decode (decodificación), execute (ejecución), memory access (acceso a memoria) y write-back (escritura de resultados).\n",
    "    *  Mejora del rendimiento: Al tener múltiples instrucciones en diferentes etapas del pipeline simultáneamente, se incrementa el rendimiento al aprovechar al máximo cada ciclo de reloj.\n",
    "- Procesadores superescalares:\n",
    "   * Duplicación de unidades funcionales: Un procesador superescalar puede tener múltiples unidades aritmético-lógicas (ALU), lo que le permite ejecutar múltiples operaciones aritméticas en paralelo.\n",
    "   * Decodificadores múltiples: Varios decodificadores de instrucciones permiten que múltiples instrucciones sean decodificadas y emitidas al mismo tiempo.\n",
    "  \n",
    "- Out-of-Order execution:\n",
    "   * Desplazamiento de dependencias: Las instrucciones que no dependen de los resultados de otras instrucciones pueden ser ejecutadas antes de tiempo, adelantando el trabajo en lugar de esperar a que las instrucciones previas se completen.\n",
    "   * Reensamblado de resultados: Al final, los resultados de las instrucciones se reensamblan en el orden correcto, asegurando que el flujo de programa se mantenga coherente.\n",
    "\n",
    "- Predicción de Bifurcaciones:\n",
    "   * Historial de bifurcaciones: Los procesadores utilizan tablas de historial de bifurcaciones que registran los patrones de bifurcaciones anteriores para hacer predicciones más precisas.\n",
    "   * Algoritmos de predicción: Algoritmos como la predicción bimodal y la predicción con historial global se utilizan para mejorar la exactitud de las predicciones.\n",
    "\n",
    "- Ejecución especulativa:\n",
    "   * Ejecución basada en predicciones: Las instrucciones se ejecutan especulativamente basadas en la predicción de bifurcaciones. Si la predicción es incorrecta, el procesador deshace las instrucciones ejecutadas incorrectamente.\n",
    "   * Manejo de errores: Mecanismos de control garantizan que cualquier efecto secundario de las ejecuciones especulativas incorrectas sea revertido, manteniendo la integridad del estado del procesador.\n",
    "\n",
    "**Beneficios del ILP**\n",
    "\n",
    "- ILP permite a los procesadores ejecutar múltiples instrucciones en paralelo, lo que resulta en un mejor rendimiento y una mayor eficiencia en el uso del hardware disponible.\n",
    "- Al reordenar las instrucciones y predecir bifurcaciones, se minimizan los ciclos de espera y se maximiza la utilización del pipeline, reduciendo los tiempos muertos y mejorando la velocidad de procesamiento.\n",
    "- La capacidad de ejecutar instrucciones fuera de orden y especulativamente proporciona flexibilidad, permitiendo que el procesador maneje dependencias de datos y bifurcaciones de manera más eficiente.\n",
    "\n",
    "**Desafíos del ILP**\n",
    "- La implementación de ILP requiere hardware complejo, incluyendo múltiples unidades funcionales, decodificadores y mecanismos de control de dependencias, lo que incrementa los costos y la dificultad de diseño.\n",
    "- La cantidad de paralelismo disponible a nivel de instrucción está limitada por la naturaleza del código y las dependencias de datos, lo que puede restringir la cantidad de ILP que se puede explotar.\n",
    "- El hardware adicional y las operaciones especulativas pueden incrementar significativamente el consumo de energía, lo cual es un factor crítico en el diseño de procesadores, especialmente en dispositivos móviles y sistemas embebidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fb3c55-c708-4bdc-aaab-dc3a825932ed",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "1 . Explica cómo funciona el pipeline en una CPU moderna. Describa las diferentes etapas del pipeline y cómo se superponen para mejorar el rendimiento del procesador.\n",
    "\n",
    " Respuesta esperada:\n",
    " \n",
    " Debes explicar:\n",
    "\n",
    "- Las etapas típicas del pipeline (Fetch, Decode, Execute, Memory Access, Write-back).\n",
    "- Cómo cada etapa del pipeline puede trabajar en una instrucción diferente simultáneamente.\n",
    "-  Cómo el pipelining mejora el rendimiento al permitir que múltiples instrucciones estén en diferentes fases de ejecución al mismo tiempo.\n",
    "\n",
    "2 . Describe el concepto de reordenamiento de instrucciones (out-of-order execution) y cómo ayuda a mejorar el rendimiento en procesadores modernos. Incluya un ejemplo ilustrativo.\n",
    "\n",
    " Respuesta esperada:\n",
    " \n",
    " Debes explicar:\n",
    "    \n",
    "- Cómo el procesador puede reordenar las instrucciones para ejecutar otras que no tengan dependencias mientras espera por las que sí tienen.\n",
    "- Ejemplo: Si una instrucción A está esperando un dato que se está calculando en otra instrucción B, el procesador puede ejecutar una instrucción C que no depende de B mientras espera.\n",
    "\n",
    "3 . Discute cómo la predicción de bifurcaciones (branch prediction) se utiliza para mejorar el flujo de instrucciones en el pipeline. Explica los conceptos de predicción estática y dinámica.\n",
    "\n",
    " Respuesta esperada:\n",
    " \n",
    " Debes explicar:\n",
    "    \n",
    "- Predicción estática: decisiones fijas basadas en reglas predefinidas (e.g., siempre predecir que la bifurcación no se tomará).\n",
    "- Predicción dinámica: decisiones basadas en el historial de ejecución de las bifurcaciones (e.g., tablas de historial de bifurcaciones).\n",
    "- Cómo estas técnicas reducen los ciclos de burbuja en el pipeline al anticipar la dirección de las bifurcaciones.\n",
    "\n",
    "4 . Implementa un programa en C que simule el pipeline de un procesador simple con las etapas de Fetch, Decode, Execute, Memory Access, y Write-back. Simule la ejecución de un conjunto de instrucciones y muestre cómo las instrucciones se superponen en el pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2038929-d250-417e-be04-de00eb032810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "\n",
    "#define NUM_INSTRUCTIONS 5\n",
    "\n",
    "const char *instructions[NUM_INSTRUCTIONS] = {\n",
    "    \"LOAD R1, 100\",\n",
    "    \"ADD R2, R1, R3\",\n",
    "    \"STORE R2, 200\",\n",
    "    \"SUB R4, R2, R5\",\n",
    "    \"LOAD R3, 300\"\n",
    "};\n",
    "\n",
    "void fetch(int cycle) {\n",
    "    printf(\"Cycle %d: Fetching instruction\\n\", cycle);\n",
    "}\n",
    "\n",
    "void decode(int cycle) {\n",
    "    printf(\"Cycle %d: Decoding instruction\\n\", cycle);\n",
    "}\n",
    "\n",
    "void execute(int cycle) {\n",
    "    printf(\"Cycle %d: Executing instruction\\n\", cycle);\n",
    "}\n",
    "\n",
    "void memory_access(int cycle) {\n",
    "    printf(\"Cycle %d: Accessing memory\\n\", cycle);\n",
    "}\n",
    "\n",
    "void write_back(int cycle) {\n",
    "    printf(\"Cycle %d: Writing back to register\\n\", cycle);\n",
    "}\n",
    "\n",
    "void simulate_pipeline() {\n",
    "    for (int i = 0; i < NUM_INSTRUCTIONS + 4; i++) {\n",
    "        if (i < NUM_INSTRUCTIONS) {\n",
    "            printf(\"Instruction: %s\\n\", instructions[i]);\n",
    "        }\n",
    "        if (i >= 4) {\n",
    "            write_back(i);\n",
    "        }\n",
    "        if (i >= 3) {\n",
    "            memory_access(i);\n",
    "        }\n",
    "        if (i >= 2) {\n",
    "            execute(i);\n",
    "        }\n",
    "        if (i >= 1) {\n",
    "            decode(i);\n",
    "        }\n",
    "        if (i < NUM_INSTRUCTIONS) {\n",
    "            fetch(i);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    simulate_pipeline();\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963ececc-e6c3-412a-a993-bfc42deab607",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a67e7b7-0311-429a-83af-4379ef3e17e2",
   "metadata": {},
   "source": [
    "5 . Implementa un programa en C que demuestre el reordenamiento de instrucciones. Crea un conjunto de instrucciones donde algunas dependan de los resultados de otras y optimice el orden de ejecución para mejorar el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4407043b-c81d-47f6-9c8b-de06181ec498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "\n",
    "void instruction_A() {\n",
    "    printf(\"Instruction A: Load data into R1\\n\");\n",
    "}\n",
    "\n",
    "void instruction_B() {\n",
    "    printf(\"Instruction B: Perform computation using R1\\n\");\n",
    "}\n",
    "\n",
    "void instruction_C() {\n",
    "    printf(\"Instruction C: Independent computation\\n\");\n",
    "}\n",
    "\n",
    "void instruction_D() {\n",
    "    printf(\"Instruction D: Use result from B\\n\");\n",
    "}\n",
    "\n",
    "void execute_instructions_in_order() {\n",
    "    instruction_A();\n",
    "    instruction_B();\n",
    "    instruction_C();\n",
    "    instruction_D();\n",
    "}\n",
    "\n",
    "void execute_instructions_out_of_order() {\n",
    "    instruction_A();\n",
    "    instruction_C(); // Moved up to avoid waiting for instruction B\n",
    "    instruction_B();\n",
    "    instruction_D();\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"Executing instructions in order:\\n\");\n",
    "    execute_instructions_in_order();\n",
    "    printf(\"\\n\");\n",
    "\n",
    "    printf(\"Executing instructions out of order:\\n\");\n",
    "    execute_instructions_out_of_order();\n",
    "    printf(\"\\n\");\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5344243a-d5b2-40e1-9229-76c507e7ea7d",
   "metadata": {},
   "source": [
    "6 . Implementa un programa en Python que simule un predictor de bifurcaciones simple. Use un historial para predecir si una bifurcación será tomada o no y ajuste las predicciones basadas en los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d71302f-97ff-4ec5-8b20-dfa37ec28eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: False, Actual: True\n",
      "Predicted: False, Actual: False\n",
      "Predicted: True, Actual: False\n",
      "Predicted: False, Actual: True\n"
     ]
    }
   ],
   "source": [
    "class BranchPredictor: #predecir y actualizar el historial de predicciones\n",
    "    def __init__(self):\n",
    "        self.history = {} #almacena historial de predicciones\n",
    "\n",
    "    def predict(self, branch):\n",
    "        return self.history.get(branch, False) #retorna la prediccion almacenada si la rama no esta en diccionario retorn false\n",
    "\n",
    "    def update(self, branch, taken): #actualza el diccionario con el resultado actual de la rama\n",
    "        self.history[branch] = taken\n",
    "\n",
    "def main():\n",
    "    predictor = BranchPredictor() #crean una instancia\n",
    "    branches = [(\"branch1\", True), (\"branch2\", False), (\"branch1\", False), (\"branch2\", True)] #diferentes tuplas contiene el nombre de una rama que indica si fue tomada o ono\n",
    "\n",
    "    for branch, taken in branches: \n",
    "        prediction = predictor.predict(branch) #obitene la prediccion actual de la rama\n",
    "        print(f\"Predicted: {prediction}, Actual: {taken}\")  \n",
    "        predictor.update(branch, taken) #actualiza el predictor \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc97642-ba07-4c03-8170-d26c61787801",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14926d5-be36-4895-b579-f37e7799fa24",
   "metadata": {},
   "source": [
    "7 . Implementa un programa en Python que demuestre el paralelismo de instrucciones utilizando hilos. Crea un conjunto de tareas independientes que se ejecuten en paralelo utilizando el módulo threading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1edd752b-c3b9-42ce-aeef-f614907ed82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1: Executing\n",
      "Task 2: Executing\n",
      "Task 3: Executing\n",
      "Task 4: Executing\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "def task_1():\n",
    "    print(\"Task 1: Executing\")\n",
    "\n",
    "def task_2():\n",
    "    print(\"Task 2: Executing\")\n",
    "\n",
    "def task_3():\n",
    "    print(\"Task 3: Executing\")\n",
    "\n",
    "def task_4():\n",
    "    print(\"Task 4: Executing\")\n",
    "\n",
    "def main():\n",
    "    threads = []\n",
    "    tasks = [task_1, task_2, task_3, task_4]\n",
    "    for task in tasks:\n",
    "        thread = threading.Thread(target=task) #se crea un thread donde target es la funcion que el hilo ejecutara\n",
    "        threads.append(thread) #se agrega el objeto a la lista\n",
    "        thread.start() #ejecuta en paralelo\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join() #blloquea la ejecucion del programa principal hasta que el hilo haya terminado su eje\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3abe98-a076-407c-b43b-1a0483ff9e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
