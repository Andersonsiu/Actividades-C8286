{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67d1b97f-1440-4e2b-8e10-44f6d08455ef",
   "metadata": {},
   "source": [
    "\n",
    "### Memoria Caché \n",
    "\n",
    "La memoria caché es un componente esencial en la arquitectura de los sistemas de computación modernos. Sirve como una memoria de alta velocidad que almacena temporalmente los datos más utilizados, mejorando significativamente el rendimiento del sistema al reducir el tiempo de acceso a los datos. En el contexto de la programación paralela y distribuida, la gestión eficiente de la memoria caché es crucial para maximizar el rendimiento y minimizar la latencia de las operaciones.\n",
    "\n",
    "**Tamaños de caché L1, L2, L3**\n",
    "\n",
    "La memoria caché se organiza en niveles jerárquicos para equilibrar el rendimiento y el costo. Estos niveles son comúnmente conocidos como L1, L2 y L3.\n",
    "\n",
    "- Caché L1: Es la memoria caché más cercana al núcleo del procesador. Generalmente, cada núcleo de CPU tiene su propia caché L1, lo que permite un acceso extremadamente rápido a los datos. La caché L1 suele dividirse en dos partes: una caché de instrucciones (L1i) y una caché de datos (L1d). Los tamaños típicos de la caché L1 varían entre 32KB y 64KB por núcleo. La latencia de la caché L1 es muy baja, lo que permite tiempos de acceso de unos pocos ciclos de reloj.\n",
    "\n",
    "- Caché L2: Esta caché es más grande y ligeramente más lenta que la L1. En muchos diseños modernos, cada núcleo de CPU tiene su propia caché L2, pero en algunos casos, puede ser compartida entre varios núcleos. Los tamaños típicos de la caché L2 oscilan entre 256KB y 512KB por núcleo, con una latencia de acceso mayor que la L1 pero aún bastante baja, generalmente entre 10 y 20 ciclos de reloj.\n",
    "\n",
    "- Caché L3: Es la más grande y la más lenta de las tres. La caché L3 generalmente es compartida entre todos los núcleos de un procesador. Los tamaños de la caché L3 pueden variar significativamente, desde 2MB hasta 32MB o más, dependiendo del diseño del procesador. La latencia de acceso a la caché L3 es considerablemente mayor que la de las cachés L1 y L2, típicamente en el rango de 30 a 50 ciclos de reloj.\n",
    "\n",
    "**Políticas de reemplazo de Caché**\n",
    "\n",
    "Dado que las memorias caché tienen un tamaño limitado, es esencial contar con políticas de reemplazo eficientes para decidir qué datos mantener y cuáles descartar cuando la caché se llena. Algunas de las políticas de reemplazo más comunes incluyen:\n",
    "\n",
    "- Least Recently Used (LRU): Esta política reemplaza el bloque de caché que no ha sido usado por el mayor tiempo. LRU es popular debido a su simplicidad y eficacia, aunque puede ser costoso en términos de hardware y complejidad computacional.\n",
    "\n",
    "- First In, First Out (FIFO): Reemplaza el bloque más antiguo en la caché, sin considerar cuándo fue accedido por última vez. FIFO es fácil de implementar pero puede no ser tan eficiente como LRU en términos de rendimiento.\n",
    "\n",
    "- Least Frequently Used (LFU): Esta política reemplaza el bloque que ha sido usado con menor frecuencia. LFU puede ser más difícil de implementar debido a la necesidad de mantener un contador para cada bloque de caché.\n",
    "\n",
    "- Random Replacement: Reemplaza un bloque al azar. Esta política es fácil de implementar y, sorprendentemente, puede ser eficaz en ciertos escenarios.\n",
    "\n",
    "**Latencia de caché**\n",
    "\n",
    "La latencia de la caché es el tiempo que tarda el procesador en acceder a los datos almacenados en la caché. La latencia está influenciada por varios factores, incluyendo el tamaño de la caché, su ubicación jerárquica (L1, L2, L3) y la política de reemplazo utilizada. En términos de programación paralela y distribuida, la latencia de la caché puede tener un impacto significativo en el rendimiento de las aplicaciones, especialmente aquellas que requieren un acceso intensivo a los datos.\n",
    "\n",
    "La baja latencia de la caché L1 permite a los procesadores realizar operaciones rápidas y eficientes, reduciendo el tiempo de espera para acceder a los datos. Sin embargo, a medida que se escala hacia cachés L2 y L3, la latencia aumenta, lo que puede ralentizar las operaciones si los datos necesarios no están presentes en la caché de nivel superior.\n",
    "\n",
    "**Gestión de caché en la programación paralela y distribuida**\n",
    "\n",
    "En entornos de programación paralela y distribuida, la gestión de la caché se vuelve aún más crítica. La concurrencia y la paralelización pueden llevar a situaciones donde múltiples núcleos acceden a los mismos datos, creando posibles conflictos y problemas de coherencia. Algunas de las estrategias y técnicas utilizadas para gestionar eficientemente la caché en estos entornos incluyen:\n",
    "\n",
    "- Localidad de referencia: Optimizar los algoritmos para mejorar la localidad temporal y espacial puede aumentar significativamente la eficiencia de la caché. La localidad temporal se refiere a la reutilización de datos en intervalos cortos de tiempo, mientras que la localidad espacial se refiere al acceso a datos cercanos en la memoria.\n",
    "\n",
    "- Afinidad de núcleo: Asignar tareas a núcleos específicos y mantener la afinidad de los datos a esos núcleos puede reducir la necesidad de transferir datos entre cachés de diferentes núcleos, mejorando así la eficiencia.\n",
    "\n",
    "- Coherencia de caché: En sistemas multinúcleo, mantener la coherencia de caché es crucial. Protocolos de coherencia de caché como MESI (Modified, Exclusive, Shared, Invalid) y MOESI (Modified, Owner, Exclusive, Shared, Invalid) son utilizados para asegurar que todos los núcleos vean una visión consistente de la memoria.\n",
    "\n",
    "- Prefetching: El prefetching es una técnica donde se cargan datos en la caché antes de que sean necesitados, basándose en patrones de acceso previsibles. Esto puede reducir la latencia de caché al tener los datos ya disponibles cuando se requieren.\n",
    "\n",
    "- Particionado de caché: Dividir la caché en segmentos asignados a diferentes núcleos o procesos puede reducir la interferencia y mejorar el rendimiento, especialmente en sistemas donde las tareas tienen diferentes patrones de acceso a los datos.\n",
    "\n",
    "- Optimización de algoritmos: Adaptar los algoritmos para ser más \"cache-friendly\" es una técnica clave. Esto puede implicar el reordenamiento de bucles, el uso de estructuras de datos adecuadas y la minimización de accesos a memoria dispersos.\n",
    "\n",
    "\n",
    "El impacto de la gestión de caché en el rendimiento de las aplicaciones paralelas y distribuidas no puede ser subestimado. En aplicaciones de alto rendimiento, como la computación científica y la simulación, la eficiencia de la caché puede determinar la viabilidad del procesamiento en tiempo real. La optimización del uso de la caché puede llevar a mejoras significativas en el rendimiento, reduciendo la latencia de acceso a datos y mejorando el throughput general del sistema.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001ef500-68c5-45f8-a0ea-0c036ee61e6f",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "1 . Analiza este ejercicio te permitirá medir la latencia de acceso a diferentes tamaños de datos en Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e44bc52-ed8a-418c-8906-968401ec5059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def measure_latency(array_size):\n",
    "    array = np.zeros(array_size)\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    # Acceder a todos los elementos del array\n",
    "    for i in range(array_size):\n",
    "        array[i] += 1\n",
    "    \n",
    "    end_time = time.perf_counter()\n",
    "    latency = end_time - start_time\n",
    "    return latency\n",
    "\n",
    "sizes = [10**3, 10**4, 10**5, 10**6, 10**7]\n",
    "latencies = []\n",
    "\n",
    "for size in sizes:\n",
    "    latency = measure_latency(size)\n",
    "    latencies.append(latency)\n",
    "    print(f\"Tamaño del array: {size}, Latencia: {latency:.6f} segundos\")\n",
    "\n",
    "# Graficar los resultados\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(sizes, latencies, marker='o')\n",
    "plt.xlabel('Tamaño del Array')\n",
    "plt.ylabel('Latencia (segundos)')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.title('Latencia de Acceso a Datos en Diferentes Tamaños de Array')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1578e963-dece-4f90-9449-7b06fa8f2722",
   "metadata": {},
   "source": [
    "2 . Analiza la importancia de la localidad de referencia en el acceso a datos. Compara el tiempo de acceso cuando se recorren los datos de manera secuencial versus de manera aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0de30b-2eac-4f9c-8824-4dfc586f14ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def measure_access_time(array, indices):\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    for i in indices:\n",
    "        array[i] += 1\n",
    "    \n",
    "    end_time = time.perf_counter()\n",
    "    access_time = end_time - start_time\n",
    "    return access_time\n",
    "\n",
    "size = 10**6\n",
    "array = np.zeros(size)\n",
    "sequential_indices = list(range(size))\n",
    "random_indices = sequential_indices.copy()\n",
    "random.shuffle(random_indices)\n",
    "\n",
    "sequential_time = measure_access_time(array, sequential_indices)\n",
    "random_time = measure_access_time(array, random_indices)\n",
    "\n",
    "print(f\"Tiempo de acceso secuencial: {sequential_time:.6f} segundos\")\n",
    "print(f\"Tiempo de acceso aleatorio: {random_time:.6f} segundos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce589bab-321c-4bf4-afbc-b5d3764ed050",
   "metadata": {},
   "source": [
    "3 . Analiza cómo la coherencia de caché afecta el rendimiento en un entorno multihilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4431a6-be25-4b33-83f8-cbb758037691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def worker(shared_data, start, end):\n",
    "    for i in range(start, end):\n",
    "        shared_data[i] += 1\n",
    "\n",
    "size = 10**6\n",
    "shared_data = np.zeros(size)\n",
    "num_threads = 4\n",
    "threads = []\n",
    "\n",
    "chunk_size = size // num_threads\n",
    "for i in range(num_threads):\n",
    "    start = i * chunk_size\n",
    "    end = (i + 1) * chunk_size\n",
    "    thread = threading.Thread(target=worker, args=(shared_data, start, end))\n",
    "    threads.append(thread)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"Tiempo total con {num_threads} hilos: {total_time:.6f} segundos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ffe760-5fed-4e97-b45f-f56013a25d8f",
   "metadata": {},
   "source": [
    "4 . Analiza el código que implementa una forma sencilla de prefetching de datos, cargando datos en la caché antes de que sean necesarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faed4dc5-68e0-48cc-af86-36a0d233a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefetch_data(array, indices, prefetch_distance):\n",
    "    for i in range(len(indices) - prefetch_distance):\n",
    "        _ = array[indices[i + prefetch_distance]]  # Prefetch\n",
    "        array[indices[i]] += 1  # Access\n",
    "\n",
    "size = 10**6\n",
    "array = np.zeros(size)\n",
    "indices = list(range(size))\n",
    "random.shuffle(indices)\n",
    "prefetch_distance = 10\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "prefetch_data(array, indices, prefetch_distance)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "print(f\"Tiempo con prefetching: {total_time:.6f} segundos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8603aeb6-da78-44fc-b9ae-95482dceeae0",
   "metadata": {},
   "source": [
    "5 . Analiza  cómo la afinidad de núcleo puede influir en el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b37547-cd38-43d0-a3e2-312704edcd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def core_affinity_worker(core_id, shared_data, start, end):\n",
    "    p = multiprocessing.current_process()\n",
    "    p.cpu_affinity([core_id])  # Asigna el núcleo específico\n",
    "    for i in range(start, end):\n",
    "        shared_data[i] += 1\n",
    "\n",
    "size = 10**6\n",
    "shared_data = np.zeros(size)\n",
    "num_processes = 4\n",
    "processes = []\n",
    "\n",
    "chunk_size = size // num_processes\n",
    "for i in range(num_processes):\n",
    "    start = i * chunk_size\n",
    "    end = (i + 1) * chunk_size\n",
    "    process = multiprocessing.Process(target=core_affinity_worker, args=(i, shared_data, start, end))\n",
    "    processes.append(process)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "for process in processes:\n",
    "    process.start()\n",
    "\n",
    "for process in processes:\n",
    "    process.join()\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"Tiempo total con afinidad de núcleo y {num_processes} procesos: {total_time:.6f} segundos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d1e816-b42c-4492-87c7-c98916a2ce88",
   "metadata": {},
   "source": [
    "6 . Implementa una política de reemplazo LRU para una caché y simula el acceso a los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb18062-2115-412d-9b6f-11c9fcff6b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class LRUCache:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.cache = OrderedDict()\n",
    "\n",
    "    def get(self, key):\n",
    "        if key not in self.cache:\n",
    "            return -1\n",
    "        self.cache.move_to_end(key)\n",
    "        return self.cache[key]\n",
    "\n",
    "    def put(self, key, value):\n",
    "        if key in self.cache:\n",
    "            self.cache.move_to_end(key)\n",
    "        self.cache[key] = value\n",
    "        if len(self.cache) > self.capacity:\n",
    "            self.cache.popitem(last=False)\n",
    "\n",
    "# Simulación de acceso\n",
    "cache = LRUCache(5)\n",
    "operations = [(\"put\", 1, \"data1\"), (\"put\", 2, \"data2\"), (\"get\", 1), (\"put\", 3, \"data3\"),\n",
    "              (\"put\", 4, \"data4\"), (\"put\", 5, \"data5\"), (\"get\", 2), (\"put\", 6, \"data6\"),\n",
    "              (\"get\", 3), (\"get\", 1)]\n",
    "\n",
    "for op in operations:\n",
    "    if op[0] == \"put\":\n",
    "        cache.put(op[1], op[2])\n",
    "        print(f\"Put: {op[1]} -> {op[2]}\")\n",
    "    elif op[0] == \"get\":\n",
    "        result = cache.get(op[1])\n",
    "        print(f\"Get: {op[1]} -> {result}\")\n",
    "    print(f\"Estado de la caché: {list(cache.cache.items())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afa23fb-eb83-4ea4-b3f4-0bc950535760",
   "metadata": {},
   "source": [
    "7 . Implementa una política de reemplazo FIFO para una caché y simula el acceso a los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653337c4-a217-458d-ab00-6bcf7abbe29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class FIFOCache:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.cache = {}\n",
    "        self.order = deque()\n",
    "\n",
    "    def get(self, key):\n",
    "        return self.cache.get(key, -1)\n",
    "\n",
    "    def put(self, key, value):\n",
    "        if key not in self.cache:\n",
    "            if len(self.cache) >= self.capacity:\n",
    "                oldest = self.order.popleft()\n",
    "                del self.cache[oldest]\n",
    "            self.cache[key] = value\n",
    "            self.order.append(key)\n",
    "        else:\n",
    "            self.cache[key] = value\n",
    "\n",
    "# Simulación de acceso\n",
    "cache = FIFOCache(3)\n",
    "operations = [(\"put\", 1, \"data1\"), (\"put\", 2, \"data2\"), (\"put\", 3, \"data3\"), (\"get\", 1),\n",
    "              (\"put\", 4, \"data4\"), (\"get\", 2), (\"put\", 5, \"data5\"), (\"get\", 3), (\"get\", 1)]\n",
    "\n",
    "for op in operations:\n",
    "    if op[0] == \"put\":\n",
    "        cache.put(op[1], op[2])\n",
    "        print(f\"Put: {op[1]} -> {op[2]}\")\n",
    "    elif op[0] == \"get\":\n",
    "        result = cache.get(op[1])\n",
    "        print(f\"Get: {op[1]} -> {result}\")\n",
    "    print(f\"Estado de la caché: {list(cache.cache.items())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754f386b-644f-4efa-b9fd-1c337c627474",
   "metadata": {},
   "source": [
    "8.Implementa una política de reemplazo LFU (Reemplazo Least Frequently Used) para una caché y simula el acceso a los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb13832f-7f8e-4f51-bad5-454edbc2159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "class LFUCache:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.cache = {}\n",
    "        self.freq = defaultdict(OrderedDict)\n",
    "        self.min_freq = 0\n",
    "\n",
    "    def get(self, key):\n",
    "        if key not in self.cache:\n",
    "            return -1\n",
    "        freq = self.cache[key][1]\n",
    "        self.cache[key][1] += 1\n",
    "        value = self.cache[key][0]\n",
    "        del self.freq[freq][key]\n",
    "        if not self.freq[freq]:\n",
    "            del self.freq[freq]\n",
    "            if self.min_freq == freq:\n",
    "                self.min_freq += 1\n",
    "        self.freq[freq + 1][key] = None\n",
    "        return value\n",
    "\n",
    "    def put(self, key, value):\n",
    "        if self.capacity == 0:\n",
    "            return\n",
    "        if key in self.cache:\n",
    "            self.cache[key][0] = value\n",
    "            self.get(key)\n",
    "            return\n",
    "        if len(self.cache) >= self.capacity:\n",
    "            evict = next(iter(self.freq[self.min_freq]))\n",
    "            del self.freq[self.min_freq][evict]\n",
    "            del self.cache[evict]\n",
    "        self.cache[key] = [value, 1]\n",
    "        self.freq[1][key] = None\n",
    "        self.min_freq = 1\n",
    "\n",
    "# Simulación de acceso\n",
    "cache = LFUCache(3)\n",
    "operations = [(\"put\", 1, \"data1\"), (\"put\", 2, \"data2\"), (\"put\", 3, \"data3\"), (\"get\", 1),\n",
    "              (\"put\", 4, \"data4\"), (\"get\", 2), (\"put\", 5, \"data5\"), (\"get\", 3), (\"get\", 1)]\n",
    "\n",
    "for op in operations:\n",
    "    if op[0] == \"put\":\n",
    "        cache.put(op[1], op[2])\n",
    "        print(f\"Put: {op[1]} -> {op[2]}\")\n",
    "    elif op[0] == \"get\":\n",
    "        result = cache.get(op[1])\n",
    "        print(f\"Get: {op[1]} -> {result}\")\n",
    "    print(f\"Estado de la caché: {list(cache.cache.items())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276d5e99-5666-4998-9a68-62456daaa886",
   "metadata": {},
   "source": [
    "9 .  Implementa una política de reemplazo aleatorio para una caché y simula el acceso a los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6908dd8-1b6f-4079-8287-741bb975249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class RandomCache:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.cache = {}\n",
    "\n",
    "    def get(self, key):\n",
    "        return self.cache.get(key, -1)\n",
    "\n",
    "    def put(self, key, value):\n",
    "        if key not in self.cache:\n",
    "            if len(self.cache) >= self.capacity:\n",
    "                evict = random.choice(list(self.cache.keys()))\n",
    "                del self.cache[evict]\n",
    "        self.cache[key] = value\n",
    "\n",
    "# Simulación de acceso\n",
    "cache = RandomCache(3)\n",
    "operations = [(\"put\", 1, \"data1\"), (\"put\", 2, \"data2\"), (\"put\", 3, \"data3\"), (\"get\", 1),\n",
    "              (\"put\", 4, \"data4\"), (\"get\", 2), (\"put\", 5, \"data5\"), (\"get\", 3), (\"get\", 1)]\n",
    "\n",
    "for op in operations:\n",
    "    if op[0] == \"put\":\n",
    "        cache.put(op[1], op[2])\n",
    "        print(f\"Put: {op[1]} -> {op[2]}\")\n",
    "    elif op[0] == \"get\":\n",
    "        result = cache.get(op[1])\n",
    "        print(f\"Get: {op[1]} -> {result}\")\n",
    "    print(f\"Estado de la caché: {list(cache.cache.items())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a9b9af-b34b-4aa6-9918-658fd2d0eac0",
   "metadata": {},
   "source": [
    "10 . Analiza la estrategia de prefetching de datos en un entorno paralelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb2b3b-cdad-4580-b28e-aef407e98d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def prefetching_worker(array, indices, prefetch_distance):\n",
    "    for i in range(len(indices) - prefetch_distance):\n",
    "        _ = array[indices[i + prefetch_distance]]  # Prefetch\n",
    "        array[indices[i]] += 1  # Access\n",
    "\n",
    "size = 10**6\n",
    "array = np.zeros(size)\n",
    "indices = list(range(size))\n",
    "random.shuffle(indices)\n",
    "prefetch_distance = 10\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    futures = [executor.submit(prefetching_worker, array, indices[i::4], prefetch_distance) for i in range(4)]\n",
    "    \n",
    "    for future in futures:\n",
    "        future.result()\n",
    "\n",
    "print(f\"Prefetching completado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd114140-ee56-4e8c-a12a-b7569c62fd5c",
   "metadata": {},
   "source": [
    "11 . Analiza este algoritmo para mejorar la localidad temporal y espacial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeaf114-a729-4718-9734-5e04abf977fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def locality_optimized_algorithm(matrix):\n",
    "    n = len(matrix)\n",
    "    result = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            result[i][j] = matrix[i][j] + matrix[j][i]\n",
    "    \n",
    "    return result\n",
    "\n",
    "n = 1000\n",
    "matrix = np.random.rand(n, n)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "result = locality_optimized_algorithm(matrix)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f\"Tiempo de ejecución: {end_time - start_time:.6f} segundos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ce2e9d-f80a-4f9d-9657-36c4003e7240",
   "metadata": {},
   "source": [
    "12 . Analiza la simulación de coherencia de caché en un entorno multinúcleo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84739c20-146c-4880-aa6e-faffdda009dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "def coherence_worker(shared_array, start, end):\n",
    "    for i in range(start, end):\n",
    "        shared_array[i] += 1\n",
    "\n",
    "size = 10**6\n",
    "shared_array = multiprocessing.Array('d', size)\n",
    "num_processes = 4\n",
    "chunk_size = size // num_processes\n",
    "processes = []\n",
    "\n",
    "for i in range(num_processes):\n",
    "    start = i * chunk_size\n",
    "    end = (i + 1) * chunk_size\n",
    "    process = multiprocessing.Process(target=coherence_worker, args=(shared_array, start, end))\n",
    "    processes.append(process)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "for process in processes:\n",
    "    process.start()\n",
    "\n",
    "for process in processes:\n",
    "    process.join()\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"Tiempo total con coherencia de caché y {num_processes} procesos: {total_time:.6f} segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979da2e9-8e02-496c-8d3a-224eeaab7756",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d1fcc7-c27c-4d12-b4b8-61ba8a1bdb44",
   "metadata": {},
   "source": [
    "### Coherencia de caché\n",
    "\n",
    "La coherencia de caché es un concepto crucial en sistemas de memoria compartida, especialmente en entornos de multiprocesadores donde múltiples procesadores o núcleos acceden a una memoria común. La coherencia de caché asegura que todas las copias de una misma ubicación de memoria, almacenadas en las cachés de distintos procesadores, mantengan valores consistentes, evitando así problemas de inconsistencia que pueden llevar a errores en los cálculos y resultados inesperados en las aplicaciones.\n",
    "\n",
    "En sistemas de multiprocesadores, cada procesador generalmente tiene su propia caché para reducir la latencia de acceso a datos y mejorar el rendimiento general del sistema. Sin embargo, esta mejora en el rendimiento viene con el desafío de mantener la coherencia entre las diferentes copias de datos almacenadas en las cachés de los procesadores. Si no se maneja adecuadamente, diferentes procesadores podrían trabajar con datos desactualizados, llevando a errores de sincronización y resultados incorrectos.\n",
    "\n",
    "**Protocos de coherencia de caché**\n",
    "\n",
    "Los protocolos de coherencia de caché son mecanismos diseñados para gestionar la consistencia de datos en cachés de múltiples procesadores. Estos protocolos aseguran que cualquier cambio en los datos de una caché se refleje adecuadamente en las demás cachés que contengan una copia de esos datos. Existen varios protocolos de coherencia de caché, cada uno con sus propias estrategias y mecanismos para mantener la coherencia.\n",
    "\n",
    "- El Protocolo MESI, que es un acrónimo de los cuatro estados posibles de una línea de caché: Modified (Modificado), Exclusive (Exclusivo), Shared (Compartido), e Invalid (Inválido). En el estado Modificado, una línea de caché ha sido alterada y no es coherente con la memoria principal. En el estado Exclusivo, una línea de caché es la única copia en todas las cachés y es coherente con la memoria principal. En el estado Compartido, una línea de caché puede estar presente en múltiples cachés y es coherente con la memoria principal. En el estado Inválido, la línea de caché no es válida y no debe ser utilizada.\n",
    "\n",
    "El protocolo MESI funciona con base en dos tipos de transacciones: las de lectura y las de escritura. Cuando un procesador desea leer un dato, verifica si la línea de caché está en estado Modificado, Exclusivo o Compartido. Si está en estado Inválido, debe obtener el dato de la memoria principal o de otra caché. Cuando un procesador desea escribir un dato, si la línea de caché está en estado Modificado o Exclusivo, puede proceder con la escritura. Si está en estado Compartido o Inválido, debe invalidar las otras copias antes de escribir.\n",
    "\n",
    "- El Protocolo MOESI, que es una extensión del protocolo MESI e introduce un estado adicional: Owned (Propietario). En el estado Owned, una línea de caché es la única copia modificada, pero otras cachés pueden tener copias compartidas. El procesador propietario es responsable de actualizar la memoria principal cuando la línea es reemplazada. Este estado adicional permite optimizaciones en la comunicación entre cachés y reduce la necesidad de acceder a la memoria principal para mantener la coherencia.\n",
    "\n",
    "- El protocolo MSI es una simplificación del protocolo MESI, con solo tres estados: Modified, Shared e Invalid. El estado Exclusivo no está presente en este protocolo. Aunque es más simple de implementar, puede ser menos eficiente en ciertos escenarios debido a la ausencia del estado Exclusivo, lo que podría llevar a más invalidaciones y tráfico de memoria.\n",
    "\n",
    "- El protocolo Dragon es otro ejemplo de un protocolo de coherencia de caché utilizado en sistemas de multiprocesadores. Introduce estados adicionales como Shared-clean y Shared-modified, que permiten una mayor flexibilidad en la gestión de las líneas de caché compartidas y modificadas. Este protocolo se utiliza para minimizar el tráfico de coherencia y mejorar el rendimiento en sistemas con alta concurrencia.\n",
    "\n",
    "Los protocolos de coherencia de caché no solo se diferencian por los estados que manejan, sino también por las políticas de invalidación y actualización que implementan. Las políticas de invalidación aseguran que cuando un procesador modifica un dato, las demás cachés invalidan sus copias de ese dato. Esto garantiza que los procesadores no trabajen con datos desactualizados. Las políticas de actualización, por otro lado, actualizan automáticamente las copias de los datos en otras cachés cuando un procesador realiza una modificación. Esto puede reducir la latencia de acceso a datos actualizados, pero también puede aumentar el tráfico de coherencia.\n",
    "\n",
    "La coherencia de caché también se puede lograr mediante el uso de **directorios de coherencia**, que son estructuras de datos centralizadas o distribuidas que mantienen información sobre las copias de datos en las cachés de los procesadores. Los directorios de coherencia pueden ser efectivos para reducir el tráfico de coherencia y mejorar el rendimiento en sistemas con un gran número de procesadores.\n",
    "\n",
    "En entornos de programación paralela y distribuida, la coherencia de caché es fundamental para asegurar la consistencia de los datos y el correcto funcionamiento de los programas. Los desarrolladores deben estar conscientes de las implicaciones de la coherencia de caché y utilizar técnicas y herramientas que les permitan gestionar adecuadamente la coherencia en sus aplicaciones. Esto incluye el uso de bibliotecas y marcos de trabajo que implementen protocolos de coherencia de caché, así como el diseño de algoritmos y estructuras de datos que minimicen la necesidad de acceso concurrente a datos compartidos.\n",
    "\n",
    "Además, la coherencia de caché puede tener un impacto significativo en el rendimiento de las aplicaciones paralelas y distribuidas. El tráfico de coherencia y las latencias asociadas pueden convertirse en cuellos de botella, limitando la escalabilidad y eficiencia de las aplicaciones. Por lo tanto, es esencial optimizar el acceso a la memoria y el uso de la caché para minimizar estos impactos.\n",
    "\n",
    "El manejo eficiente de la coherencia de caché también implica el uso de técnicas de prefetching y políticas de reemplazo de caché que aprovechen la localidad temporal y espacial de los datos. El prefetching anticipa las necesidades de datos futuros y los carga en la caché antes de que sean necesarios, reduciendo así las latencias de acceso. Las políticas de reemplazo de caché, por otro lado, determinan qué datos deben mantenerse en la caché y cuáles deben ser reemplazados cuando la caché está llena, basándose en patrones de acceso recientes y previstos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9486bd48-7510-4820-94f3-ba6c4d2a2fe5",
   "metadata": {},
   "source": [
    "### Consistencia de caché\n",
    "\n",
    "La consistencia de caché es un problema crítico en sistemas multiprocesadores donde múltiples núcleos de procesamiento acceden a una memoria compartida. La caché se utiliza para mejorar el rendimiento al almacenar datos frecuentemente accedidos cerca del procesador, reduciendo así el tiempo de acceso a la memoria. Sin embargo, en un sistema multiprocesador, mantener la coherencia entre múltiples cachés que pueden almacenar copias de los mismos datos se vuelve un desafío significativo.\n",
    "\n",
    "**Fundamentos de la consistencia de caché**\n",
    "\n",
    "La memoria caché es una memoria de alta velocidad que almacena copias de datos de la memoria principal. Cada núcleo del procesador puede tener su propia caché, permitiendo un acceso más rápido a los datos frecuentemente usados.\n",
    "\n",
    "El problema surge cuando múltiples cachés contienen copias de los mismos datos y una de estas copias es modificada. Es crucial asegurar que todas las copias reflejen el cambio para mantener la coherencia de datos. Si una caché modifica un dato y las otras cachés no se actualizan, los procesadores pueden trabajar con datos inconsistentes, llevando a errores en la ejecución del programa.\n",
    "\n",
    "**Protocolos de consistencia de caché**\n",
    "\n",
    "Para manejar la consistencia de caché, se utilizan varios protocolos. Estos protocolos aseguran que cualquier modificación en los datos se refleje en todas las copias existentes de la caché. Algunos de los protocolos más comunes incluyen:\n",
    "\n",
    "Protocolo MESI: MESI es uno de los protocolos de coherencia de caché más utilizados y sus siglas representan los cuatro estados posibles de una línea de caché: Modificado, Exclusivo, Compartido e Inválido.\n",
    "\n",
    "- Modificado (M): La línea de caché ha sido modificada y no coincide con la copia en la memoria principal. Solo esta caché tiene una copia válida.\n",
    "- Exclusivo (E): La línea de caché es la única copia y coincide con la memoria principal.\n",
    "- Compartido (S): La línea de caché puede ser compartida por múltiples cachés y coincide con la memoria principal.\n",
    "- Inválido (I): La línea de caché no es válida.\n",
    "\n",
    "Este protocolo asegura que cualquier modificación de datos en una caché se refleje en las otras cachés, invalidando las copias antiguas o actualizando las mismas.\n",
    "\n",
    "Protocolo MOESI: MOESI es una extensión del protocolo MESI que agrega un estado adicional: Owned (O). Este estado permite que una línea de caché modificada se comparta entre varias cachés, con una caché actuando como la \"propietaria\" que coordina la actualización.\n",
    "\n",
    "- Owned (O): La línea de caché es una copia modificada que puede ser compartida y es responsable de propagar los cambios a la memoria principal cuando sea necesario.\n",
    "\n",
    "Protocolo MSI: MSI es una versión simplificada de MESI con solo tres estados: Modificado, Compartido e Inválido. Aunque más simple, puede llevar a más tráfico de bus debido a la falta del estado Exclusivo.\n",
    "\n",
    "**Mecánicas de consistencia**\n",
    "\n",
    "Snooping: El snooping es una técnica donde todas las cachés en un sistema observan el bus para detectar operaciones que puedan afectar las líneas de caché que almacenan. Si una caché detecta una operación relevante (como una escritura en una línea de caché que contiene), toma medidas para mantener la coherencia.\n",
    "\n",
    "Directorios: Los sistemas basados en directorios utilizan una estructura centralizada que mantiene un registro del estado de cada línea de caché en todas las cachés del sistema. Este enfoque escala mejor para sistemas con muchos núcleos, pero introduce una latencia adicional debido a la necesidad de consultar el directorio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6770d6a-31af-4912-9eb9-f810011bb5fe",
   "metadata": {},
   "source": [
    "#### Ejemplo 1:\n",
    "\n",
    "Imaginemos un sistema con dos núcleos, cada uno con su propia caché L1. Ambos núcleos necesitan acceder a una variable X almacenada en la memoria principal. Inicialmente, ambos cachés cargan X, y ambas copias están en el estado Compartido.\n",
    "\n",
    "* Si el núcleo 1 modifica X, su caché cambia el estado de la línea de X a Modificado. El núcleo 1 debe invalidar la copia en la caché del núcleo 2.\n",
    "* Si el núcleo 2 intenta leer X después de la modificación, encontrará su copia inválida y deberá solicitar la nueva copia desde la memoria principal o desde la caché del núcleo 1.\n",
    "\n",
    "#### Ejemplo 2:\n",
    "\n",
    "Considera un sistema con cuatro núcleos utilizando el protocolo MOESI. El núcleo 1 modifica un dato D, cambiando su estado a Modificado.\n",
    "\n",
    "* El núcleo 2 solicita D, y el núcleo 1 cambia el estado a Owned y responde con la copia modificada. El núcleo 2 ahora tiene D en estado Compartido.\n",
    "* Si el núcleo 3 también solicita D, el núcleo 1 o el 2 pueden proporcionar la copia, manteniendo la coherencia sin necesidad de acceder a la memoria principal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57168910-4db0-4249-afa1-5ac63e237db0",
   "metadata": {},
   "source": [
    "**Desafíos en la consistencia de caché**\n",
    "\n",
    "- Latencia de Comunicación: Mantener la coherencia de caché introduce latencia adicional debido al tráfico en el bus o las consultas al directorio.\n",
    "- Escalabilidad: A medida que el número de núcleos en un sistema aumenta, el tráfico de coherencia se incrementa, lo que puede llevar a cuellos de botella. Los sistemas basados en snooping pueden no escalar bien para un gran número de núcleos debido al aumento del tráfico de bus.\n",
    "- Complejidad del protocolo:Los protocolos más avanzados, como MOESI, introducen complejidad adicional en el diseño de hardware, lo que puede incrementar los costos de desarrollo y fabricación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04621eed-7305-48f8-91d0-bf5f304cfcda",
   "metadata": {},
   "source": [
    "Herramientas como GEM5 y SimpleScalar permiten a los investigadores simular diferentes arquitecturas de caché y protocolos de coherencia para evaluar su desempeño.\n",
    "\n",
    "Los procesadores modernos de Intel y AMD implementan sofisticados protocolos de coherencia de caché, como MESIF y MOESIF, que son variaciones avanzadas de los protocolos MESI y MOESI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49460d3-3c4b-4f97-a1b0-a25c491edcba",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "1 . Explica cada uno de los estados del protocolo MESI (Modified, Exclusive, Shared, Invalid) y dé un ejemplo práctico de cuándo una línea de caché puede cambiar de un estado a otro.\n",
    "\n",
    "2 .Compara y contraste los protocolos de coherencia de caché basados en invalidación (ej. MESI) y basados en actualización (ej. MOESI). ¿Cuáles son las ventajas y desventajas de cada uno?\n",
    "\n",
    "3 .  Discute cómo los diferentes protocolos de coherencia de caché pueden impactar el rendimiento de un sistema multiprocesador. Considere factores como el tráfico de red y la latencia de acceso a datos.\n",
    "\n",
    "4 . Explica cómo la coherencia de caché afecta la escalabilidad de sistemas multiprocesadores. ¿Qué desafíos presentan los sistemas con un gran número de procesadores?\n",
    "\n",
    "5 . Explica cómo funciona un directorio de coherencia en un sistema multiprocesador y cuáles son sus ventajas sobre los protocolos basados en bus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003bbd91-80fb-44db-8352-74c7ff33f4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aa8bab-c8bb-43ea-a466-2876237bb8bf",
   "metadata": {},
   "source": [
    "6 . Implementación de un simulador de Protocolo MESI:\n",
    "\n",
    "Descripción: Implementa un simulador simple del protocolo MESI en Python. Simula varios procesadores y cachés que acceden y modifican líneas de datos, cambiando los estados de las líneas de caché según las reglas de MESI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b33db-cbaa-47ce-b283-254b19e550cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codigo de inicio\n",
    "class CacheLine:\n",
    "    def __init__(self):\n",
    "        self.state = 'Invalid'\n",
    "        self.data = None\n",
    "\n",
    "class Processor:\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "        self.cache = {}\n",
    "\n",
    "    def read(self, address):\n",
    "        if address in self.cache and self.cache[address].state != 'Invalid':\n",
    "            return self.cache[address].data\n",
    "        else:\n",
    "            self.cache[address] = CacheLine()\n",
    "            self.cache[address].state = 'Shared'\n",
    "            self.cache[address].data = memory_read(address)\n",
    "            return self.cache[address].data\n",
    "\n",
    "    def write(self, address, data):\n",
    "        if address in self.cache and (self.cache[address].state == 'Shared' or self.cache[address].state == 'Exclusive'):\n",
    "            self.cache[address].state = 'Modified'\n",
    "            self.cache[address].data = data\n",
    "        else:\n",
    "            self.cache[address] = CacheLine()\n",
    "            self.cache[address].state = 'Modified'\n",
    "            self.cache[address].data = data\n",
    "            memory_write(address, data)\n",
    "\n",
    "def memory_read(address):\n",
    "    # Simula una lectura de memoria principal\n",
    "    return \"data_from_memory\"\n",
    "\n",
    "def memory_write(address, data):\n",
    "    # Simula una escritura en memoria principal\n",
    "    pass\n",
    "\n",
    "# Ejemplo de uso\n",
    "p1 = Processor(1)\n",
    "p2 = Processor(2)\n",
    "p1.write(0x1A, \"data1\")\n",
    "p2.read(0x1A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3addad0c-1b91-42e7-a4ac-25decb6229c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2fe6fc-9a06-4d3f-84d6-f24988cb1079",
   "metadata": {},
   "source": [
    "7 . Simulación de trafico de coherencia:\n",
    "\n",
    "Descripción: Extiende el simulador anterior para incluir múltiples procesadores y rastrear el tráfico de coherencia (lecturas y escrituras en el bus de memoria).\n",
    "a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190420b-7fa7-4520-a44e-2daa283ac433",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Codigo inicial\n",
    "\n",
    "traffic = 0\n",
    "\n",
    "class CacheLine:\n",
    "    def __init__(self):\n",
    "        self.state = 'Invalid'\n",
    "        self.data = None\n",
    "\n",
    "class Processor:\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "        self.cache = {}\n",
    "\n",
    "    def read(self, address):\n",
    "        global traffic\n",
    "        if address in self.cache and self.cache[address].state != 'Invalid':\n",
    "            return self.cache[address].data\n",
    "        else:\n",
    "            self.cache[address] = CacheLine()\n",
    "            self.cache[address].state = 'Shared'\n",
    "            traffic += 1\n",
    "            self.cache[address].data = memory_read(address)\n",
    "            return self.cache[address].data\n",
    "\n",
    "    def write(self, address, data):\n",
    "        global traffic\n",
    "        if address in self.cache and (self.cache[address].state == 'Shared' or self.cache[address].state == 'Exclusive'):\n",
    "            self.cache[address].state = 'Modified'\n",
    "            self.cache[address].data = data\n",
    "        else:\n",
    "            self.cache[address] = CacheLine()\n",
    "            self.cache[address].state = 'Modified'\n",
    "            traffic += 1\n",
    "            self.cache[address].data = data\n",
    "            memory_write(address, data)\n",
    "\n",
    "def memory_read(address):\n",
    "    return \"data_from_memory\"\n",
    "\n",
    "def memory_write(address, data):\n",
    "    pass\n",
    "\n",
    "# Ejemplo de uso\n",
    "p1 = Processor(1)\n",
    "p2 = Processor(2)\n",
    "p1.write(0x1A, \"data1\")\n",
    "p2.read(0x1A)\n",
    "print(f\"Traffic: {traffic} transactions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e7a8f5-e129-4440-81a2-735227a9f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8dc94f-df10-4607-bde4-37c65c93c83f",
   "metadata": {},
   "source": [
    "8 . Protocolo de directorio distribuido:\n",
    "\n",
    "Descripción: Implementa un simulador básico de un protocolo de directorio distribuido. Cada procesador tiene su propio directorio local que mantiene información sobre las líneas de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb57819-c7fd-498f-becf-a689d40bc258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codigo de inicio\n",
    "class Directory:\n",
    "    def __init__(self):\n",
    "        self.entries = {}\n",
    "\n",
    "    def update(self, address, processor_id):\n",
    "        if address not in self.entries:\n",
    "            self.entries[address] = set()\n",
    "        self.entries[address].add(processor_id)\n",
    "\n",
    "    def invalidate(self, address):\n",
    "        if address in self.entries:\n",
    "            self.entries[address] = set()\n",
    "\n",
    "class Processor:\n",
    "    def __init__(self, id, directory):\n",
    "        self.id = id\n",
    "        self.cache = {}\n",
    "        self.directory = directory\n",
    "\n",
    "    def read(self, address):\n",
    "        if address in self.cache and self.cache[address].state != 'Invalid':\n",
    "            return self.cache[address].data\n",
    "        else:\n",
    "            self.cache[address] = CacheLine()\n",
    "            self.cache[address].state = 'Shared'\n",
    "            self.directory.update(address, self.id)\n",
    "            self.cache[address].data = memory_read(address)\n",
    "            return self.cache[address].data\n",
    "\n",
    "    def write(self, address, data):\n",
    "        if address in self.cache and (self.cache[address].state == 'Shared' or self.cache[address].state == 'Exclusive'):\n",
    "            self.cache[address].state = 'Modified'\n",
    "            self.cache[address].data = data\n",
    "            self.directory.invalidate(address)\n",
    "        else:\n",
    "            self.cache[address] = CacheLine()\n",
    "            self.cache[address].state = 'Modified'\n",
    "            self.cache[address].data = data\n",
    "            self.directory.invalidate(address)\n",
    "            memory_write(address, data)\n",
    "\n",
    "def memory_read(address):\n",
    "    return \"data_from_memory\"\n",
    "\n",
    "def memory_write(address, data):\n",
    "    pass\n",
    "\n",
    "# Ejemplo de uso\n",
    "directory = Directory()\n",
    "p1 = Processor(1, directory)\n",
    "p2 = Processor(2, directory)\n",
    "p1.write(0x1A, \"data1\")\n",
    "p2.read(0x1A)\n",
    "print(directory.entries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0691beec-46de-4426-aaac-6e26ceeb2dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7d2b84-73a3-42ee-a879-662c6aa5f2f8",
   "metadata": {},
   "source": [
    "### Problemas de coherencia y consistencia\n",
    "\n",
    "El problema de la coherencia y consistencia de caché es un desafío fundamental en la arquitectura de sistemas multiprocesadores. La necesidad de mantener una vista coherente y consistente de la memoria compartida entre múltiples procesadores es crucial para asegurar la correcta ejecución de aplicaciones paralelas y distribuidas. A medida que los sistemas de computación evolucionan y la demanda de rendimiento crece, se hace imperativo implementar mecanismos efectivos para gestionar la coherencia y consistencia de caché. Uno de los enfoques más comunes para abordar este problema es el uso de protocolos de coherencia de caché basados en snooping y sistemas de bus compartido.\n",
    "\n",
    "En un sistema multiprocesador, cada procesador tiene su propia caché local para acelerar el acceso a datos frecuentes y reducir la latencia de acceso a memoria. Sin embargo, cuando múltiples procesadores trabajan en la misma región de memoria, pueden ocurrir inconsistencias si no se implementan mecanismos adecuados para mantener la coherencia de caché. \n",
    "\n",
    "Uno de los métodos más comunes para mantener la coherencia de caché en sistemas multiprocesadores es el uso de un **protocolo de snooping**. En este enfoque, todas las cachés monitorean (o \"husmean\") las transacciones en un bus compartido para detectar accesos a líneas de memoria que pueden estar en caché localmente. Cuando un procesador realiza una operación de lectura o escritura en una línea de memoria, emite una transacción en el bus compartido. Los demás procesadores observan esta transacción y, si tienen una copia de la línea de memoria en sus cachés, actúan en consecuencia para mantener la coherencia.\n",
    "\n",
    "El protocolo MESI (Modified, Exclusive, Shared, Invalid) y MOESI son uno de los protocolos de snooping más utilizados. \n",
    "\n",
    "Cuando un procesador desea leer o escribir una línea de caché, realiza una transacción en el bus. Si otro procesador tiene una copia de la línea en estado Modified, debe escribir los datos de vuelta en la memoria principal (write-back) antes de que el primer procesador pueda proceder. Este mecanismo asegura que todas las copias de una línea de caché estén sincronizadas y que las modificaciones sean visibles para todos los procesadores.\n",
    "\n",
    " MOESI puede reducir el tráfico de coherencia al permitir que las líneas de caché modificadas se compartan sin necesidad de escribir de vuelta a la memoria principal inmediatamente.\n",
    "\n",
    "Además de los protocolos basados en snooping, existen protocolos de coherencia basados en directorios, que son más adecuados para sistemas con un gran número de procesadores. En estos sistemas, el uso de un bus compartido puede convertirse en un cuello de botella debido al elevado tráfico de coherencia. Los **protocolos de directorio** utilizan una estructura de datos centralizada o distribuida que mantiene un registro de las líneas de caché y sus estados en cada procesador. Cuando un procesador desea acceder a una línea de memoria, consulta el directorio para determinar si la línea está presente en otras cachés y en qué estado se encuentra. El directorio coordina las actualizaciones y las invalidaciones, reduciendo la necesidad de tráfico en el bus compartido.\n",
    "\n",
    "La consistencia de caché es otro aspecto crítico que debe gestionarse en sistemas multiprocesadores. Los modelos de consistencia definen el orden en que las operaciones de memoria deben ser visibles a los procesadores. El modelo de consistencia más estricto es la **consistencia secuencial**, que asegura que las operaciones de memoria se vean en el mismo orden en que se ejecutaron. Sin embargo, la consistencia secuencial puede ser costosa en términos de rendimiento, ya que requiere una fuerte sincronización entre los procesadores.\n",
    "\n",
    "Para mejorar el rendimiento, se utilizan modelos de consistencia más relajados, como la **consistencia débil** y la **consistencia de memoria liberada** (release consistency). En la consistencia débil, las operaciones de memoria pueden ejecutarse en cualquier orden, siempre y cuando se sincronicen en puntos específicos del programa. La consistencia de memoria liberada permite que las operaciones de lectura y escritura se realicen en cualquier orden, pero requiere que las operaciones de sincronización (como las barreras de memoria) se ejecuten en un orden específico para asegurar la correcta ejecución del programa.\n",
    "\n",
    "El problema de la coherencia y consistencia de caché es particularmente desafiante en sistemas distribuidos, donde los nodos pueden estar ubicados en diferentes ubicaciones geográficas y comunicarse a través de redes de alta latencia. En estos sistemas, mantener una vista coherente y consistente de la memoria compartida requiere algoritmos sofisticados y técnicas de sincronización eficientes. Por ejemplo, los **algoritmos de consenso** como Paxos y Raft se utilizan para asegurar que los datos sean consistentes en todos los nodos, incluso en presencia de fallos de red y nodos defectuosos.\n",
    "\n",
    "Además, en sistemas distribuidos modernos, se emplean técnicas como el uso de **cachés distribuidas** y **replicación de datos** para mejorar el rendimiento y la disponibilidad. Las cachés distribuidas permiten que los datos se almacenen en múltiples nodos, reduciendo la latencia de acceso al aprovechar la cercanía geográfica de los datos. Sin embargo, esto introduce nuevos desafíos para mantener la coherencia y consistencia de los datos replicados. Las políticas de coherencia deben asegurarse de que cualquier actualización realizada en una copia de los datos se propague a todas las demás copias, y las políticas de consistencia deben definir cómo se manejan los conflictos de actualización y las fallas de red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66862b28-293c-4433-85f3-d8bd8a1ed4cc",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "* Explica el problema de la coherencia de caché en un sistema multiprocesador. ¿Por qué es importante mantener la coherencia de la caché?\n",
    "* Describe el protocolo MESI. ¿Cuáles son los estados involucrados y qué significan? Explica cómo el protocolo MESI maneja una operación de lectura y escritura en un entorno multiprocesador.\n",
    "* Compara y contraste los protocolos MSI y MESI. ¿Cuáles son las diferencias clave entre estos protocolos de coherencia de caché?\n",
    "* Explica cómo funcionan los protocolos de directorio para mantener la coherencia de la caché. ¿Qué ventajas ofrecen estos protocolos sobre los basados en snooping?\n",
    "* Describe las diferencias entre un protocolo de directorio centralizado y uno distribuido. ¿Cuáles son los beneficios y desventajas de cada enfoque?\n",
    "* Analiza un escenario en el que un protocolo de directorio distribuido podría ser más eficiente que uno centralizado. ¿Qué factores influirían en esta decisión?\n",
    "* Explica el propósito de los algoritmos de consenso en sistemas distribuidos. ¿Por qué es importante alcanzar el consenso entre nodos en un sistema distribuido?\n",
    "* Describa el algoritmo Paxos. ¿Cuáles son los roles principales (proposer, acceptor, learner) y cómo interactúan entre sí para alcanzar el consenso?\n",
    "* Compare y contraste Paxos con el algoritmo Raft. ¿Cuáles son las diferencias clave en su funcionamiento y uso?\n",
    "* Explica el concepto de una caché distribuida. ¿Cuáles son los principales desafíos en la implementación de una caché distribuida?\n",
    "* Describe una estrategia de consistencia eventual en cachés distribuidas. ¿Cómo se maneja la replicación de datos y qué garantías de consistencia se ofrecen?\n",
    "* Analiza un escenario en el que la consistencia eventual podría ser insuficiente. ¿Qué tipo de aplicaciones requieren una consistencia más fuerte?\n",
    "* Explica los diferentes modelos de consistencia en la replicación de datos. ¿Cuáles son las diferencias entre consistencia fuerte, consistencia eventual y consistencia causal?\n",
    "* Describe un sistema de replicación de datos con consistencia eventual. ¿Cómo se manejan las actualizaciones y cómo se resuelven los conflictos?\n",
    "* Analice las ventajas y desventajas de la replicación de datos con consistencia eventual frente a la consistencia fuerte. ¿En qué tipo de aplicaciones sería más adecuada cada una?\n",
    "* Supongamos un sistema multiprocesador con cuatro núcleos (P1, P2, P3 y P4) que utilizan un protocolo MESI. Describa paso a paso cómo se manejaría una operación de escritura en una dirección de memoria que inicialmente no está en la caché de ningún procesador.\n",
    "* Considera un sistema distribuido con nodos que implementan el algoritmo de consenso Paxos. Describa el proceso completo de una propuesta que pasa por los estados de promesa y aceptación hasta alcanzar el consenso.\n",
    "* Analiza un escenario en el que un sistema de directorio distribuido podría fallar al mantener la coherencia de caché. Plantea soluciones para mitigar estos problemas y mejorar la robustez del sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f06329-792f-4c24-87ce-d70fa30a5a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0a158d-58e4-456b-8dbb-932a22609dd2",
   "metadata": {},
   "source": [
    "1 . Implementa una versión simplificada del algoritmo de consenso Paxos en Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec53ad-dfb4-48c9-8d72-c81d47e94e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codigo base\n",
    "import random\n",
    "\n",
    "class Proposer:\n",
    "    def __init__(self, id, acceptors):\n",
    "        self.id = id\n",
    "        self.acceptors = acceptors\n",
    "\n",
    "    def propose(self, value):\n",
    "        proposal_number = random.randint(1, 100)\n",
    "        promises = 0\n",
    "        for acceptor in self.acceptors:\n",
    "            if acceptor.promise(proposal_number):\n",
    "                promises += 1\n",
    "\n",
    "        if promises > len(self.acceptors) // 2:\n",
    "            for acceptor in self.acceptors:\n",
    "                acceptor.accept(proposal_number, value)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "class Acceptor:\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "        self.promised_proposal = 0\n",
    "        self.accepted_proposal = 0\n",
    "        self.accepted_value = None\n",
    "\n",
    "    def promise(self, proposal_number):\n",
    "        if proposal_number > self.promised_proposal:\n",
    "            self.promised_proposal = proposal_number\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def accept(self, proposal_number, value):\n",
    "        if proposal_number >= self.promised_proposal:\n",
    "            self.accepted_proposal = proposal_number\n",
    "            self.accepted_value = value\n",
    "\n",
    "# Ejemplo de uso\n",
    "acceptors = [Acceptor(i) for i in range(3)]\n",
    "proposer = Proposer(1, acceptors)\n",
    "\n",
    "if proposer.propose(\"value1\"):\n",
    "    print(\"Proposal accepted\")\n",
    "else:\n",
    "    print(\"Proposal rejected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32557302-7020-44a8-946b-892f8754d77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66845276-18da-472c-b265-bd2d8929cda6",
   "metadata": {},
   "source": [
    "2 . Implementa una caché distribuida simple en Python utilizando un mecanismo básico de replicación de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ec4e8-fac2-494f-8d8c-b5319e9bfce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistributedCache:\n",
    "    def __init__(self):\n",
    "        self.nodes = {}\n",
    "\n",
    "    def add_node(self, node_id):\n",
    "        self.nodes[node_id] = {}\n",
    "\n",
    "    def put(self, key, value):\n",
    "        for node in self.nodes.values():\n",
    "            node[key] = value\n",
    "\n",
    "    def get(self, node_id, key):\n",
    "        return self.nodes[node_id].get(key, None)\n",
    "\n",
    "# Ejemplo de uso\n",
    "cache = DistributedCache()\n",
    "cache.add_node('node1')\n",
    "cache.add_node('node2')\n",
    "\n",
    "cache.put('key1', 'value1')\n",
    "print(cache.get('node1', 'key1'))\n",
    "print(cache.get('node2', 'key1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a949ad19-2105-483d-abe5-785c0d1737ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d822710b-85b8-4de4-b99b-4dd283b99f54",
   "metadata": {},
   "source": [
    "3 . Implementa un sistema de replicación de datos con consistencia eventual en Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4490837c-8914-4290-95af-b0574c3e2299",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "        self.data = {}\n",
    "        self.log = []\n",
    "\n",
    "    def put(self, key, value):\n",
    "        self.data[key] = value\n",
    "        self.log.append((key, value))\n",
    "\n",
    "    def get(self, key):\n",
    "        return self.data.get(key, None)\n",
    "\n",
    "    def replicate(self, other_node):\n",
    "        for entry in self.log:\n",
    "            other_node.data[entry[0]] = entry[1]\n",
    "        other_node.log.extend(self.log)\n",
    "\n",
    "# Ejemplo de uso\n",
    "node1 = Node('node1')\n",
    "node2 = Node('node2')\n",
    "\n",
    "node1.put('key1', 'value1')\n",
    "node1.put('key2', 'value2')\n",
    "\n",
    "node1.replicate(node2)\n",
    "\n",
    "print(node2.get('key1'))\n",
    "print(node2.get('key2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c317ce5-1c5d-43be-98ff-99eda17b7afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
