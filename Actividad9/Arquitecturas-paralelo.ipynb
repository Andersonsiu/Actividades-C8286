{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d60b8a1-975b-4794-8fa1-63812e14cbbe",
   "metadata": {},
   "source": [
    "### Arquitecturas de sistemas paralelos\n",
    "Las arquitecturas de sistemas paralelos son fundamentales para mejorar el rendimiento de las aplicaciones mediante la ejecución simultánea de múltiples operaciones. Estas arquitecturas se dividen en varias categorías, cada una adecuada para diferentes tipos de tareas y aplicaciones. En general, las arquitecturas paralelas se clasifican en función de la organización de la memoria y la interconexión de los procesadores.\n",
    "\n",
    "En el ámbito de la computación paralela, las arquitecturas de sistemas pueden clasificarse en dos categorías principales basadas en cómo gestionan la memoria: arquitecturas de memoria compartida y arquitecturas de memoria distribuida. Ambas tienen sus ventajas y desventajas, y son adecuadas para diferentes tipos de aplicaciones y entornos de ejecución.\n",
    "\n",
    "**Arquitectura de memoria compartida**\n",
    "\n",
    "En una arquitectura de memoria compartida, todos los procesadores acceden a un único espacio de memoria global. Esta configuración es intuitiva y facilita la programación, ya que los procesos pueden comunicarse y sincronizarse a través de variables compartidas.\n",
    "\n",
    "Tipos de memoria compartida\n",
    "\n",
    "- Memoria compartida uniforme (UMA): En UMA (Uniform Memory Access), todos los procesadores tienen igual tiempo de acceso a la memoria principal. Esto significa que la latencia de acceso a la memoria es la misma para todos los procesadores.\n",
    "    - Ejemplos: Estaciones de trabajo multiprocesador, servidores de gama media.\n",
    "    - Ventajas: Simplicidad en la programación debido a la uniformidad en el acceso a la memoria. Facilita la coherencia de la caché y la sincronización entre procesadores.\n",
    "    - Desventajas: No escala bien a un gran número de procesadores debido a la contención de memoria y los cuellos de botella en el bus de memoria.\n",
    "\n",
    "- Memoria compartida no uniforme (NUMA): En NUMA (Non-Uniform Memory Access), cada procesador tiene su memoria local, y el tiempo de acceso a la memoria varía dependiendo de si se accede a la memoria local o a la memoria de otro procesador.\n",
    "    - Ejemplos: Servidores de alto rendimiento, sistemas NUMA basados en arquitecturas como AMD EPYC e Intel Xeon.\n",
    "    - Ventajas: Mejora la escalabilidad al reducir la contención de memoria y permite un acceso más rápido a la memoria local.\n",
    "    - Desventajas: Mayor complejidad en la programación, ya que se debe gestionar la latencia variable en el acceso a la memoria.\n",
    "\n",
    "Ventajas y desventajas de la memoria compartida\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "- Facilidad de programación: La memoria compartida es más intuitiva para los programadores, ya que se puede usar una única dirección de memoria para la comunicación entre hilos.\n",
    "- Rendimiento: En sistemas UMA, el acceso uniforme a la memoria puede simplificar la optimización del rendimiento.\n",
    "- Coherencia de caché: Los sistemas NUMA y UMA gestionan la coherencia de la caché, lo que puede reducir errores en la programación.\n",
    "\n",
    "Desventajas:\n",
    "\n",
    "- Escalabilidad: Los sistemas UMA enfrentan limitaciones en la escalabilidad debido a la contención del bus de memoria.\n",
    "- Complejidad en NUMA: Aunque NUMA mejora la escalabilidad, introduce complejidad en la programación debido a las diferencias en la latencia de acceso a la memoria.\n",
    "- Costos: Los sistemas de memoria compartida pueden ser más costosos debido a la necesidad de hardware más sofisticado para gestionar la coherencia de la caché y el acceso a la memoria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4f6112-b81a-499f-ba10-ed47f9def065",
   "metadata": {},
   "source": [
    "**Arquitectura de memoria distribuida**\n",
    "\n",
    "En una arquitectura de memoria distribuida, cada procesador tiene su propia memoria local. Los procesadores no pueden acceder directamente a la memoria de otros procesadores. La comunicación entre procesadores se realiza mediante el paso de mensajes.\n",
    "\n",
    "Tipos de arquitecturas de memoria distribuida\n",
    "\n",
    "Multicomputadores: Sistemas compuestos por varios nodos de computación, cada uno con su propia CPU y memoria. Los nodos están interconectados mediante una red de alta velocidad.\n",
    "\n",
    "- Ejemplos: Supercomputadoras, clústeres de computadoras.\n",
    "- Ventajas: Alta escalabilidad, ya que no hay contención de memoria compartida. Mejor tolerancia a fallos, ya que cada nodo es independiente.\n",
    "- Desventajas: Programación más compleja debido a la necesidad de gestionar la comunicación y sincronización entre nodos mediante el paso de mensajes.\n",
    "\n",
    "Clústeres de computadoras: Un tipo específico de multicomputador donde varios sistemas completos (nodos) están conectados a través de una red para trabajar juntos como un solo sistema.\n",
    "- Ejemplos: Clústeres de alto rendimiento (HPC), clústeres de alta disponibilidad (HA).\n",
    "- Ventajas: Coste-efectividad al utilizar hardware convencional. Capacidad de combinar recursos de diferentes sistemas para tareas específicas.\n",
    "- Desventajas: Dependencia de la red para la comunicación, lo que puede introducir latencias significativas.\n",
    "\n",
    "Ventajas y desventajas de la memoria distribuida\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "- Escalabilidad: Permite construir sistemas con un gran número de nodos sin problemas significativos de contención.\n",
    "- Tolerancia a fallos: La falla de un nodo no afecta necesariamente a los demás, mejorando la fiabilidad del sistema.\n",
    "- Flexibilidad: Los nodos pueden ser heterogéneos, permitiendo la integración de diferentes tipos de hardware según sea necesario.\n",
    "\n",
    "Desventajas:\n",
    "\n",
    "- Complejidad en la programación: Requiere un manejo explícito de la comunicación y sincronización entre nodos, lo que aumenta la complejidad del desarrollo de software.\n",
    "- Latencia de comunicación: La comunicación entre nodos puede ser lenta debido a la latencia de la red, afectando el rendimiento de las aplicaciones que requieren alta interactividad.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e100840-d69c-4e37-a48d-9b7d43a09ef2",
   "metadata": {},
   "source": [
    "La elección entre una arquitectura de memoria compartida y una de memoria distribuida depende de las características de la aplicación y de los requisitos específicos del sistema.\n",
    "\n",
    "**Aplicaciones adecuadas para memoria compartida**:\n",
    "\n",
    "- Aplicaciones con alta interactividad entre procesos.\n",
    "- Sistemas donde la facilidad de programación es una prioridad.\n",
    "- Entornos donde la coherencia de la caché y la sincronización son críticas.\n",
    "\n",
    "**Aplicaciones adecuadas para memoria distribuida**:\n",
    "\n",
    "- Aplicaciones que requieren alta escalabilidad, como simulaciones científicas y análisis de big data.\n",
    "- Sistemas distribuidos y clústeres donde la tolerancia a fallos es crucial.\n",
    "- Aplicaciones que pueden tolerar latencias de comunicación más altas y donde la programación paralela se puede manejar mediante el paso de mensajes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0ac02b-ed50-450a-b45a-398870f5bdf8",
   "metadata": {},
   "source": [
    "\n",
    "**Arquitecturas paralelas híbridas**\n",
    "Las arquitecturas paralelas híbridas combinan elementos de arquitecturas de memoria compartida y memoria distribuida para aprovechar las ventajas de ambas y mitigar sus desventajas. Estas arquitecturas se utilizan en sistemas que requieren alta escalabilidad y rendimiento, y son comunes en aplicaciones científicas, de ingeniería y de análisis de datos masivos. \n",
    "\n",
    "Las arquitecturas híbridas están diseñadas para mejorar la eficiencia y el rendimiento combinando características de sistemas de memoria compartida (como UMA y NUMA) y sistemas de memoria distribuida (como multicomputadores y clústeres). En una arquitectura híbrida, los nodos individuales pueden ser sistemas de memoria compartida que están interconectados mediante una red de alta velocidad para formar un sistema de memoria distribuida.\n",
    "\n",
    "Un ejemplo típico de una arquitectura híbrida es un clúster de nodos NUMA. Cada nodo es un sistema NUMA, donde múltiples procesadores comparten una memoria local. Los nodos están conectados a través de una red, formando un sistema de memoria distribuida. Este enfoque permite que cada nodo NUMA opere de manera eficiente con baja latencia de memoria local, mientras que la red de interconexión permite la comunicación entre nodos para tareas de gran escala.\n",
    "\n",
    "Ventajas de las arquitecturas híbridas\n",
    "\n",
    "- Escalabilidad mejorada: La combinación de memoria compartida y distribuida permite escalar el sistema a un gran número de procesadores sin los problemas de contención de memoria asociados con UMA. La memoria distribuida entre nodos reduce la carga en el bus de memoria y mejora la escalabilidad.\n",
    "- Flexibilidad: Las arquitecturas híbridas pueden adaptarse a una amplia variedad de aplicaciones, desde tareas intensivas en cálculo hasta aplicaciones que requieren gran ancho de banda de memoria.\n",
    "Los desarrolladores pueden optimizar las aplicaciones utilizando la memoria local para datos de acceso frecuente y la memoria distribuida para datos que no requieren acceso inmediato.\n",
    "- Rendimiento: Los nodos NUMA dentro de una arquitectura híbrida permiten un acceso rápido a la memoria local, mejorando el rendimiento de las aplicaciones. La interconexión de alta velocidad entre nodos permite una comunicación eficiente para tareas que requieren intercambio de datos.\n",
    "- Tolerancia a fallos: La naturaleza distribuida de la memoria permite que el sistema continúe operando incluso si uno o varios nodos fallan. Las arquitecturas híbridas pueden incluir mecanismos de redundancia y recuperación para mejorar la fiabilidad del sistema.\n",
    "\n",
    "Desventajas de las arquitecturas híbridas\n",
    "\n",
    "- Complejidad de programación: Los desarrolladores deben gestionar tanto la memoria compartida como la distribuida, lo que aumenta la complejidad del desarrollo de software. La programación paralela en arquitecturas híbridas requiere un profundo conocimiento de los modelos de memoria y las técnicas de sincronización.\n",
    "- Latencia de comunicación: Aunque la red de interconexión es rápida, la comunicación entre nodos aún puede introducir latencia, afectando el rendimiento de aplicaciones altamente interactivas. Las estrategias de minimización de latencia deben ser cuidadosamente diseñadas y optimizadas.\n",
    "- Costos: La implementación de arquitecturas híbridas puede ser costosa debido a la necesidad de hardware sofisticado y redes de alta velocidad. Los costos operativos y de mantenimiento también pueden ser altos debido a la complejidad del sistema.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d03f83-8769-4aa3-be7f-ab409ca5f315",
   "metadata": {},
   "source": [
    "#### Modelos de programación en arquitecturas híbridas\n",
    "\n",
    "Para aprovechar las arquitecturas híbridas, se utilizan diversos modelos de programación que combinan técnicas de memoria compartida y distribuida:\n",
    "\n",
    "- Modelo MPI+OpenMP: Este modelo combina el paso de mensajes (MPI) para la comunicación entre nodos y la memoria compartida (OpenMP) para la paralelización dentro de cada nodo.\n",
    "    * Ejemplo: En una simulación de dinámica de fluidos, MPI se puede usar para distribuir diferentes regiones del dominio de simulación entre nodos, mientras que OpenMP se usa para paralelizar los cálculos dentro de cada región.\n",
    "\n",
    "- Modelo UPC (Unified Parallel C): UPC es un modelo de programación paralela que extiende C para incluir tanto memoria compartida como distribuida.\n",
    "    * Permite a los desarrolladores escribir programas que pueden aprovechar las arquitecturas híbridas sin tener que gestionar explícitamente la comunicación entre nodos.\n",
    "- Modelo GASNet (Global Address Space Networking): GASNet es una API de comunicaciones diseñada para soportar modelos de programación con espacio de direcciones global.\n",
    "   * Proporciona una abstracción de comunicación eficiente que permite a los desarrolladores escribir aplicaciones paralelas que pueden escalar en arquitecturas híbridas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2123fcd-6b71-4b84-b889-1afce909fd1d",
   "metadata": {},
   "source": [
    "#### Aplicaciones de las arquitecturas híbridas\n",
    "Las arquitecturas híbridas son particularmente adecuadas para una amplia gama de aplicaciones científicas y de ingeniería:\n",
    "\n",
    "Simulaciones científicas:\n",
    "\n",
    "- Aplicaciones como simulaciones de dinámica molecular, modelado climático y simulaciones de física de alta energía se benefician de la combinación de memoria compartida y distribuida para manejar grandes volúmenes de datos y cálculos intensivos.\n",
    "\n",
    "Análisis de datos masivos:\n",
    "\n",
    "- En el análisis de big data, las arquitecturas híbridas permiten procesar grandes conjuntos de datos de manera eficiente mediante la distribución de tareas y datos entre nodos y el uso de memoria compartida para cálculos intensivos.\n",
    "\n",
    "Inteligencia artificial y aprendizaje automático:\n",
    "\n",
    "- Los entrenamientos de modelos de aprendizaje profundo pueden aprovechar arquitecturas híbridas para distribuir datos y tareas de entrenamiento entre múltiples nodos, mientras que los cálculos intensivos se realizan dentro de los nodos utilizando memoria compartida.\n",
    "\n",
    "Ingeniería y diseño asistido por computadora (CAE/CAD):\n",
    "\n",
    "Las aplicaciones de CAE y CAD, que requieren simulaciones precisas y detalladas, pueden utilizar arquitecturas híbridas para manejar las demandas computacionales y de memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c3cbd-6908-4b0b-9f00-169a524e2bb9",
   "metadata": {},
   "source": [
    "#### Ejemplos\n",
    "Un ejemplo real de arquitectura híbrida es un clúster de alto rendimiento (HPC) que utiliza nodos NUMA interconectados mediante una red InfiniBand de alta velocidad. Cada nodo NUMA tiene múltiples procesadores con memoria local compartida, y los nodos están conectados para formar una memoria distribuida global. Este tipo de clúster se utiliza en centros de supercomputación para tareas como la simulación de fenómenos físicos complejos y el análisis de grandes conjuntos de datos.\n",
    "\n",
    "Características del clúster HPC híbrido:\n",
    "\n",
    "- Interconexión de alta velocidad:\n",
    "  * La red InfiniBand proporciona una latencia baja y un alto ancho de banda para la comunicación entre nodos, mejorando el rendimiento global del sistema.\n",
    "\n",
    "- Gestión de memoria eficiente:\n",
    "  * Los desarrolladores pueden aprovechar la memoria local de los nodos NUMA para datos de acceso frecuente y utilizar la memoria distribuida para datos menos críticos.\n",
    "\n",
    "Soporte para diversos modelos de programación:\n",
    "\n",
    "  * El clúster puede soportar modelos de programación como MPI+OpenMP, UPC y GASNet, proporcionando flexibilidad para los desarrolladores.\n",
    "Escalabilidad y Rendimiento:\n",
    "\n",
    "La arquitectura híbrida permite escalar el clúster a miles de nodos, proporcionando un rendimiento sustancial para aplicaciones de gran escala."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dcb401-6ce0-4df8-b9e7-96cf3646ec66",
   "metadata": {},
   "source": [
    "### Técnicas orientadas a computación paralela y distribuida\n",
    "\n",
    "**Paralelismo de datos**\n",
    "\n",
    "El paralelismo de datos implica dividir grandes conjuntos de datos en partes más pequeñas y procesarlas simultáneamente en diferentes procesadores. Esta técnica es efectiva en aplicaciones como el procesamiento de imágenes, simulaciones científicas, y análisis de grandes volúmenes de datos.\n",
    "\n",
    "**Paralelismo de tareas**\n",
    "\n",
    "El paralelismo de tareas divide un programa en tareas o hilos que se ejecutan en paralelo. Cada tarea puede realizar una operación diferente, permitiendo la ejecución concurrente de múltiples operaciones. Esta técnica es útil en aplicaciones como servidores web y procesamiento en tiempo real.\n",
    "\n",
    "**Modelos de programación paralela**\n",
    "\n",
    "- Modelo de paso de mensajes (MPI): Utilizado en sistemas de memoria distribuida, donde los procesadores se comunican enviando y recibiendo mensajes. MPI es un estándar ampliamente utilizado en aplicaciones de HPC.\n",
    "\n",
    "- Modelo de memoria compartida (OpenMP): Utilizado en sistemas de memoria compartida, permite la creación de aplicaciones paralelas mediante directivas en el código fuente. OpenMP simplifica la programación paralela en sistemas SMP y multinúcleo.\n",
    "\n",
    "- Modelo híbrido: Combina MPI y OpenMP para aprovechar las ventajas de ambos modelos en sistemas NUMA o clústeres heterogéneos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9c5d49-c0d0-4b33-abfb-1c684e91a8bf",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "- Explica la diferencia entre UMA (Uniform Memory Access) y NUMA (Non-Uniform Memory Access).\n",
    "- Describe las ventajas y desventajas de la memoria compartida en comparación con la memoria distribuida.\n",
    "- ¿Qué es la coherencia de caché y por qué es importante en sistemas de memoria compartida?\n",
    "- Describe el proceso de comunicación entre nodos en un sistema de memoria distribuida.\n",
    "- Explica las técnicas comunes para optimizar la comunicación en sistemas de memoria distribuida.\n",
    "- Discute los desafíos de programación en sistemas de memoria distribuida.\n",
    "- Define qué es una arquitectura de memoria híbrida y da ejemplos de sistemas que la utilizan.\n",
    "- Explica cómo se puede combinar MPI y OpenMP en una arquitectura híbrida para mejorar el rendimiento.\n",
    "- Discute las consideraciones de diseño al desarrollar aplicaciones para arquitecturas híbridas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5a9e4d-efd2-4f9f-9b22-4d3e5b7c681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dfdce4-7917-4b22-a4e4-0ea22b7aecf1",
   "metadata": {},
   "source": [
    "1 . Escribe un programa en Python que use la librería multiprocessing para simular múltiples procesos accediendo y modificando una variable compartida. Usa un Manager para manejar el acceso seguro a la variable compartida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fc2dd3-6526-41da-937a-030571e12d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager\n",
    "\n",
    "def increment(shared_dict, key):\n",
    "    for _ in range(1000):\n",
    "        shared_dict[key] += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    manager = Manager()\n",
    "    shared_dict = manager.dict()\n",
    "    shared_dict[\"counter\"] = 0\n",
    "\n",
    "    processes = []\n",
    "    for _ in range(4):\n",
    "        p = Process(target=increment, args=(shared_dict, \"counter\"))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    print(f\"Final counter value: {shared_dict['counter']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d66eb2d-65d7-47b4-a411-e01833c7e4cc",
   "metadata": {},
   "source": [
    "2 . Usa la librería mpi4py para simular la comunicación entre nodos en un sistema de memoria distribuida. Crea un programa que envíe y reciba mensajes entre múltiples procesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d400608-2348-4558-8b6c-72183f42fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "if rank == 0:\n",
    "    data = \"Hello from rank 0\"\n",
    "    for i in range(1, size):\n",
    "        comm.send(data, dest=i)\n",
    "else:\n",
    "    data = comm.recv(source=0)\n",
    "    print(f\"Rank {rank} received data: {data}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c4b8a7-babe-49c5-b25b-b5001da32860",
   "metadata": {},
   "source": [
    "3 . Combina MPI y OpenMP en un programa Python utilizando mpi4py y threading. Simula una tarea que se distribuye entre nodos y luego se paraleliza dentro de cada nodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19366a8f-9409-4c56-ad30-8da7e1c15155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "from threading import Thread\n",
    "\n",
    "def thread_task(rank):\n",
    "    print(f\"Thread in rank {rank} is running\")\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "threads = []\n",
    "for _ in range(4):\n",
    "    t = Thread(target=thread_task, args=(rank,))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "if rank == 0:\n",
    "    print(\"All threads completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c848b3-eac0-4eb1-8148-c8222311ded1",
   "metadata": {},
   "source": [
    "4 . Escribe un programa en C que use pthread para crear múltiples hilos que accedan y modifiquen una variable global compartida de manera segura usando mutex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54d9396-982e-484d-af3d-e4e6ad6d50ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <pthread.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int counter = 0;\n",
    "pthread_mutex_t lock;\n",
    "\n",
    "void* increment(void* arg) {\n",
    "    for (int i = 0; i < 1000; i++) {\n",
    "        pthread_mutex_lock(&lock);\n",
    "        counter++;\n",
    "        pthread_mutex_unlock(&lock);\n",
    "    }\n",
    "    return NULL;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    pthread_t threads[4];\n",
    "    pthread_mutex_init(&lock, NULL);\n",
    "\n",
    "    for (int i = 0; i < 4; i++) {\n",
    "        pthread_create(&threads[i], NULL, increment, NULL);\n",
    "    }\n",
    "\n",
    "    for (int i = 0; i < 4; i++) {\n",
    "        pthread_join(threads[i], NULL);\n",
    "    }\n",
    "\n",
    "    pthread_mutex_destroy(&lock);\n",
    "    printf(\"Final counter value: %d\\n\", counter);\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2a3e08-951c-4c56-8bab-0055b2787b4c",
   "metadata": {},
   "source": [
    "5 . Usa MPI en C para crear un programa que envíe y reciba mensajes entre múltiples procesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c28774-763b-47ee-9122-ce392c3e6e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int rank, size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "    if (rank == 0) {\n",
    "        char message[] = \"Hello from rank 0\";\n",
    "        for (int i = 1; i < size; i++) {\n",
    "            MPI_Send(message, sizeof(message), MPI_CHAR, i, 0, MPI_COMM_WORLD);\n",
    "        }\n",
    "    } else {\n",
    "        char message[20];\n",
    "        MPI_Recv(message, 20, MPI_CHAR, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
    "        printf(\"Rank %d received message: %s\\n\", rank, message);\n",
    "    }\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba48ecb7-96d8-48a1-9ce6-a59efdeac865",
   "metadata": {},
   "source": [
    "6 . Escribe un programa en Python que use multiprocessing.Pool para sumar los elementos de una lista en paralelo. Divide la lista en partes iguales y asigna cada parte a un proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85412fdb-8347-41c6-9d4e-7c0a07de2c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def sum_segment(segment):\n",
    "    return sum(segment)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = list(range(1000000))  # Lista de un millón de elementos\n",
    "    num_processes = 4\n",
    "    segment_size = len(data) // num_processes\n",
    "\n",
    "    segments = [data[i * segment_size:(i + 1) * segment_size] for i in range(num_processes)]\n",
    "\n",
    "    with Pool(num_processes) as pool:\n",
    "        results = pool.map(sum_segment, segments)\n",
    "\n",
    "    total_sum = sum(results)\n",
    "    print(f\"Total sum: {total_sum}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2e2745-3643-4691-9f68-5a07d4ce1870",
   "metadata": {},
   "source": [
    "7 . Implementa un patrón productor-consumidor usando multiprocessing.Queue en Python. Crea varios procesos productores que pongan datos en la cola y varios procesos consumidores que lean y procesen esos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c86c0e-0224-4079-b436-77ecaa20ad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "import time\n",
    "import random\n",
    "\n",
    "def producer(queue):\n",
    "    for _ in range(10):\n",
    "        item = random.randint(1, 100)\n",
    "        queue.put(item)\n",
    "        print(f\"Produced {item}\")\n",
    "        time.sleep(random.random())\n",
    "\n",
    "def consumer(queue):\n",
    "    while True:\n",
    "        item = queue.get()\n",
    "        if item is None:  # Sentinel value to indicate end of processing\n",
    "            break\n",
    "        print(f\"Consumed {item}\")\n",
    "        time.sleep(random.random())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    queue = Queue()\n",
    "\n",
    "    producers = [Process(target=producer, args=(queue,)) for _ in range(2)]\n",
    "    consumers = [Process(target=consumer, args=(queue,)) for _ in range(2)]\n",
    "\n",
    "    for p in producers:\n",
    "        p.start()\n",
    "\n",
    "    for c in consumers:\n",
    "        c.start()\n",
    "\n",
    "    for p in producers:\n",
    "        p.join()\n",
    "\n",
    "    # Add sentinel values to the queue to signal consumers to exit\n",
    "    for _ in consumers:\n",
    "        queue.put(None)\n",
    "\n",
    "    for c in consumers:\n",
    "        c.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f8a498-35a4-46b6-82ab-b24cb265f8dc",
   "metadata": {},
   "source": [
    "8 . Usa mpi4py para implementar un broadcast donde un proceso envía datos a todos los demás procesos en el comunicador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f29ac74-9824-4fe4-9ba5-91c52821178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = {'key1': 'value1', 'key2': 'value2'}\n",
    "else:\n",
    "    data = None\n",
    "\n",
    "data = comm.bcast(data, root=0)\n",
    "\n",
    "print(f\"Rank {rank} received data: {data}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30e20bc-bd15-42ce-b5ab-dadf81660b64",
   "metadata": {},
   "source": [
    "9 . Implementa una reducción (reduce) con mpi4py para sumar números distribuidos entre varios procesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af090f67-d02a-42fb-aedb-1f0bb4eb839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "# Cada proceso tiene un número diferente\n",
    "number = rank + 1\n",
    "\n",
    "total_sum = comm.reduce(number, op=MPI.SUM, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    print(f\"Total sum: {total_sum}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f0b88d-c4e2-4ee2-98ee-fb7ab9790bc9",
   "metadata": {},
   "source": [
    "10 . Combina MPI y threading para distribuir una lista de datos entre nodos y luego procesarla en paralelo dentro de cada nodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e49b4e9-055f-423c-9165-f3094b331c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "from threading import Thread\n",
    "\n",
    "def process_data(data_segment):\n",
    "    result = [x ** 2 for x in data_segment]\n",
    "    print(f\"Processed segment: {result}\")\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "data = None\n",
    "if rank == 0:\n",
    "    data = list(range(100))\n",
    "    segment_size = len(data) // size\n",
    "    data_segments = [data[i * segment_size:(i + 1) * segment_size] for i in range(size)]\n",
    "else:\n",
    "    data_segments = None\n",
    "\n",
    "data_segment = comm.scatter(data_segments, root=0)\n",
    "\n",
    "threads = []\n",
    "for i in range(4):\n",
    "    t = Thread(target=process_data, args=(data_segment[i::4],))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "comm.Barrier()\n",
    "\n",
    "if rank == 0:\n",
    "    print(\"All data processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcf1b2f-2d32-4cd5-9b08-6eb65d8408f5",
   "metadata": {},
   "source": [
    "11 . Usa MPI para recolectar y combinar los resultados de datos procesados en paralelo utilizando OpenMP en cada nodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf933c-66b5-4317-b15c-3b14c855b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "from threading import Thread\n",
    "\n",
    "def compute_square(value, result_list, index):\n",
    "    result_list[index] = value ** 2\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "data = None\n",
    "if rank == 0:\n",
    "    data = list(range(1, 101))\n",
    "    segment_size = len(data) // size\n",
    "    data_segments = [data[i * segment_size:(i + 1) * segment_size] for i in range(size)]\n",
    "else:\n",
    "    data_segments = None\n",
    "\n",
    "data_segment = comm.scatter(data_segments, root=0)\n",
    "\n",
    "results = [0] * len(data_segment)\n",
    "threads = []\n",
    "for i in range(len(data_segment)):\n",
    "    t = Thread(target=compute_square, args=(data_segment[i], results, i))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "gathered_results = comm.gather(results, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    final_results = [item for sublist in gathered_results for item in sublist]\n",
    "    print(f\"Final results: {final_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f280c4ca-7a59-495a-a341-b13765049c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe469bd7-1d0a-493d-9549-90af1c3ff896",
   "metadata": {},
   "source": [
    "#### Multiprocesadores\n",
    "Los multiprocesadores son sistemas que utilizan múltiples CPUs en un solo sistema de memoria compartida. Estas CPUs pueden estar en un solo chip (multinúcleo) o en varios chips (multiprocesador). Los multiprocesadores pueden mejorar significativamente el rendimiento de las aplicaciones mediante el paralelismo a nivel de tarea o de hilo.\n",
    "\n",
    "Tipos de multiprocesadores\n",
    "\n",
    "- Sistemas simétricos de multiprocesamiento (SMP): En SMP, todos los procesadores son iguales y comparten la memoria principal de manera equitativa. Cada procesador tiene acceso directo a toda la memoria y a los dispositivos de E/S. Los sistemas SMP son ideales para aplicaciones que requieren alta interactividad entre procesos.\n",
    "\n",
    "- Sistemas asimétricos de multiprocesamiento (AMP): En AMP, los procesadores no son iguales. Un procesador principal controla el sistema y asigna tareas a los procesadores secundarios. Este modelo es menos común y se utiliza en sistemas embebidos o en aplicaciones específicas.\n",
    "\n",
    "Ventajas de los Multiprocesadores\n",
    "\n",
    "- Mejoran el rendimiento general al ejecutar múltiples tareas simultáneamente.\n",
    "- Simplifican la programación comparado con sistemas de memoria distribuida.\n",
    "- Buena escalabilidad en sistemas NUMA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc65a46-8f6c-4dc8-8e53-ad5f2b95b4fb",
   "metadata": {},
   "source": [
    "#### Multicomputadores\n",
    "Los multicomputadores, también conocidos como sistemas de memoria distribuida, consisten en múltiples nodos de computación, cada uno con su propia CPU y memoria, interconectados por una red de alta velocidad. Estos sistemas son altamente escalables y se utilizan en aplicaciones que requieren un gran poder de cómputo, como simulaciones científicas y análisis de big data.\n",
    "\n",
    "Ventajas de los multicomputadores\n",
    "\n",
    "- Alta escalabilidad debido a la naturaleza independiente de los nodos.\n",
    "- Mayor tolerancia a fallos, ya que la falla de un nodo no afecta a los demás.\n",
    "\n",
    "Desventajas de los multicomputadores\n",
    "\n",
    "- Programación compleja debido a la necesidad de gestionar la comunicación entre nodos.\n",
    "- Latencias de comunicación más altas comparadas con sistemas de memoria compartida.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9353637-b65e-410b-8efb-dee87147f2e6",
   "metadata": {},
   "source": [
    "#### Clústeres\n",
    "Los clústeres son un tipo de arquitectura de multicomputador donde varios sistemas completos (nodos) están conectados a través de una red para trabajar juntos como un solo sistema. Los clústeres pueden ser homogéneos (todos los nodos son iguales) o heterogéneos (nodos con diferentes capacidades).\n",
    "\n",
    "Tipos de clústeres\n",
    "\n",
    "* Clústeres de alto rendimiento (HPC): Diseñados para maximizar el rendimiento y son utilizados en simulaciones científicas, análisis de datos, y otras aplicaciones que requieren gran poder de cómputo.\n",
    "\n",
    "* Clústeres de alta disponibilidad (HA): Enfocados en proporcionar alta disponibilidad y tolerancia a fallos. Se utilizan en aplicaciones críticas donde el tiempo de inactividad debe minimizarse.\n",
    "\n",
    "* Clústeres de balanceo de carga: Distribuyen la carga de trabajo entre varios nodos para mejorar el rendimiento y la disponibilidad de servicios web y aplicaciones empresariales.\n",
    "\n",
    "Ventajas de los clústeres\n",
    "\n",
    "* Alta escalabilidad y flexibilidad.\n",
    "* Costo-efectividad al utilizar hardware convencional.\n",
    "* Capacidad de combinar recursos de diferentes sistemas para tareas específicas.\n",
    "Desventajas de los Clústeres\n",
    "Complejidad en la configuración y gestión.\n",
    "Dependencia de la red para la comunicación entre nodos, lo que puede introducir latencias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5716bb-6bc1-4258-9c42-f0493ce96f88",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "* Explica las diferencias fundamentales entre un multiprocesador y un multicomputador en términos de arquitectura, comunicación entre procesadores y aplicaciones típicas.\n",
    "* Discute los diferentes modelos de consistencia de memoria en sistemas de multiprocesadores. Compara y contrasta la consistencia secuencial, la consistencia causal y la consistencia eventual, proporcionando ejemplos de situaciones en las que cada uno podría ser adecuado.\n",
    "* Define el problema de coherencia de caché en sistemas multiprocesadores y describe al menos dos protocolos de coherencia de caché (como MESI y MOESI). Explica cómo estos protocolos ayudan a mantener la coherencia y los posibles problemas de rendimiento asociados.\n",
    "Paralelismo a Nivel de Instrucción (ILP)\n",
    "* Describe el concepto de paralelismo a nivel de instrucción (ILP) y cómo los multiprocesadores pueden explotarlo. Discute técnicas como la ejecución fuera de orden y la predicción de saltos, y cómo estas técnicas afectan el rendimiento.\n",
    "* Describe las diferentes topologías de red utilizadas en multicomputadores (como malla, hipercubo, anillo y estrella). Analiza las ventajas y desventajas de cada topología en términos de latencia, ancho de banda y tolerancia a fallos.\n",
    "* Compara y contrasta los protocolos de comunicación punto a punto y basados en mensajes en multicomputadores. Proporciona ejemplos de situaciones en las que uno podría ser más adecuado que el otro.\n",
    "* Define el concepto de escalabilidad en el contexto de multicomputadores y discute los factores que afectan la escalabilidad, como la latencia de comunicación, el ancho de banda y el balance de carga. Proporciona ejemplos de cómo diseñar un sistema multicomputador escalable.\n",
    "* Explica los desafíos de la sincronización en sistemas distribuidos y describe al menos dos algoritmos de sincronización (como el algoritmo de Lamport y el algoritmo de Ricart-Agrawala). Discute cómo estos algoritmos aseguran la exclusión mutua y las posibles desventajas.\n",
    "* Describe los componentes clave en el diseño de un clúster de alto rendimiento, incluyendo nodos de computación, redes de interconexión, almacenamiento y software de gestión. Discute las decisiones de diseño que afectan el rendimiento y la escalabilidad del clúster.\n",
    "Modelos de Programación para Clústeres\n",
    "* Compara y contrasta los modelos de programación para clústeres, como MPI (Message Passing Interface) y OpenMP (Open Multi-Processing). Discute las ventajas y desventajas de cada modelo y proporciona ejemplos de aplicaciones típicas.\n",
    "* Explica la importancia de la tolerancia a fallos en clústeres y describe las técnicas comunes para lograrla, como la replicación de datos, el checkpointing y la migración de tareas. Discute los desafíos asociados con cada técnica.\n",
    "* Describe los métodos utilizados para evaluar el rendimiento de un clúster, como benchmarks (por ejemplo, LINPACK, HPCG) y métricas (por ejemplo, FLOPS, latencia, ancho de banda). Explica cómo interpretar los resultados y utilizarlos para optimizar el rendimiento del clúster.\n",
    "* Análisis de escalabilidad_ Un sistema multiprocesador tiene 8 núcleos y se observa que una aplicación que tarda 100 segundos en ejecutarse en un solo núcleo tarda 20 segundos en ejecutarse en 8 núcleos. Calcula la aceleración (speedup) y la eficiencia del sistema. ¿Es el sistema escalable? Justifica tu respuesta.\n",
    "* Describe el problema de la cena de los filósofos y cómo se aplica a los sistemas de multiprocesadores. Propón una solución utilizando semáforos o monitores y discute las posibles situaciones de deadlock y cómo evitarlas.\n",
    "* Investiga un caso de estudio real de un clúster de alto rendimiento utilizado en una aplicación científica o industrial. Describe la arquitectura del clúster, el tipo de aplicaciones que ejecuta, y los desafíos y soluciones implementadas en términos de rendimiento y escalabilidad.\n",
    "* Realiza una evaluación comparativa teórica de dos arquitecturas de clústeres diferentes (por ejemplo, uno basado en CPU y otro basado en GPU). Discute las ventajas y desventajas de cada arquitectura para diferentes tipos de aplicaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9d4000-beb2-4129-934e-00c1acd47358",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c427e40-8594-4112-8483-e380a627d891",
   "metadata": {},
   "source": [
    "1 . Implementa la multiplicación de dos matrices grandes en paralelo utilizando la librería multiprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdbe054-9ce6-4da0-82b7-6ff5bb406222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "\n",
    "def matrix_multiply_segment(args):\n",
    "    A_segment, B = args\n",
    "    return np.dot(A_segment, B)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    A = np.random.rand(1000, 1000)\n",
    "    B = np.random.rand(1000, 1000)\n",
    "\n",
    "    num_processes = 4\n",
    "    segment_size = A.shape[0] // num_processes\n",
    "    segments = [(A[i * segment_size:(i + 1) * segment_size], B) for i in range(num_processes)]\n",
    "\n",
    "    with Pool(num_processes) as pool:\n",
    "        results = pool.map(matrix_multiply_segment, segments)\n",
    "\n",
    "    C = np.vstack(results)\n",
    "    print(\"Matrix multiplication completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2974988e-f07f-419e-9a18-1f40cb4d9051",
   "metadata": {},
   "source": [
    "2 . Implementa la suma de dos vectores grandes distribuidos entre varios nodos utilizando mpi4py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02734643-6821-4908-99c2-a5d3c9921420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "vector_size = 1000000\n",
    "local_size = vector_size // size\n",
    "\n",
    "if rank == 0:\n",
    "    A = np.random.rand(vector_size)\n",
    "    B = np.random.rand(vector_size)\n",
    "else:\n",
    "    A = None\n",
    "    B = None\n",
    "\n",
    "local_A = np.empty(local_size, dtype='d')\n",
    "local_B = np.empty(local_size, dtype='d')\n",
    "\n",
    "comm.Scatter(A, local_A, root=0)\n",
    "comm.Scatter(B, local_B, root=0)\n",
    "\n",
    "local_C = local_A + local_B\n",
    "\n",
    "if rank == 0:\n",
    "    C = np.empty(vector_size, dtype='d')\n",
    "else:\n",
    "    C = None\n",
    "\n",
    "comm.Gather(local_C, C, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    print(\"Vector addition completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a077935a-e464-4f21-acf6-1634adb3b2a9",
   "metadata": {},
   "source": [
    "3 . Implementa una simulación de Monte Carlo para calcular el valor de Pi en paralelo en un clúster utilizando mpi4py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bb7cbc-2ddd-4b3f-b07a-723c4b7b56bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "num_samples = 1000000\n",
    "local_samples = num_samples // size\n",
    "\n",
    "np.random.seed(rank)\n",
    "local_count = 0\n",
    "\n",
    "for _ in range(local_samples):\n",
    "    x, y = np.random.rand(2)\n",
    "    if x**2 + y**2 <= 1.0:\n",
    "        local_count += 1\n",
    "\n",
    "total_count = comm.reduce(local_count, op=MPI.SUM, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    pi_estimate = (4.0 * total_count) / num_samples\n",
    "    print(f\"Estimated Pi: {pi_estimate}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daf8b66-df02-4bfe-a383-a906abdb3ecb",
   "metadata": {},
   "source": [
    "4 . Divide y procesa un gran archivo de texto en un clúster, donde cada nodo procesa una parte del archivo y luego los resultados se combinan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f82114a-94a5-4f1b-95bf-3a7a3f2803dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "if rank == 0:\n",
    "    with open('large_text_file.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "else:\n",
    "    lines = None\n",
    "\n",
    "lines = comm.scatter(lines, root=0)\n",
    "\n",
    "local_word_count = sum(len(line.split()) for line in lines)\n",
    "\n",
    "total_word_count = comm.reduce(local_word_count, op=MPI.SUM, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    print(f\"Total word count: {total_word_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58bb94d-0aa0-4410-a7af-8b769c6356e2",
   "metadata": {},
   "source": [
    "5 . Usa pthread para dividir un arreglo en segmentos y sumarlos en paralelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09966634-d63a-46fd-a632-fcb326e4e7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <pthread.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define NUM_THREADS 4\n",
    "#define ARRAY_SIZE 1000000\n",
    "\n",
    "int array[ARRAY_SIZE];\n",
    "long long sum = 0;\n",
    "pthread_mutex_t mutex;\n",
    "\n",
    "void* sum_segment(void* arg) {\n",
    "    int start = (int)arg * (ARRAY_SIZE / NUM_THREADS);\n",
    "    int end = start + (ARRAY_SIZE / NUM_THREADS);\n",
    "    long long local_sum = 0;\n",
    "\n",
    "    for (int i = start; i < end; i++) {\n",
    "        local_sum += array[i];\n",
    "    }\n",
    "\n",
    "    pthread_mutex_lock(&mutex);\n",
    "    sum += local_sum;\n",
    "    pthread_mutex_unlock(&mutex);\n",
    "\n",
    "    return NULL;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    pthread_t threads[NUM_THREADS];\n",
    "    pthread_mutex_init(&mutex, NULL);\n",
    "\n",
    "    for (int i = 0; i < ARRAY_SIZE; i++) {\n",
    "        array[i] = rand() % 100;\n",
    "    }\n",
    "\n",
    "    for (int i = 0; i < NUM_THREADS; i++) {\n",
    "        pthread_create(&threads[i], NULL, sum_segment, (void*)i);\n",
    "    }\n",
    "\n",
    "    for (int i = 0; i < NUM_THREADS; i++) {\n",
    "        pthread_join(threads[i], NULL);\n",
    "    }\n",
    "\n",
    "    pthread_mutex_destroy(&mutex);\n",
    "    printf(\"Total sum: %lld\\n\", sum);\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5acdb5-cc23-4b03-a627-de4f8eaee416",
   "metadata": {},
   "source": [
    "6 . Implementa la suma de dos vectores grandes distribuidos entre varios nodos utilizando MPI en C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d9825-4585-4345-9c49-6a856378d74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int rank, size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "    int vector_size = 1000000;\n",
    "    int local_size = vector_size / size;\n",
    "\n",
    "    double* local_A = (double*)malloc(local_size * sizeof(double));\n",
    "    double* local_B = (double*)malloc(local_size * sizeof(double));\n",
    "    double* local_C = (double*)malloc(local_size * sizeof(double));\n",
    "\n",
    "    for (int i = 0; i < local_size; i++) {\n",
    "        local_A[i] = rank + 1;\n",
    "        local_B[i] = rank + 2;\n",
    "    }\n",
    "\n",
    "    MPI_Allreduce(local_A, local_C, local_size, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);\n",
    "\n",
    "    for (int i = 0; i < local_size; i++) {\n",
    "        local_C[i] = local_A[i] + local_B[i];\n",
    "    }\n",
    "\n",
    "    free(local_A);\n",
    "    free(local_B);\n",
    "    free(local_C);\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86429624-099a-42ca-b806-f2bbb52ced44",
   "metadata": {},
   "source": [
    "7 . Implementa una simulación de Monte Carlo para calcular el valor de Pi en paralelo en un clúster utilizando MPI en C.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ae5c7-d4e4-4366-a189-074730c26513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int rank, size;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "    long long num_samples = 1000000;\n",
    "    long long local_samples = num_samples / size;\n",
    "    long long local_count = 0;\n",
    "    unsigned int seed = rank;\n",
    "\n",
    "    for (long long i = 0; i < local_samples; i++) {\n",
    "        double x = (double)rand_r(&seed) / RAND_MAX;\n",
    "        double y = (double)rand_r(&seed) / RAND_MAX;\n",
    "        if (x * x + y * y <= 1.0) {\n",
    "            local_count++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    long long total_count;\n",
    "    MPI_Reduce(&local_count, &total_count, 1, MPI_LONG_LONG_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "\n",
    "    if (rank == 0) {\n",
    "        double pi_estimate = (4.0 * total_count) / num_samples;\n",
    "        printf(\"Estimated Pi: %f\\n\", pi_estimate);\n",
    "    }\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e898fa6d-2d72-4888-9be1-c97066ddb049",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
